{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOr4uMNGkxetE4zE59f0D8T"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# -------------------------------------------------\n","# 1Ô∏è‚É£ Íµ¨Í∏Ä ÎìúÎùºÏù¥Î∏å ÎßàÏö¥Ìä∏\n","# -------------------------------------------------\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"inH0BUJ9NDTv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762148063153,"user_tz":-540,"elapsed":21766,"user":{"displayName":"Star Sin","userId":"12579642930462495568"}},"outputId":"2fb69332-14e7-4eee-84cb-6db08263bf5b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_L99bKOrMR6U","executionInfo":{"status":"ok","timestamp":1762150808941,"user_tz":-540,"elapsed":14918,"user":{"displayName":"Star Sin","userId":"12579642930462495568"}},"outputId":"5090ad39-6ade-4bc4-f8de-da122cfb13d6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","fonts-nanum is already the newest version (20200506-1).\n","0 upgraded, 0 newly installed, 0 to remove and 51 not upgraded.\n","/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n","/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n","/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n","/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n","/usr/share/fonts/truetype/nanum: caching, new cache contents: 39 fonts, 0 dirs\n","/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n","/root/.local/share/fonts: skipping, no such directory\n","/root/.fonts: skipping, no such directory\n","/usr/share/fonts/truetype: skipping, looped directory detected\n","/usr/share/fonts/truetype/humor-sans: skipping, looped directory detected\n","/usr/share/fonts/truetype/liberation: skipping, looped directory detected\n","/usr/share/fonts/truetype/nanum: skipping, looped directory detected\n","/var/cache/fontconfig: cleaning cache directory\n","/root/.cache/fontconfig: not cleaning non-existent cache directory\n","/root/.fontconfig: not cleaning non-existent cache directory\n","fc-cache: succeeded\n","W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"]}],"source":["!sudo apt-get install -y fonts-nanum\n","!sudo fc-cache -fv\n","!rm ~/.cache/matplotlib -rf\n","\n","!apt-get update -qq\n","!apt-get install fonts-nanum* -qq\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.font_manager as fm\n","import warnings\n","warnings.filterwarnings(action='ignore')\n","\n","path = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf' # ÎÇòÎàî Í≥†Îîï\n","font_name = fm.FontProperties(fname=path, size=10).get_name() # Í∏∞Î≥∏ Ìè∞Ìä∏ ÏÇ¨Ïù¥Ï¶à : 10\n","plt.rc('font', family=font_name)\n","\n","fm.fontManager.addfont(path)"]},{"cell_type":"code","source":["\n","# === ÌîÑÎ°úÏ†ùÌä∏ Î£®Ìä∏ (ÎÑ§ Ìè¥Îçî ÏúÑÏπòÏóê ÎßûÏ∂∞ Î∞îÍøîÏ§ò) ===\n","# Ïòà) MyDrive/colab_projects/pill_detect_runs Ï≤òÎüº Î≥∏Ïù∏ Ìè¥Îçî Í≤ΩÎ°úÎ°ú ÏßÄÏ†ï\n","PROJECT_DIR = \"/content/drive/MyDrive/pill_det/mnt_data\"\n","\n","import os\n","from pathlib import Path\n","\n","# ÌôïÏù∏Ïö© Ï∂úÎ†•\n","print(\"PROJECT_DIR:\", PROJECT_DIR)\n","print(\"Ï°¥Ïû¨?\", os.path.isdir(PROJECT_DIR))\n","print(\"ÏïàÏùò ÌååÏùº 10Í∞ú ÏòàÏãú:\", list(Path(PROJECT_DIR).glob(\"*\"))[:10])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G7Dvv858Nar6","executionInfo":{"status":"ok","timestamp":1762148409256,"user_tz":-540,"elapsed":41,"user":{"displayName":"Star Sin","userId":"12579642930462495568"}},"outputId":"8521a394-7ea3-4152-ebb2-2a493dcddf97"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["PROJECT_DIR: /content/drive/MyDrive/pill_det/mnt_data\n","Ï°¥Ïû¨? True\n","ÏïàÏùò ÌååÏùº 10Í∞ú ÏòàÏãú: [PosixPath('/content/drive/MyDrive/pill_det/mnt_data/pred_ensemble_1761707940.csv'), PosixPath('/content/drive/MyDrive/pill_det/mnt_data/submission_ensemble_ocr.csv'), PosixPath('/content/drive/MyDrive/pill_det/mnt_data/all_results_csv.zip'), PosixPath('/content/drive/MyDrive/pill_det/mnt_data/submission_final.csv'), PosixPath('/content/drive/MyDrive/pill_det/mnt_data/results.csv'), PosixPath('/content/drive/MyDrive/pill_det/mnt_data/loss.zip')]\n"]}]},{"cell_type":"code","source":["# =========================================================\n","# üîÅ Îç∞Ïù¥ÌÑ∞ ÍµêÏ≤¥¬∑Í≤ÄÏ¶ù¬∑ÌÜµÌï© ‚Äî Îã®Ïùº ÏÖÄ\n","#   - DATA_CONFIGÎßå ÏàòÏ†ïÌïòÎ©¥ ÏÉàÎ°úÏö¥ ÌååÏùºÎ°ú df_master Ïû¨ÏÉùÏÑ±\n","#   - Ï†úÏ∂úCSV/YOLO results/FRCNN loss/K-Fold Î¨∂Ïùå ZIP Î™®Îëê ÏÑ†ÌÉùÏ†ÅÏúºÎ°ú Ï≤òÎ¶¨\n","# =========================================================\n","import os, zipfile, json, time, re\n","from pathlib import Path\n","import numpy as np\n","import pandas as pd\n","\n","# ---------------------------\n","# 0) Ïó¨Í∏∞Î•º ÎÑ§ ÌôòÍ≤ΩÏúºÎ°ú ÍµêÏ≤¥\n","# ---------------------------\n","DATA_CONFIG = {\n","    # Î≤†Ïù¥Ïä§ Ìè¥Îçî (Colab: Íµ¨Í∏ÄÎìúÎùºÏù¥Î∏å or Î°úÏª¨)\n","    \"BASE_DIR\": \"/content/drive/MyDrive/pill_det/mnt_data\",\n","\n","    # ÌååÏùº Í≤ΩÎ°úÎì§ (ÏóÜÏúºÎ©¥ None ÌóàÏö©)\n","    \"PATH_SUB_FINAL\": \"submission_final.csv\",          # OCR Ïû¨Îû≠ÌÇπ ÏµúÏ¢Ö Ï†úÏ∂ú\n","    \"PATH_SUB_ENS\":   \"submission_ensemble_ocr.csv\",   # ÏïôÏÉÅÎ∏î+OCR Ï†úÏ∂ú\n","    \"PATH_FINAL_RES\": \"results.csv\",                   # ÏµúÏ¢Ö overfit run results.csv\n","    \"PATH_KFOLD_ZIP\": \"all_results_csv.zip\",          # K-Fold results.csv Î¨∂Ïùå ZIP\n","    \"PATH_LOSS_ZIP\":  \"loss.zip\",                      # FRCNN loss json Î¨∂Ïùå ZIP\n","\n","    # Ï∂úÎ†•\n","    \"OUT_DIR\": \"out\",                                  # BASE_DIR/out\n","    \"MASTER_NAME\": \"analysis_master.csv\",              # ÎßàÏä§ÌÑ∞ CSV ÌååÏùºÎ™Ö\n","}\n","\n","# ---------------------------\n","# 1) Í≤ΩÎ°ú Ïú†Ìã∏\n","# ---------------------------\n","BASE_DIR   = DATA_CONFIG[\"BASE_DIR\"]\n","OUT_DIR    = os.path.join(BASE_DIR, DATA_CONFIG[\"OUT_DIR\"])\n","MASTER_CSV = os.path.join(OUT_DIR, DATA_CONFIG[\"MASTER_NAME\"])\n","os.makedirs(OUT_DIR, exist_ok=True)\n","\n","def _p(rel_or_abs):\n","    \"\"\"BASE_DIR Í∏∞Ï§Ä ÏÉÅÎåÄ/Ï†àÎåÄ Í≤ΩÎ°úÎ•º ÏïàÏ†ÑÌïòÍ≤å Î≥ëÌï©\"\"\"\n","    if rel_or_abs is None:\n","        return None\n","    p = str(rel_or_abs)\n","    return p if p.startswith(\"/\") or p.startswith(\"\\\\\") else os.path.join(BASE_DIR, p)\n","\n","# Ïã§Ï†ú Í≤ΩÎ°ú ÌôïÏ†ï\n","PATH_SUB_FINAL = _p(DATA_CONFIG[\"PATH_SUB_FINAL\"])\n","PATH_SUB_ENS   = _p(DATA_CONFIG[\"PATH_SUB_ENS\"])\n","PATH_FINAL_RES = _p(DATA_CONFIG[\"PATH_FINAL_RES\"])\n","PATH_KFOLD_ZIP = _p(DATA_CONFIG[\"PATH_KFOLD_ZIP\"])\n","PATH_LOSS_ZIP  = _p(DATA_CONFIG[\"PATH_LOSS_ZIP\"])\n","\n","print(\"üîß BASE:\", BASE_DIR)\n","for k, v in {\n","    \"PATH_SUB_FINAL\": PATH_SUB_FINAL,\n","    \"PATH_SUB_ENS\": PATH_SUB_ENS,\n","    \"PATH_FINAL_RES\": PATH_FINAL_RES,\n","    \"PATH_KFOLD_ZIP\": PATH_KFOLD_ZIP,\n","    \"PATH_LOSS_ZIP\": PATH_LOSS_ZIP,\n","    \"OUT_DIR\": OUT_DIR,\n","    \"MASTER_CSV\": MASTER_CSV,\n","}.items():\n","    print(f\" - {k}: {v}\")\n","\n","# ---------------------------\n","# 2) Î°úÎçî & ÌååÏÑú\n","# ---------------------------\n","def safe_read_csv(path, **kwargs):\n","    if not path or not os.path.isfile(path):\n","        return None\n","    try:\n","        return pd.read_csv(path, **kwargs)\n","    except Exception:\n","        pass\n","    for sep in [\",\", \";\", \"\\t\", \" \"]:\n","        try:\n","            return pd.read_csv(path, sep=sep)\n","        except Exception:\n","            continue\n","    for enc in [\"utf-8-sig\",\"cp949\",\"euc-kr\",\"latin-1\"]:\n","        try:\n","            return pd.read_csv(path, encoding=enc)\n","        except Exception:\n","            continue\n","    return None\n","\n","def extract_all_from_zip(zip_path, target_dir, exts=None):\n","    if not zip_path or not os.path.isfile(zip_path):\n","        return []\n","    os.makedirs(target_dir, exist_ok=True)\n","    with zipfile.ZipFile(zip_path, \"r\") as z:\n","        z.extractall(target_dir)\n","    paths = list(Path(target_dir).glob(\"**/*\"))\n","    if exts:\n","        paths = [str(p) for p in paths if p.suffix.lower() in exts]\n","    else:\n","        paths = [str(p) for p in paths]\n","    return paths\n","\n","def parse_submission_df(df_sub: pd.DataFrame, prefix: str):\n","    if df_sub is None:\n","        return None, None\n","    # Ïú†Ïó∞Ìïú Ïª¨ÎüºÎ™Ö Í∞êÏßÄ\n","    cols = {c.lower(): c for c in df_sub.columns}\n","    if (\"image_id\" not in cols.values()) or (\"predictionstring\" not in [c.lower() for c in df_sub.columns]):\n","        return None, None\n","    img_col = next(c for c in df_sub.columns if c.lower()==\"image_id\")\n","    ps_col  = next(c for c in df_sub.columns if c.lower()==\"predictionstring\")\n","\n","    rows_stat, rows_flat = [], []\n","    for _, r in df_sub.iterrows():\n","        img_id = str(r[img_col])\n","        pred   = r[ps_col]\n","        num_boxes=0; avg_score=max_score=min_score=0.0\n","        scores=[]\n","        if isinstance(pred, str) and pred.strip():\n","            parts = pred.split()\n","            chunks = [parts[i:i+6] for i in range(0, len(parts), 6)]\n","            for ch in chunks:\n","                if len(ch) < 6:\n","                    continue\n","                cname = ch[0]\n","                try: s = float(ch[1])\n","                except: s = np.nan\n","                try: x1,y1,x2,y2 = map(float, ch[2:6])\n","                except: x1=y1=x2=y2=np.nan\n","                rows_flat.append({\n","                    \"image_id\": img_id, \"cls_name\": cname, \"score\": s,\n","                    \"x1\": x1, \"y1\": y1, \"x2\": x2, \"y2\": y2,\n","                    \"source_submission\": prefix\n","                })\n","                scores.append(s)\n","            num_boxes = len(chunks)\n","            if scores:\n","                avg_score = float(np.nanmean(scores))\n","                max_score = float(np.nanmax(scores))\n","                min_score = float(np.nanmin(scores))\n","        rows_stat.append({\n","            \"image_id\": img_id,\n","            f\"num_boxes_{prefix}\": num_boxes,\n","            f\"avg_score_{prefix}\": avg_score,\n","            f\"max_score_{prefix}\": max_score,\n","            f\"min_score_{prefix}\": min_score,\n","        })\n","    return pd.DataFrame(rows_stat).drop_duplicates(\"image_id\"), (pd.DataFrame(rows_flat) if rows_flat else None)\n","\n","def pick_metric_column(cols):\n","    for c in cols:\n","        lc = c.lower()\n","        if \"map\" in lc and (\"50-95\" in lc or \"50:95\" in lc):\n","            return c\n","    for c in cols:\n","        if \"map\" in c.lower() and \"50\" in c.lower():\n","            return c\n","    for c in cols:\n","        if \"map\" in c.lower():\n","            return c\n","    return None\n","\n","def guess_fold_and_model(run_name: str):\n","    fold, model = None, None\n","    m = re.match(r\"^fold(\\d+)_([A-Za-z0-9\\-]+)\", run_name or \"\")\n","    if m:\n","        try: fold = int(m.group(1))\n","        except: pass\n","        model_plus = m.group(2)\n","        for cand in [\"yolov8n\",\"yolov8s\",\"yolov8m\",\"yolov8l\",\"yolov8x\",\"yolo11n\",\"yolo11s\",\"yolo11m\",\"yolo11l\",\"yolo11x\"]:\n","            if model_plus.startswith(cand):\n","                model = cand\n","                break\n","        if model is None: model = model_plus\n","    return fold, model\n","\n","def parse_yolo_results(df_res: pd.DataFrame, run_name: str, phase: str, fold_guess=None, model_type_guess=None):\n","    if df_res is None or len(df_res)==0:\n","        return None\n","    cols = list(df_res.columns)\n","    loss_cols = [c for c in cols if \"loss\" in c.lower()]\n","    map_col = pick_metric_column(cols)\n","    f_auto, m_auto = guess_fold_and_model(run_name)\n","    fold   = f_auto if fold_guess is None else fold_guess\n","    model  = m_auto if model_type_guess is None else model_type_guess\n","\n","    out=[]\n","    for _, row in df_res.iterrows():\n","        ep = pd.to_numeric(row.get(\"epoch\", np.nan), errors=\"coerce\")\n","        loss_sum, seen = 0.0, False\n","        for lc in loss_cols:\n","            try:\n","                v = float(row[lc])\n","                if not np.isnan(v):\n","                    loss_sum += v; seen = True\n","            except: pass\n","        loss_sum = loss_sum if seen else np.nan\n","        m5095 = np.nan\n","        if map_col and map_col in row:\n","            try: m5095 = float(row[map_col])\n","            except: m5095 = np.nan\n","        out.append({\n","            \"row_type\":\"train_epoch\",\"phase\":phase,\"run_name\":run_name,\n","            \"fold\":fold,\"model_type\":model,\"epoch\":ep,\n","            \"train_loss\":loss_sum,\"val_loss\":np.nan,\"map5095\":m5095,\n","            \"timestamp\":time.time(),\n","            \"image_id\":np.nan,\"num_boxes_final\":np.nan,\"avg_score_final\":np.nan,\"max_score_final\":np.nan,\"min_score_final\":np.nan,\n","            \"num_boxes_ens\":np.nan,\"avg_score_ens\":np.nan,\"max_score_ens\":np.nan,\"min_score_ens\":np.nan,\n","            \"score_gap\":np.nan,\"boxcount_gap\":np.nan\n","        })\n","    return pd.DataFrame(out)\n","\n","def parse_frcnn_jsonloss(df_json: pd.DataFrame, run_name: str, fold_guess=None):\n","    if df_json is None or len(df_json)==0:\n","        return None\n","    m = re.search(r\"fold(\\d+)\", run_name or \"\")\n","    fold = fold_guess\n","    if fold is None and m:\n","        try: fold = int(m.group(1))\n","        except: pass\n","    out=[]\n","    for _, row in df_json.iterrows():\n","        out.append({\n","            \"row_type\":\"train_epoch\",\"phase\":\"frcnn\",\"run_name\":run_name,\"fold\":fold,\n","            \"model_type\":\"fasterrcnn_resnet50_fpn\",\n","            \"epoch\":row.get(\"epoch\", np.nan),\n","            \"train_loss\":row.get(\"train_loss\", np.nan),\n","            \"val_loss\":row.get(\"val_loss\", np.nan),\n","            \"map5095\":np.nan,\"timestamp\":row.get(\"time\", time.time()),\n","            \"image_id\":np.nan,\"num_boxes_final\":np.nan,\"avg_score_final\":np.nan,\"max_score_final\":np.nan,\"min_score_final\":np.nan,\n","            \"num_boxes_ens\":np.nan,\"avg_score_ens\":np.nan,\"max_score_ens\":np.nan,\"min_score_ens\":np.nan,\n","            \"score_gap\":np.nan,\"boxcount_gap\":np.nan\n","        })\n","    return pd.DataFrame(out)\n","\n","# ---------------------------\n","# 3) Îç∞Ïù¥ÌÑ∞ Î°úÎìú\n","# ---------------------------\n","df_sub_final = safe_read_csv(PATH_SUB_FINAL)\n","df_sub_ens   = safe_read_csv(PATH_SUB_ENS)\n","df_final_run = safe_read_csv(PATH_FINAL_RES)\n","\n","print(\"\\nüì¶ ÏõêÎ≥∏ ÌòïÌÉú\")\n","print(\" - submission_final:\", None if df_sub_final is None else df_sub_final.shape)\n","print(\" - submission_ens  :\", None if df_sub_ens   is None else df_sub_ens.shape)\n","print(\" - final results   :\", None if df_final_run is None else df_final_run.shape)\n","\n","EXTRACT_KFOLD_DIR = os.path.join(OUT_DIR, \"kfold_extracted\")\n","EXTRACT_LOSS_DIR  = os.path.join(OUT_DIR, \"loss_extracted\")\n","\n","kfold_csv_paths = extract_all_from_zip(PATH_KFOLD_ZIP, EXTRACT_KFOLD_DIR, exts={\".csv\"})\n","loss_json_paths = extract_all_from_zip(PATH_LOSS_ZIP,  EXTRACT_LOSS_DIR,  exts={\".json\"})\n","\n","df_kfold_all = []\n","for p in kfold_csv_paths:\n","    tmp = safe_read_csv(p)\n","    if tmp is not None and len(tmp):\n","        tmp[\"__src_file\"] = Path(p).name\n","        df_kfold_all.append(tmp)\n","df_kfold_all = pd.concat(df_kfold_all, ignore_index=True) if df_kfold_all else None\n","\n","df_loss_all = []\n","for p in loss_json_paths:\n","    try:\n","        tmp = pd.read_json(p)\n","        tmp[\"__src_file\"] = Path(p).name\n","        df_loss_all.append(tmp)\n","    except: pass\n","df_loss_all = pd.concat(df_loss_all, ignore_index=True) if df_loss_all else None\n","\n","print(\" - K-Fold zip     :\", None if df_kfold_all is None else df_kfold_all.shape)\n","print(\" - FRCNN loss zip :\", None if df_loss_all  is None else df_loss_all.shape)\n","\n","# ---------------------------\n","# 4) Ï†úÏ∂ú CSV ‚Üí Ïù¥ÎØ∏ÏßÄÎ≥Ñ ÌÜµÍ≥Ñ\n","# ---------------------------\n","sub_final_stats, sub_final_flat = parse_submission_df(df_sub_final, prefix=\"final\")\n","sub_ens_stats,   sub_ens_flat   = parse_submission_df(df_sub_ens,   prefix=\"ens\")\n","\n","if sub_final_stats is None and sub_ens_stats is None:\n","    df_sub_merged = pd.DataFrame()\n","else:\n","    if sub_final_stats is None:\n","        df_sub_merged = sub_ens_stats.copy()\n","    elif sub_ens_stats is None:\n","        df_sub_merged = sub_final_stats.copy()\n","    else:\n","        df_sub_merged = sub_final_stats.merge(sub_ens_stats, on=\"image_id\", how=\"outer\")\n","    # ÌååÏÉùÏπò\n","    if \"avg_score_final\" in df_sub_merged.columns and \"avg_score_ens\" in df_sub_merged.columns:\n","        df_sub_merged[\"score_gap\"] = df_sub_merged[\"avg_score_ens\"] - df_sub_merged[\"avg_score_final\"]\n","    if \"num_boxes_final\" in df_sub_merged.columns and \"num_boxes_ens\" in df_sub_merged.columns:\n","        df_sub_merged[\"boxcount_gap\"] = df_sub_merged[\"num_boxes_ens\"] - df_sub_merged[\"num_boxes_final\"]\n","\n","def wrap_submission_rows(df_in):\n","    if df_in is None or len(df_in)==0:\n","        return pd.DataFrame()\n","    out = df_in.copy()\n","    out[\"row_type\"]=\"submission_image\"\n","    out[\"phase\"]=\"inference\"\n","    out[\"run_name\"]=\"compare_final_vs_ens\"\n","    out[\"fold\"]=np.nan\n","    out[\"model_type\"]=\"inference_compare\"\n","    out[\"epoch\"]=np.nan\n","    out[\"train_loss\"]=np.nan\n","    out[\"val_loss\"]=np.nan\n","    out[\"map5095\"]=np.nan\n","    out[\"timestamp\"]=time.time()\n","    for col in [\n","        \"num_boxes_final\",\"avg_score_final\",\"max_score_final\",\"min_score_final\",\n","        \"num_boxes_ens\",\"avg_score_ens\",\"max_score_ens\",\"min_score_ens\",\n","        \"score_gap\",\"boxcount_gap\"\n","    ]:\n","        if col not in out.columns: out[col]=np.nan\n","    return out.reset_index(drop=True)\n","\n","df_sub_rows = wrap_submission_rows(df_sub_merged)\n","print(\"\\nüßÆ df_sub_rows:\", df_sub_rows.shape)\n","\n","# ---------------------------\n","# 5) ÌïôÏäµ Î°úÍ∑∏ ÌëúÏ§ÄÌôî\n","# ---------------------------\n","rows_training=[]\n","\n","# K-Fold YOLO\n","if df_kfold_all is not None:\n","    for run_src, part in df_kfold_all.groupby(\"__src_file\"):\n","        rn = Path(run_src).stem\n","        dfp = parse_yolo_results(part, run_name=rn, phase=\"kfold\")\n","        if dfp is not None and len(dfp): rows_training.append(dfp)\n","\n","# Final overfit YOLO\n","if df_final_run is not None and len(df_final_run):\n","    dfp = parse_yolo_results(df_final_run, run_name=\"final_overfit\", phase=\"final_overfit\")\n","    if dfp is not None and len(dfp): rows_training.append(dfp)\n","\n","# FRCNN\n","if df_loss_all is not None and len(df_loss_all):\n","    for src, part in df_loss_all.groupby(\"__src_file\"):\n","        rn = Path(src).stem\n","        dfp = parse_frcnn_jsonloss(part, run_name=rn)\n","        if dfp is not None and len(dfp): rows_training.append(dfp)\n","\n","df_training_all = pd.concat(rows_training, ignore_index=True) if rows_training else pd.DataFrame()\n","print(\"üß™ df_training_all:\", df_training_all.shape)\n","\n","# ---------------------------\n","# 6) ÎßàÏä§ÌÑ∞ Í≤∞Ìï© & Ï†ÄÏû•\n","# ---------------------------\n","df_master = pd.concat([df_training_all, df_sub_rows], ignore_index=True)\n","\n","ordered = [\n","    \"row_type\",\"phase\",\"run_name\",\"fold\",\"model_type\",\"epoch\",\n","    \"train_loss\",\"val_loss\",\"map5095\",\"timestamp\",\"image_id\",\n","    \"num_boxes_final\",\"avg_score_final\",\"max_score_final\",\"min_score_final\",\n","    \"num_boxes_ens\",\"avg_score_ens\",\"max_score_ens\",\"min_score_ens\",\n","    \"score_gap\",\"boxcount_gap\"\n","]\n","for c in ordered:\n","    if c not in df_master.columns: df_master[c]=np.nan\n","df_master = df_master[ordered + [c for c in df_master.columns if c not in ordered]]\n","\n","df_master.to_csv(MASTER_CSV, index=False, encoding=\"utf-8-sig\")\n","\n","print(\"\\n‚úÖ DONE\")\n","print(\" - MASTER_CSV:\", MASTER_CSV, \"shape:\", df_master.shape)\n","print(\" - ÏÉòÌîå ÎØ∏Î¶¨Î≥¥Í∏∞:\")\n","display(df_master.head(10))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":794},"id":"KqcKp1l3PBGr","executionInfo":{"status":"ok","timestamp":1762151568326,"user_tz":-540,"elapsed":7302,"user":{"displayName":"Star Sin","userId":"12579642930462495568"}},"outputId":"c8713229-5c92-4399-f7b4-98a3eee91a16"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["üîß BASE: /content/drive/MyDrive/pill_det/mnt_data\n"," - PATH_SUB_FINAL: /content/drive/MyDrive/pill_det/mnt_data/submission_final.csv\n"," - PATH_SUB_ENS: /content/drive/MyDrive/pill_det/mnt_data/submission_ensemble_ocr.csv\n"," - PATH_FINAL_RES: /content/drive/MyDrive/pill_det/mnt_data/results.csv\n"," - PATH_KFOLD_ZIP: /content/drive/MyDrive/pill_det/mnt_data/all_results_csv.zip\n"," - PATH_LOSS_ZIP: /content/drive/MyDrive/pill_det/mnt_data/loss.zip\n"," - OUT_DIR: /content/drive/MyDrive/pill_det/mnt_data/out\n"," - MASTER_CSV: /content/drive/MyDrive/pill_det/mnt_data/out/analysis_master.csv\n","\n","üì¶ ÏõêÎ≥∏ ÌòïÌÉú\n"," - submission_final: (3233, 8)\n"," - submission_ens  : (3341, 8)\n"," - final results   : (300, 15)\n"," - K-Fold zip     : (791, 16)\n"," - FRCNN loss zip : (7140, 7)\n","\n","üßÆ df_sub_rows: (0, 0)\n","üß™ df_training_all: (8231, 21)\n","\n","‚úÖ DONE\n"," - MASTER_CSV: /content/drive/MyDrive/pill_det/mnt_data/out/analysis_master.csv shape: (8231, 21)\n"," - ÏÉòÌîå ÎØ∏Î¶¨Î≥¥Í∏∞:\n"]},{"output_type":"display_data","data":{"text/plain":["      row_type  phase run_name  fold model_type  epoch  train_loss  val_loss  \\\n","0  train_epoch  kfold  results  None       None    1.0    20.46230       NaN   \n","1  train_epoch  kfold  results  None       None    2.0    12.50269       NaN   \n","2  train_epoch  kfold  results  None       None    3.0     8.07739       NaN   \n","3  train_epoch  kfold  results  None       None    4.0     6.01768       NaN   \n","4  train_epoch  kfold  results  None       None    5.0     5.11035       NaN   \n","5  train_epoch  kfold  results  None       None    6.0     4.64403       NaN   \n","6  train_epoch  kfold  results  None       None    7.0     4.25749       NaN   \n","7  train_epoch  kfold  results  None       None    8.0     3.95353       NaN   \n","8  train_epoch  kfold  results  None       None    9.0     3.81607       NaN   \n","9  train_epoch  kfold  results  None       None   10.0     3.65787       NaN   \n","\n","   map5095     timestamp  ...  num_boxes_final  avg_score_final  \\\n","0  0.00935  1.762152e+09  ...              NaN              NaN   \n","1  0.08987  1.762152e+09  ...              NaN              NaN   \n","2  0.33295  1.762152e+09  ...              NaN              NaN   \n","3  0.58544  1.762152e+09  ...              NaN              NaN   \n","4  0.72451  1.762152e+09  ...              NaN              NaN   \n","5  0.76662  1.762152e+09  ...              NaN              NaN   \n","6  0.79502  1.762152e+09  ...              NaN              NaN   \n","7  0.83328  1.762152e+09  ...              NaN              NaN   \n","8  0.83547  1.762152e+09  ...              NaN              NaN   \n","9  0.85454  1.762152e+09  ...              NaN              NaN   \n","\n","   max_score_final  min_score_final  num_boxes_ens  avg_score_ens  \\\n","0              NaN              NaN            NaN            NaN   \n","1              NaN              NaN            NaN            NaN   \n","2              NaN              NaN            NaN            NaN   \n","3              NaN              NaN            NaN            NaN   \n","4              NaN              NaN            NaN            NaN   \n","5              NaN              NaN            NaN            NaN   \n","6              NaN              NaN            NaN            NaN   \n","7              NaN              NaN            NaN            NaN   \n","8              NaN              NaN            NaN            NaN   \n","9              NaN              NaN            NaN            NaN   \n","\n","   max_score_ens  min_score_ens  score_gap  boxcount_gap  \n","0            NaN            NaN        NaN           NaN  \n","1            NaN            NaN        NaN           NaN  \n","2            NaN            NaN        NaN           NaN  \n","3            NaN            NaN        NaN           NaN  \n","4            NaN            NaN        NaN           NaN  \n","5            NaN            NaN        NaN           NaN  \n","6            NaN            NaN        NaN           NaN  \n","7            NaN            NaN        NaN           NaN  \n","8            NaN            NaN        NaN           NaN  \n","9            NaN            NaN        NaN           NaN  \n","\n","[10 rows x 21 columns]"],"text/html":["\n","  <div id=\"df-344c7419-299e-488f-ac28-33eeace7a37c\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>row_type</th>\n","      <th>phase</th>\n","      <th>run_name</th>\n","      <th>fold</th>\n","      <th>model_type</th>\n","      <th>epoch</th>\n","      <th>train_loss</th>\n","      <th>val_loss</th>\n","      <th>map5095</th>\n","      <th>timestamp</th>\n","      <th>...</th>\n","      <th>num_boxes_final</th>\n","      <th>avg_score_final</th>\n","      <th>max_score_final</th>\n","      <th>min_score_final</th>\n","      <th>num_boxes_ens</th>\n","      <th>avg_score_ens</th>\n","      <th>max_score_ens</th>\n","      <th>min_score_ens</th>\n","      <th>score_gap</th>\n","      <th>boxcount_gap</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>train_epoch</td>\n","      <td>kfold</td>\n","      <td>results</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>1.0</td>\n","      <td>20.46230</td>\n","      <td>NaN</td>\n","      <td>0.00935</td>\n","      <td>1.762152e+09</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>train_epoch</td>\n","      <td>kfold</td>\n","      <td>results</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>2.0</td>\n","      <td>12.50269</td>\n","      <td>NaN</td>\n","      <td>0.08987</td>\n","      <td>1.762152e+09</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>train_epoch</td>\n","      <td>kfold</td>\n","      <td>results</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>3.0</td>\n","      <td>8.07739</td>\n","      <td>NaN</td>\n","      <td>0.33295</td>\n","      <td>1.762152e+09</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>train_epoch</td>\n","      <td>kfold</td>\n","      <td>results</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>4.0</td>\n","      <td>6.01768</td>\n","      <td>NaN</td>\n","      <td>0.58544</td>\n","      <td>1.762152e+09</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>train_epoch</td>\n","      <td>kfold</td>\n","      <td>results</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>5.0</td>\n","      <td>5.11035</td>\n","      <td>NaN</td>\n","      <td>0.72451</td>\n","      <td>1.762152e+09</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>train_epoch</td>\n","      <td>kfold</td>\n","      <td>results</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>6.0</td>\n","      <td>4.64403</td>\n","      <td>NaN</td>\n","      <td>0.76662</td>\n","      <td>1.762152e+09</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>train_epoch</td>\n","      <td>kfold</td>\n","      <td>results</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>7.0</td>\n","      <td>4.25749</td>\n","      <td>NaN</td>\n","      <td>0.79502</td>\n","      <td>1.762152e+09</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>train_epoch</td>\n","      <td>kfold</td>\n","      <td>results</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>8.0</td>\n","      <td>3.95353</td>\n","      <td>NaN</td>\n","      <td>0.83328</td>\n","      <td>1.762152e+09</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>train_epoch</td>\n","      <td>kfold</td>\n","      <td>results</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>9.0</td>\n","      <td>3.81607</td>\n","      <td>NaN</td>\n","      <td>0.83547</td>\n","      <td>1.762152e+09</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>train_epoch</td>\n","      <td>kfold</td>\n","      <td>results</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>10.0</td>\n","      <td>3.65787</td>\n","      <td>NaN</td>\n","      <td>0.85454</td>\n","      <td>1.762152e+09</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10 rows √ó 21 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-344c7419-299e-488f-ac28-33eeace7a37c')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-344c7419-299e-488f-ac28-33eeace7a37c button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-344c7419-299e-488f-ac28-33eeace7a37c');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-dfc6093a-f60f-4fd3-9de8-6f3a4d72f7c1\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dfc6093a-f60f-4fd3-9de8-6f3a4d72f7c1')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-dfc6093a-f60f-4fd3-9de8-6f3a4d72f7c1 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe"}},"metadata":{}}]},{"cell_type":"code","source":["# ============================\n","# ONE-CELL: ÌÜµÌï© Î°úÎìú ‚Üí Ï†ïÍ∑úÌôî ‚Üí ÏãúÍ∞ÅÌôî(Ï†ÄÏû•X)\n","# ============================\n","import os, zipfile, json, time, re, math\n","from pathlib import Path\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# --------------------------------\n","# 0) Í≤ΩÎ°ú ÏÑ§Ï†ï (ÌïÑÏöîÏãú Ïó¨Í∏∞Î•º Î∞îÍøî)\n","# --------------------------------\n","try:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","except Exception:\n","    pass\n","\n","DRIVE_BASE = \"/content/drive/MyDrive/pill_det/mnt_data\"\n","PATH_SUB_FINAL = f\"{DRIVE_BASE}/submission_final.csv\"\n","PATH_SUB_ENS   = f\"{DRIVE_BASE}/submission_ensemble_ocr.csv\"\n","PATH_FINAL_RES = f\"{DRIVE_BASE}/results.csv\"\n","PATH_KFOLD_ZIP = f\"{DRIVE_BASE}/all_results_csv.zip\"\n","PATH_LOSS_ZIP  = f\"{DRIVE_BASE}/loss.zip\"\n","\n","print(\"BASE:\", DRIVE_BASE)\n","print(\" - PATH_SUB_FINAL:\", PATH_SUB_FINAL)\n","print(\" - PATH_SUB_ENS:\", PATH_SUB_ENS)\n","print(\" - PATH_FINAL_RES:\", PATH_FINAL_RES)\n","print(\" - PATH_KFOLD_ZIP:\", PATH_KFOLD_ZIP)\n","print(\" - PATH_LOSS_ZIP:\", PATH_LOSS_ZIP)\n","\n","# --------------------------------\n","# 1) Ïú†Ìã∏\n","# --------------------------------\n","def safe_read_csv(path, **kwargs):\n","    if not os.path.isfile(path):\n","        return None\n","    try:\n","        return pd.read_csv(path, **kwargs)\n","    except Exception:\n","        for sep in [\",\",\";\",\"\\t\",\" \"]:\n","            try:\n","                return pd.read_csv(path, sep=sep)\n","            except Exception:\n","                continue\n","        for enc in [\"utf-8-sig\",\"cp949\",\"euc-kr\",\"latin-1\"]:\n","            try:\n","                return pd.read_csv(path, encoding=enc)\n","            except Exception:\n","                continue\n","    return None\n","\n","def extract_all_from_zip(zip_path, exts=None):\n","    if not os.path.isfile(zip_path):\n","        return []\n","    out_dir = os.path.join(os.path.dirname(zip_path), \"_extracted_tmp\")\n","    os.makedirs(out_dir, exist_ok=True)\n","    with zipfile.ZipFile(zip_path, 'r') as z:\n","        z.extractall(out_dir)\n","    if exts is None:\n","        return [str(p) for p in Path(out_dir).glob(\"**/*\")]\n","    out = []\n","    for ext in exts:\n","        out.extend(Path(out_dir).glob(f\"**/*{ext}\"))\n","    return [str(p) for p in out]\n","\n","def pick_metric_column(cols):\n","    # YOLO results.csv mAP Ïö∞ÏÑ†ÏàúÏúÑ\n","    for c in cols:\n","        if \"mAP\" in c and (\"50-95\" in c or \"50:95\" in c):\n","            return c\n","    for c in cols:\n","        if \"mAP\" in c and \"50\" in c:\n","            return c\n","    for c in cols:\n","        if \"mAP\" in c:\n","            return c\n","    return None\n","\n","def parse_yolo_results(df_res: pd.DataFrame, run_name: str, phase: str):\n","    \"\"\"YOLO results.csv ‚Üí epochÎ≥Ñ ÌëúÏ§ÄÌôî (train_loss=box+cls+dfl Ìï©)\"\"\"\n","    if df_res is None or len(df_res)==0:\n","        return None\n","    cols = list(df_res.columns)\n","    loss_cols = [c for c in cols if \"loss\" in c.lower()]\n","    map_col = pick_metric_column(cols)\n","\n","    # run_nameÏóêÏÑú fold, model Ïú†Ï∂î(ÏûàÏúºÎ©¥)\n","    fold, model = None, None\n","    m = re.match(r\"^fold(\\d+)_([A-Za-z0-9\\-]+)\", run_name)\n","    if m:\n","        try:\n","            fold = int(m.group(1))\n","        except:\n","            fold = None\n","        model = m.group(2)\n","\n","    rows = []\n","    for _, row in df_res.iterrows():\n","        ep = pd.to_numeric(row.get(\"epoch\", np.nan), errors=\"coerce\")\n","        # loss Ìï©\n","        loss_sum, saw = 0.0, False\n","        for lc in loss_cols:\n","            v = pd.to_numeric(row.get(lc, np.nan), errors=\"coerce\")\n","            if pd.notna(v):\n","                loss_sum += float(v)\n","                saw = True\n","        if not saw:\n","            loss_sum = np.nan\n","        # mAP\n","        m5095 = np.nan\n","        if map_col and map_col in row:\n","            m5095 = pd.to_numeric(row[map_col], errors=\"coerce\")\n","\n","        rows.append({\n","            \"row_type\": \"train_epoch\",\n","            \"phase\": phase,\n","            \"run_name\": run_name,\n","            \"fold\": fold,\n","            \"model_type\": model,\n","            \"epoch\": float(ep) if pd.notna(ep) else np.nan,\n","            \"train_loss\": loss_sum,\n","            \"val_loss\": np.nan,\n","            \"map5095\": float(m5095) if pd.notna(m5095) else np.nan,\n","            \"timestamp\": time.time(),\n","            # submission ÎπÑÍµêÏö© ÏπºÎüºÎì§ÏùÄ ÎπàÏπ∏\n","            \"image_id\": np.nan,\n","            \"num_boxes_final\": np.nan, \"avg_score_final\": np.nan, \"max_score_final\": np.nan, \"min_score_final\": np.nan,\n","            \"num_boxes_ens\": np.nan,   \"avg_score_ens\": np.nan,   \"max_score_ens\": np.nan,   \"min_score_ens\": np.nan,\n","            \"score_gap\": np.nan, \"boxcount_gap\": np.nan\n","        })\n","    return pd.DataFrame(rows)\n","\n","def parse_submission_df(df_sub: pd.DataFrame, prefix: str):\n","    \"\"\"Ï†úÏ∂ú CSV(image_id, PredictionString) ‚Üí Ïù¥ÎØ∏ÏßÄÎ≥Ñ ÌÜµÍ≥Ñ/ÌèâÌÉÑÌôî\"\"\"\n","    if df_sub is None or \"image_id\" not in df_sub.columns or \"PredictionString\" not in df_sub.columns:\n","        return None, None\n","    rows_stat, rows_flat = [], []\n","    for _, r in df_sub.iterrows():\n","        img_id = str(r[\"image_id\"])\n","        pred = r[\"PredictionString\"]\n","        nbox = 0\n","        avg_sc = max_sc = min_sc = 0.0\n","        scores = []\n","        if isinstance(pred, str) and pred.strip():\n","            parts = pred.strip().split()\n","            chunks = [parts[i:i+6] for i in range(0, len(parts), 6)]\n","            for ch in chunks:\n","                if len(ch) < 6:\n","                    continue\n","                cname = ch[0]\n","                s = pd.to_numeric(ch[1], errors=\"coerce\")\n","                try:\n","                    x1,y1,x2,y2 = map(float, ch[2:6])\n","                except:\n","                    x1=y1=x2=y2=np.nan\n","                rows_flat.append({\n","                    \"image_id\": img_id,\n","                    \"cls_name\": cname,\n","                    \"score\": float(s) if pd.notna(s) else np.nan,\n","                    \"x1\": x1, \"y1\": y1, \"x2\": x2, \"y2\": y2,\n","                    \"source_submission\": prefix\n","                })\n","                if pd.notna(s): scores.append(float(s))\n","            nbox = len(chunks)\n","            if scores:\n","                avg_sc = float(np.nanmean(scores))\n","                max_sc = float(np.nanmax(scores))\n","                min_sc = float(np.nanmin(scores))\n","        rows_stat.append({\n","            \"image_id\": img_id,\n","            f\"num_boxes_{prefix}\": nbox,\n","            f\"avg_score_{prefix}\": avg_sc,\n","            f\"max_score_{prefix}\": max_sc,\n","            f\"min_score_{prefix}\": min_sc,\n","        })\n","    return pd.DataFrame(rows_stat).drop_duplicates(subset=[\"image_id\"]), (pd.DataFrame(rows_flat) if rows_flat else None)\n","\n","def load_json_rows_from_zip(zip_path: str):\n","    \"\"\"loss.zip Ïïà Ïó¨Îü¨ JSON ‚Üí Îã®Ïùº DF (epoch/mAP/box,cls,dfl, train_loss Ìï©ÏÇ∞)\"\"\"\n","    if not os.path.isfile(zip_path):\n","        return None\n","    rows = []\n","    with zipfile.ZipFile(zip_path, 'r') as z:\n","        for name in z.namelist():\n","            if not name.lower().endswith(\".json\"):\n","                continue\n","            with z.open(name) as f:\n","                try:\n","                    data = json.load(f)\n","                except Exception:\n","                    continue\n","            run_name = Path(name).stem\n","            m = re.search(r\"fold(\\d+)\", run_name)\n","            fold = int(m.group(1)) if m else None\n","\n","            if isinstance(data, list):\n","                recs = data\n","            elif isinstance(data, dict) and \"history\" in data and isinstance(data[\"history\"], list):\n","                recs = data[\"history\"]\n","            else:\n","                recs = [data]\n","\n","            for r in recs:\n","                epoch = pd.to_numeric(r.get(\"epoch\", np.nan), errors=\"coerce\")\n","                box_loss = pd.to_numeric(r.get(\"box_loss\", np.nan), errors=\"coerce\")\n","                cls_loss = pd.to_numeric(r.get(\"cls_loss\", np.nan), errors=\"coerce\")\n","                dfl_loss = pd.to_numeric(r.get(\"dfl_loss\", np.nan), errors=\"coerce\")\n","                # mAP ÌëúÍ∏∞ Îã§ÏñëÏÑ± ÎåÄÏùë\n","                m5095 = r.get(\"mAP_0.5_0.95\", r.get(\"mAP_0.5-0.95\", r.get(\"metrics/mAP50-95(B)\", np.nan)))\n","                m5095 = pd.to_numeric(m5095, errors=\"coerce\")\n","                m50 = pd.to_numeric(r.get(\"mAP_0.5\", np.nan), errors=\"coerce\")\n","                loss_sum = np.nan\n","                parts = [box_loss, cls_loss, dfl_loss]\n","                if np.isfinite(parts).all():\n","                    loss_sum = float(np.nansum(parts))\n","                rows.append({\n","                    \"row_type\": \"train_epoch\",\n","                    \"phase\": \"frcnn_or_yolojson\",\n","                    \"run_name\": run_name,\n","                    \"fold\": fold,\n","                    \"model_type\": None,\n","                    \"epoch\": float(epoch) if pd.notna(epoch) else np.nan,\n","                    \"train_loss\": loss_sum,\n","                    \"val_loss\": np.nan,\n","                    \"map5095\": float(m5095) if pd.notna(m5095) else np.nan,\n","                    \"timestamp\": time.time(),\n","                    \"image_id\": np.nan,\n","                    \"num_boxes_final\": np.nan, \"avg_score_final\": np.nan, \"max_score_final\": np.nan, \"min_score_final\": np.nan,\n","                    \"num_boxes_ens\": np.nan,   \"avg_score_ens\": np.nan,   \"max_score_ens\": np.nan,   \"min_score_ens\": np.nan,\n","                    \"score_gap\": np.nan, \"boxcount_gap\": np.nan,\n","                    \"mAP50\": float(m50) if pd.notna(m50) else np.nan,\n","                })\n","    return pd.DataFrame(rows) if rows else None\n","\n","# --------------------------------\n","# 2) ÏõêÏ≤ú Î°úÎìú\n","# --------------------------------\n","df_sub_final = safe_read_csv(PATH_SUB_FINAL)\n","df_sub_ens   = safe_read_csv(PATH_SUB_ENS)\n","df_final_run = safe_read_csv(PATH_FINAL_RES)\n","\n","# ZIP Ïïà K-Fold CSVÎì§\n","kfold_csv_paths = extract_all_from_zip(PATH_KFOLD_ZIP, exts=[\".csv\"])\n","df_kfold_all = []\n","for p in kfold_csv_paths:\n","    tmp = safe_read_csv(p)\n","    if tmp is not None and len(tmp):\n","        tmp[\"__src_file\"] = Path(p).name\n","        df_kfold_all.append(tmp)\n","df_kfold_all = pd.concat(df_kfold_all, ignore_index=True) if df_kfold_all else None\n","\n","# loss.zip (Ïó¨Îü¨ json)\n","df_loss_zip = load_json_rows_from_zip(PATH_LOSS_ZIP)\n","\n","print(\"ÏõêÎ≥∏ ÌÅ¨Í∏∞ Ï≤¥ÌÅ¨\")\n","print(\" - submission_final:\", None if df_sub_final is None else df_sub_final.shape)\n","print(\" - submission_ens  :\", None if df_sub_ens   is None else df_sub_ens.shape)\n","print(\" - final results   :\", None if df_final_run is None else df_final_run.shape)\n","print(\" - K-Fold zip      :\", None if df_kfold_all is None else df_kfold_all.shape)\n","print(\" - loss.zip (json) :\", None if df_loss_zip  is None else df_loss_zip.shape)\n","\n","# --------------------------------\n","# 3) Ï†úÏ∂ú CSV ‚Üí Ïù¥ÎØ∏ÏßÄÎ≥Ñ ÌÜµÍ≥Ñ Î≥ëÌï©\n","# --------------------------------\n","sub_final_stats, _ = parse_submission_df(df_sub_final, prefix=\"final\")\n","sub_ens_stats,   _ = parse_submission_df(df_sub_ens,   prefix=\"ens\")\n","\n","if sub_final_stats is None and sub_ens_stats is None:\n","    df_sub_merged = pd.DataFrame()\n","else:\n","    if sub_final_stats is None:\n","        df_sub_merged = sub_ens_stats.copy()\n","    elif sub_ens_stats is None:\n","        df_sub_merged = sub_final_stats.copy()\n","    else:\n","        df_sub_merged = sub_final_stats.merge(sub_ens_stats, on=\"image_id\", how=\"outer\")\n","\n","    if \"avg_score_final\" in df_sub_merged.columns and \"avg_score_ens\" in df_sub_merged.columns:\n","        df_sub_merged[\"score_gap\"] = df_sub_merged[\"avg_score_ens\"] - df_sub_merged[\"avg_score_final\"]\n","    if \"num_boxes_final\" in df_sub_merged.columns and \"num_boxes_ens\" in df_sub_merged.columns:\n","        df_sub_merged[\"boxcount_gap\"] = df_sub_merged[\"num_boxes_ens\"] - df_sub_merged[\"num_boxes_final\"]\n","\n","def wrap_submission_rows(df_in):\n","    if df_in is None or len(df_in)==0:\n","        return pd.DataFrame()\n","    out = df_in.copy()\n","    out[\"row_type\"]   = \"submission_image\"\n","    out[\"phase\"]      = \"inference\"\n","    out[\"run_name\"]   = \"compare_final_vs_ens\"\n","    out[\"fold\"]       = np.nan\n","    out[\"model_type\"] = \"inference_compare\"\n","    out[\"epoch\"]      = np.nan\n","    out[\"train_loss\"] = np.nan\n","    out[\"val_loss\"]   = np.nan\n","    out[\"map5095\"]    = np.nan\n","    out[\"timestamp\"]  = time.time()\n","    for col in [\n","        \"num_boxes_final\",\"avg_score_final\",\"max_score_final\",\"min_score_final\",\n","        \"num_boxes_ens\",\"avg_score_ens\",\"max_score_ens\",\"min_score_ens\",\n","        \"score_gap\",\"boxcount_gap\"\n","    ]:\n","        if col not in out.columns:\n","            out[col] = np.nan\n","    return out.reset_index(drop=True)\n","\n","df_sub_rows = wrap_submission_rows(df_sub_merged)\n","\n","# --------------------------------\n","# 4) ÌïôÏäµ Î°úÍ∑∏ ÌëúÏ§ÄÌôî & Í≤∞Ìï© (K-Fold CSV + Final CSV + loss.zip JSON)\n","# --------------------------------\n","rows_training = []\n","\n","# K-Fold: Í∞Å ÌååÏùº(__src_file)Î≥ÑÎ°ú run_name Ï∂îÏ†ïÌï¥ÏÑú parse\n","if df_kfold_all is not None:\n","    for src, part in df_kfold_all.groupby(\"__src_file\"):\n","        rn = Path(src).stem\n","        dfp = parse_yolo_results(part, run_name=rn, phase=\"kfold\")\n","        if dfp is not None and len(dfp):\n","            rows_training.append(dfp)\n","\n","# Final results.csv\n","if df_final_run is not None and len(df_final_run):\n","    rn_final = \"final_overfit\"  # Ïù¥Î¶ÑÏùÄ ÏûêÏú†\n","    dfp = parse_yolo_results(df_final_run, run_name=rn_final, phase=\"final_overfit\")\n","    if dfp is not None and len(dfp):\n","        rows_training.append(dfp)\n","\n","# loss.zip JSON ÌÜµÌï©(Ïó¨Îü¨ run Ìè¨Ìï® Í∞ÄÎä•)\n","if df_loss_zip is not None and len(df_loss_zip):\n","    rows_training.append(df_loss_zip)\n","\n","df_training_all = pd.concat(rows_training, ignore_index=True) if rows_training else pd.DataFrame()\n","\n","# Master Ìï©ÏπòÍ∏∞\n","df_master = pd.concat([df_training_all, df_sub_rows], ignore_index=True)\n","print(\"\\nÌï©Ï≥êÏßÑ df_master:\", df_master.shape)\n","\n","# --------------------------------\n","# 5) Í∑∏ÎûòÌîÑ(Ï†ÄÏû•X) ‚Äî Ìïú Ï§Ñ 3Í∞úÏî©\n","#    (A) Epoch vs mAP50-95 (line, runÎ≥Ñ)\n","#    (B) Epoch vs train_loss (line, runÎ≥Ñ)  ‚Äª lossÎäî YOLO Ìï©(box+cls+dfl)\n","#    (C) Ï†úÏ∂ú ÎπÑÍµê: score_gap, boxcount_gap ÌûàÏä§ÌÜ†Í∑∏Îû®\n","#    (D) Ï†úÏ∂ú ÎπÑÍµê: avg_score_final vs avg_score_ens, num_boxes_final vs num_boxes_ens ÏÇ∞Ï†êÎèÑ\n","# --------------------------------\n","\n","def three_per_row(runs):\n","    \"\"\"runs Î¶¨Ïä§Ìä∏Î•º 3Í∞úÏî© ÎÅäÎäî Ï†úÎÑàÎ†àÏù¥ÌÑ∞\"\"\"\n","    for i in range(0, len(runs), 3):\n","        yield runs[i:i+3]\n","\n","# (A) Epoch vs mAP50-95\n","df_train_map = df_master[(df_master[\"row_type\"]==\"train_epoch\") & df_master[\"map5095\"].notna()]\n","if len(df_train_map):\n","    run_list = list(df_train_map[\"run_name\"].dropna().unique())\n","    for group in three_per_row(run_list):\n","        plt.figure(figsize=(18,4))\n","        for i, rn in enumerate(group, start=1):\n","            part = df_train_map[df_train_map[\"run_name\"]==rn].dropna(subset=[\"epoch\",\"map5095\"])\n","            plt.subplot(1,3,i)\n","            plt.plot(part[\"epoch\"], part[\"map5095\"], marker=\"o\")\n","            plt.title(f\"[{rn}] Epoch vs mAP50-95\")\n","            plt.xlabel(\"Epoch\"); plt.ylabel(\"mAP50-95\"); plt.grid(True, alpha=0.3)\n","        plt.tight_layout()\n","        plt.show()\n","\n","# (B) Epoch vs train_loss (YOLO Ìï©)\n","df_train_loss = df_master[(df_master[\"row_type\"]==\"train_epoch\") & df_master[\"train_loss\"].notna()]\n","if len(df_train_loss):\n","    run_list = list(df_train_loss[\"run_name\"].dropna().unique())\n","    for group in three_per_row(run_list):\n","        plt.figure(figsize=(18,4))\n","        for i, rn in enumerate(group, start=1):\n","            part = df_train_loss[df_train_loss[\"run_name\"]==rn].dropna(subset=[\"epoch\",\"train_loss\"])\n","            plt.subplot(1,3,i)\n","            plt.plot(part[\"epoch\"], part[\"train_loss\"], marker=\"o\")\n","            plt.title(f\"[{rn}] Epoch vs train_loss\")\n","            plt.xlabel(\"Epoch\"); plt.ylabel(\"train_loss\"); plt.grid(True, alpha=0.3)\n","        plt.tight_layout()\n","        plt.show()\n","\n","# (C) Ï†úÏ∂ú ÎπÑÍµê ÌûàÏä§ÌÜ†Í∑∏Îû® (OCR+ENS - FINAL)\n","df_inf = df_master[df_master[\"row_type\"]==\"submission_image\"]\n","if len(df_inf):\n","    # score gap\n","    if \"score_gap\" in df_inf.columns and df_inf[\"score_gap\"].notna().any():\n","        plt.figure(figsize=(6,4))\n","        plt.hist(df_inf[\"score_gap\"].dropna(), bins=40)\n","        plt.title(\"Avg Score Gap (Ensemble+OCR - Final)\")\n","        plt.xlabel(\"avg_score_ens - avg_score_final\"); plt.ylabel(\"count\")\n","        plt.grid(True, alpha=0.3)\n","        plt.tight_layout()\n","        plt.show()\n","    # boxcount gap\n","    if \"boxcount_gap\" in df_inf.columns and df_inf[\"boxcount_gap\"].notna().any():\n","        plt.figure(figsize=(6,4))\n","        plt.hist(df_inf[\"boxcount_gap\"].dropna(), bins=40)\n","        plt.title(\"Box Count Gap (Ensemble - Final)\")\n","        plt.xlabel(\"num_boxes_ens - num_boxes_final\"); plt.ylabel(\"count\")\n","        plt.grid(True, alpha=0.3)\n","        plt.tight_layout()\n","        plt.show()\n","\n","# (D) Ï†úÏ∂ú ÎπÑÍµê ÏÇ∞Ï†êÎèÑ\n","if len(df_inf):\n","    # avg score scatter\n","    if set([\"avg_score_final\",\"avg_score_ens\"]).issubset(df_inf.columns):\n","        s = df_inf[[\"avg_score_final\",\"avg_score_ens\"]].dropna()\n","        if len(s):\n","            plt.figure(figsize=(5,5))\n","            plt.scatter(s[\"avg_score_final\"], s[\"avg_score_ens\"], s=8)\n","            lim = [min(s.min())*0.95, max(s.max())*1.05]\n","            plt.plot(lim, lim)  # y=x Í∏∞Ï§ÄÏÑ†\n","            plt.xlim(lim); plt.ylim(lim)\n","            plt.xlabel(\"avg_score_final\"); plt.ylabel(\"avg_score_ens\")\n","            plt.title(\"Avg Score: Final vs Ensemble+OCR\")\n","            plt.grid(True, alpha=0.3)\n","            plt.tight_layout()\n","            plt.show()\n","    # box count scatter\n","    if set([\"num_boxes_final\",\"num_boxes_ens\"]).issubset(df_inf.columns):\n","        s = df_inf[[\"num_boxes_final\",\"num_boxes_ens\"]].dropna()\n","        if len(s):\n","            plt.figure(figsize=(5,5))\n","            plt.scatter(s[\"num_boxes_final\"], s[\"num_boxes_ens\"], s=8)\n","            lim = [min(s.min())*0.95, max(s.max())*1.05]\n","            plt.plot(lim, lim)\n","            plt.xlim(lim); plt.ylim(lim)\n","            plt.xlabel(\"num_boxes_final\"); plt.ylabel(\"num_boxes_ens\")\n","            plt.title(\"Box Count: Final vs Ensemble\")\n","            plt.grid(True, alpha=0.3)\n","            plt.tight_layout()\n","            plt.show()\n","\n","print(\"\\nüéØ Í∑∏ÎûòÌîÑ ÌëúÏãú ÏôÑÎ£å\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1HeNy71ESFLF4X3bs4Lg7lYq34B_Z35aO"},"id":"JcSfoHDSXSI-","executionInfo":{"status":"ok","timestamp":1762158749493,"user_tz":-540,"elapsed":85610,"user":{"displayName":"Star Sin","userId":"12579642930462495568"}},"outputId":"d6ef14ee-9a96-492b-b361-a0037ade01c8"},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"M1YLt3Yr11hG"},"execution_count":null,"outputs":[]}]}