{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyMfgGZCiW5fDt5Pd0CHt8Ws"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install kaggle"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mzNY66b26l1r","executionInfo":{"status":"ok","timestamp":1761031338217,"user_tz":-540,"elapsed":7219,"user":{"displayName":"Star Sin","userId":"12579642930462495568"}},"outputId":"aa7924ef-5c0f-4db4-8884-f8d4d30e7d7f"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.2.0)\n","Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.10.5)\n","Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n","Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n","Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n","Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n","Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n","Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n"]}]},{"cell_type":"code","source":["!sudo apt-get install -y fonts-nanum\n","!sudo fc-cache -fv\n","!rm ~/.cache/matplotlib -rf\n","\n","!apt-get update -qq\n","!apt-get install fonts-nanum* -qq\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.font_manager as fm\n","import warnings\n","warnings.filterwarnings(action='ignore')\n","\n","path = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf' # ë‚˜ëˆ” ê³ ë”•\n","font_name = fm.FontProperties(fname=path, size=10).get_name() # ê¸°ë³¸ í°íŠ¸ ì‚¬ì´ì¦ˆ : 10\n","plt.rc('font', family=font_name)\n","\n","fm.fontManager.addfont(path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"81jdY9yc_A4D","executionInfo":{"status":"ok","timestamp":1761031364510,"user_tz":-540,"elapsed":23896,"user":{"displayName":"Star Sin","userId":"12579642930462495568"}},"outputId":"81538511-671e-4347-9284-0dd5c6ddd82d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following NEW packages will be installed:\n","  fonts-nanum\n","0 upgraded, 1 newly installed, 0 to remove and 38 not upgraded.\n","Need to get 10.3 MB of archives.\n","After this operation, 34.1 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-nanum all 20200506-1 [10.3 MB]\n","Fetched 10.3 MB in 1s (9,185 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package fonts-nanum.\n","(Reading database ... 126675 files and directories currently installed.)\n","Preparing to unpack .../fonts-nanum_20200506-1_all.deb ...\n","Unpacking fonts-nanum (20200506-1) ...\n","Setting up fonts-nanum (20200506-1) ...\n","Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n","/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n","/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n","/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n","/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n","/usr/share/fonts/truetype/nanum: caching, new cache contents: 12 fonts, 0 dirs\n","/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n","/root/.local/share/fonts: skipping, no such directory\n","/root/.fonts: skipping, no such directory\n","/usr/share/fonts/truetype: skipping, looped directory detected\n","/usr/share/fonts/truetype/humor-sans: skipping, looped directory detected\n","/usr/share/fonts/truetype/liberation: skipping, looped directory detected\n","/usr/share/fonts/truetype/nanum: skipping, looped directory detected\n","/var/cache/fontconfig: cleaning cache directory\n","/root/.cache/fontconfig: not cleaning non-existent cache directory\n","/root/.fontconfig: not cleaning non-existent cache directory\n","fc-cache: succeeded\n","W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n","Selecting previously unselected package fonts-nanum-coding.\n","(Reading database ... 126698 files and directories currently installed.)\n","Preparing to unpack .../fonts-nanum-coding_2.5-3_all.deb ...\n","Unpacking fonts-nanum-coding (2.5-3) ...\n","Selecting previously unselected package fonts-nanum-eco.\n","Preparing to unpack .../fonts-nanum-eco_1.000-7_all.deb ...\n","Unpacking fonts-nanum-eco (1.000-7) ...\n","Selecting previously unselected package fonts-nanum-extra.\n","Preparing to unpack .../fonts-nanum-extra_20200506-1_all.deb ...\n","Unpacking fonts-nanum-extra (20200506-1) ...\n","Setting up fonts-nanum-extra (20200506-1) ...\n","Setting up fonts-nanum-coding (2.5-3) ...\n","Setting up fonts-nanum-eco (1.000-7) ...\n","Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n"]}]},{"cell_type":"code","source":["import os, json, math, random, zipfile\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import matplotlib.patches as patches\n","from kaggle.api.kaggle_api_extended import KaggleApi\n","import torch"],"metadata":{"id":"9TJWJHWFKSto","executionInfo":{"status":"ok","timestamp":1761031375308,"user_tz":-540,"elapsed":4024,"user":{"displayName":"Star Sin","userId":"12579642930462495568"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":8,"metadata":{"id":"sqbmVAvbb0Bs","executionInfo":{"status":"ok","timestamp":1761031434460,"user_tz":-540,"elapsed":33126,"user":{"displayName":"Star Sin","userId":"12579642930462495568"}}},"outputs":[],"source":["os.environ['KAGGLE_USERNAME'] = 'starsin'\n","os.environ['KAGGLE_KEY'] = 'ff559a02afd29d67f19bc4001d5a69f7'\n","\n","api = KaggleApi()\n","api.authenticate()\n","\n","\n","# 2. ëŒ€íšŒ ë°ì´í„° ë‹¤ìš´ë¡œë“œ\n","competition_name = \"ai05-level1-project\"\n","api.competition_download_files(competition_name, path=\"./data\")"]},{"cell_type":"code","source":["zip_path = \"./data/ai05-level1-project.zip\"\n","extract_dir = \"./data/ai05-level1-project\"\n","\n","os.makedirs(extract_dir, exist_ok=True)\n","\n","with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n","    zip_ref.extractall(extract_dir)"],"metadata":{"id":"rgyHtMs76yaB","executionInfo":{"status":"ok","timestamp":1761031455605,"user_tz":-540,"elapsed":10731,"user":{"displayName":"Star Sin","userId":"12579642930462495568"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["- ë°ì´í„° ì˜ˆì‹œ\n","  - K-003351-016232-020014_0_2_0_2_75_000_200.png = ì´ë¯¸ì§€\n","  - K-003351-016232-020014 = ì–´ë…¸í…Œì´ì…˜\n","    - K-003351-016232-020014_0_2_0_2_75_000_200.json = ì–´ë…¸í…Œì´ì…˜ ì •ë³´ë“¤ì´ ì—¬ê¸°ì— ë“¤ì–´ìˆìŒ\n","\n"],"metadata":{"id":"cPqBOIODJyvE"}},{"cell_type":"code","source":["# =========================\n","# ì„¤ì •\n","# =========================\n","base_path = \"./data/ai05-level1-project\"\n","train_img_dir = os.path.join(base_path, \"train_images\")\n","train_ann_dir = os.path.join(base_path, \"train_annotations\")\n","\n","NUM_SAMPLES = 10      # ë¬´ì‘ìœ„ë¡œ ë³¼ ì´ë¯¸ì§€ ê°œìˆ˜\n","RANDOM_SEED = 42      # ì¬í˜„ì„±ì„ ìœ„í•´ ê³ ì •\n","IOU_NMS_THR = 0.6     # ì¤‘ë³µ ë°•ìŠ¤ ì œê±° ì„ê³„ê°’ (0.5~0.7 ê¶Œì¥)"],"metadata":{"id":"gAgdyTB4KRHo","executionInfo":{"status":"ok","timestamp":1761031466414,"user_tz":-540,"elapsed":11,"user":{"displayName":"Star Sin","userId":"12579642930462495568"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def iou(box1, box2):\n","    x1,y1,w1,h1 = box1\n","    x2,y2,w2,h2 = box2\n","    xa, ya = max(x1,x2), max(y1,y2)\n","    xb, yb = min(x1+w1, x2+w2), min(y1+h1, y2+h2)\n","    inter = max(0, xb-xa) * max(0, yb-ya)\n","    a1 = w1*h1; a2 = w2*h2\n","    union = a1 + a2 - inter + 1e-9\n","    return inter/union\n","\n","def nms_by_iou(anns, iou_thr=0.5):\n","    kept = []\n","    for a in anns:\n","        ok = True\n","        for b in kept:\n","            if iou(a.get(\"bbox\", [0,0,0,0]), b.get(\"bbox\", [0,0,0,0])) > iou_thr:\n","                ok = False\n","                break\n","        if ok:\n","            kept.append(a)\n","    return kept"],"metadata":{"id":"lSFdBisc7GCM","executionInfo":{"status":"ok","timestamp":1761031468187,"user_tz":-540,"elapsed":2,"user":{"displayName":"Star Sin","userId":"12579642930462495568"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def collect_coco_for_image(ann_dir, image_file):\n","    merged = {\"images\": [], \"annotations\": [], \"categories\": {}}\n","    image_obj = None\n","    ann_id = 1\n","\n","    for dp,_,files in os.walk(ann_dir):\n","        for f in files:\n","            if not f.lower().endswith(\".json\"):\n","                continue\n","            jp = os.path.join(dp,f)\n","            with open(jp,\"r\") as fh:\n","                j = json.load(fh)\n","\n","            images = j.get(\"images\", [])\n","            anns   = j.get(\"annotations\", [])\n","            cats   = j.get(\"categories\", [])\n","\n","            for c in cats:\n","                merged[\"categories\"][c[\"id\"]] = c\n","\n","            matched_ids = []\n","            for im in images:\n","                fn = os.path.basename(im.get(\"file_name\", \"\") or im.get(\"imgfile\",\"\"))\n","                if fn == image_file:\n","                    matched_ids.append(im[\"id\"])\n","                    if image_obj is None:\n","                        image_obj = {\n","                            \"id\": im[\"id\"],\n","                            \"file_name\": image_file,\n","                            \"width\": im.get(\"width\"),\n","                            \"height\": im.get(\"height\")\n","                        }\n","\n","            for a in anns:\n","                if matched_ids and a.get(\"image_id\") in matched_ids:\n","                    new_a = dict(a)\n","                    new_a[\"id\"] = ann_id; ann_id += 1\n","                    merged[\"annotations\"].append(new_a)\n","\n","    merged[\"images\"] = [image_obj] if image_obj else []\n","    merged[\"categories\"] = list(merged[\"categories\"].values())\n","    return merged"],"metadata":{"id":"0blUmuhGKlNE","executionInfo":{"status":"ok","timestamp":1761031469777,"user_tz":-540,"elapsed":2,"user":{"displayName":"Star Sin","userId":"12579642930462495568"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def count_jsons_for_image(ann_dir, image_file):\n","    count = 0\n","    target_json_name = image_file.replace(\".png\", \".json\")\n","    found_paths = []\n","    for dp,_,files in os.walk(ann_dir):\n","        for f in files:\n","            if f.lower().endswith(\".json\") and target_json_name in f:\n","                count += 1\n","                found_paths.append(os.path.join(dp, f))\n","    return count, found_paths"],"metadata":{"id":"eg0O_UsfDeiO","executionInfo":{"status":"ok","timestamp":1761031471687,"user_tz":-540,"elapsed":2,"user":{"displayName":"Star Sin","userId":"12579642930462495568"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["def draw_merged(merged, image_path, subtitle=\"\"):\n","    img = np.array(Image.open(image_path).convert(\"RGB\"))\n","    fig, ax = plt.subplots(figsize=(10,10))\n","    ax.imshow(img); ax.axis(\"off\")\n","\n","    cat_map = {c[\"id\"]: c.get(\"name\", str(c[\"id\"])) for c in merged[\"categories\"]}\n","\n","    anns = merged[\"annotations\"]\n","    if anns:\n","        anns = nms_by_iou(anns, iou_thr=IOU_NMS_THR)\n","\n","    for a in anns:\n","        bbox = a.get(\"bbox\")\n","        if not bbox or len(bbox) != 4:\n","            continue\n","        x,y,w,h = bbox\n","        rect = patches.Rectangle((x,y), w,h, fill=False, linewidth=2)\n","        ax.add_patch(rect)\n","        label = cat_map.get(a.get(\"category_id\"), str(a.get(\"category_id\")))\n","        ax.text(x, max(0,y-5), label, fontsize=9, backgroundcolor=\"white\")\n","\n","    ttl = os.path.basename(image_path)\n","    if subtitle:\n","        ttl += f\"\\n{subtitle}\"\n","    plt.title(ttl)\n","    plt.show()"],"metadata":{"id":"85TecfYKKnQj","executionInfo":{"status":"ok","timestamp":1761031472342,"user_tz":-540,"elapsed":8,"user":{"displayName":"Star Sin","userId":"12579642930462495568"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# ì´ë¯¸ì§€ í›„ë³´ ìˆ˜ì§‘\n","img_files = sorted([f for f in os.listdir(train_img_dir) if f.lower().endswith((\".png\",\".jpg\",\".jpeg\"))])\n","random.Random(RANDOM_SEED).shuffle(img_files)\n","sampled = img_files[:min(NUM_SAMPLES, len(img_files))]\n","\n","print(f\"âœ… ì´ ì´ë¯¸ì§€ {len(img_files)}ì¥ ì¤‘ {len(sampled)}ì¥ ëœë¤ ì„ íƒ\")\n","\n","for image_file in sampled:\n","    img_path = os.path.join(train_img_dir, image_file)\n","\n","    # prefix_json í´ë” ì°¾ê¸°\n","    prefix = image_file.split('_')[0]  # 'K-xxxx-xxxx-...'\n","    cand = [d for d in os.listdir(train_ann_dir) if d.startswith(prefix) and d.endswith(\"_json\")]\n","    if not cand:\n","        print(f\"âŒ ì–´ë…¸í…Œì´ì…˜ í´ë” ì—†ìŒ: {image_file}\")\n","        continue\n","    ann_dir = os.path.join(train_ann_dir, cand[0])\n","\n","    # ë””ë²„ê·¸: í•´ë‹¹ ì´ë¯¸ì§€ëª… JSON ì¡´ì¬ ê°œìˆ˜\n","    cnt, paths = count_jsons_for_image(ann_dir, image_file)\n","    print(f\"\\nğŸ–¼ï¸ {image_file}\")\n","    print(f\"ğŸ“‚ ann_dir = {os.path.basename(ann_dir)}\")\n","    print(f\"ğŸ” ë§¤ì¹­ë˜ëŠ” JSON íŒŒì¼ ìˆ˜ = {cnt}\")\n","    if cnt == 0:\n","        print(\"   âš ï¸ ì •í™• íŒŒì¼ëª… ë§¤ì¹­ JSON ì—†ìŒ. ê·¸ë˜ë„ ë³‘í•© ì‹œë„.\")\n","    else:\n","        for p in paths[:3]:\n","            print(\"   âœ…\", p)\n","        if len(paths) > 3:\n","            print(f\"   â€¦ (ì™¸ {len(paths)-3}ê°œ)\")\n","\n","    # ë³‘í•© & ì‹œê°í™”\n","    merged = collect_coco_for_image(ann_dir, image_file)\n","    subtitle = f\"Merged anns: {len(merged['annotations'])}  |  Matched JSONs by name: {cnt}\"\n","    draw_merged(merged, img_path, subtitle=subtitle)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1YCDVo02by87GQ6raohn4aWr6eWHsZGLL"},"id":"-TkqnCNPKo8a","executionInfo":{"status":"ok","timestamp":1761031479228,"user_tz":-540,"elapsed":5999,"user":{"displayName":"Star Sin","userId":"12579642930462495568"}},"outputId":"7e42b110-6b38-4800-f014-8abfce201ce6"},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["# 1ï¸âƒ£ train_annotations ì „ì²´ë¥¼ í•˜ë‚˜ì˜ COCOë¡œ ë³‘í•©\n","merged = {\"images\": [], \"annotations\": [], \"categories\": []}\n","cat_map = {}\n","imgid_remap = {}  # (prefix_file_name, orig_image_id) -> new_image_id\n","ann_id = 1\n","new_img_id = 1\n","\n","for folder in os.listdir(train_ann_dir):\n","    if not folder.endswith(\"_json\"):\n","        continue\n","    ann_dir = os.path.join(train_ann_dir, folder)\n","    for dp, _, files in os.walk(ann_dir):\n","        for f in files:\n","            if not f.endswith(\".json\"):\n","                continue\n","            with open(os.path.join(dp, f), \"r\") as fh:\n","                j = json.load(fh)\n","            images = j.get(\"images\", [])\n","            anns   = j.get(\"annotations\", [])\n","            cats   = j.get(\"categories\", [])\n","            # ì¹´í…Œê³ ë¦¬ ë³‘í•©\n","            for c in cats:\n","                if c[\"id\"] not in cat_map:\n","                    cat_map[c[\"id\"]] = c\n","            # ì´ë¯¸ì§€/ì–´ë…¸í…Œì´ì…˜ ë¦¬ë§µ\n","            for im in images:\n","                file_name = im.get(\"file_name\") or im.get(\"imgfile\")\n","                file_name = os.path.basename(file_name)\n","                key = (file_name, im[\"id\"])\n","                if key not in imgid_remap:\n","                    imgid_remap[key] = new_img_id\n","                    merged[\"images\"].append({\n","                        \"id\": new_img_id,\n","                        \"file_name\": file_name,\n","                        \"width\": im.get(\"width\", 1024),\n","                        \"height\": im.get(\"height\", 1024)\n","                    })\n","                    new_img_id += 1\n","            for a in anns:\n","                file_name = None\n","                # image_id ë§¤í•‘ì„ ìœ„í•´ ì›ë³¸ image_idê°€ ì–´ë–¤ íŒŒì¼ì¸ì§€ ì°¾ì•„ì•¼ í•¨\n","                # ê°„ë‹¨íˆ í•´ë‹¹ jsonì˜ images í…Œì´ë¸”ì—ì„œ ë™ì¼ idë¥¼ ì°¾ì•„ file_nameì„ ì–»ëŠ”ë‹¤\n","                for im in images:\n","                    if im[\"id\"] == a[\"image_id\"]:\n","                        file_name = os.path.basename(im.get(\"file_name\") or im.get(\"imgfile\"))\n","                        mapped = imgid_remap[(file_name, im[\"id\"])]\n","                        new_a = dict(a)\n","                        new_a[\"id\"] = ann_id; ann_id += 1\n","                        new_a[\"image_id\"] = mapped\n","                        merged[\"annotations\"].append(new_a)\n","                        break\n","\n","merged[\"categories\"] = list(cat_map.values())\n","\n","os.makedirs(\"./merged_coco\", exist_ok=True)\n","with open(\"./merged_coco/train_all.json\", \"w\") as f:\n","    json.dump(merged, f, indent=2)\n","print(\"âœ… COCO ë³‘í•© ì™„ë£Œ:\", len(merged[\"images\"]), \"images,\", len(merged[\"annotations\"]), \"anns,\", len(merged[\"categories\"]), \"cats\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Kqq2cQyKqpI","executionInfo":{"status":"ok","timestamp":1761031479467,"user_tz":-540,"elapsed":114,"user":{"displayName":"Star Sin","userId":"12579642930462495568"}},"outputId":"ece9a86f-ce9b-4425-f5aa-f8230fd1c854"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… COCO ë³‘í•© ì™„ë£Œ: 1489 images, 4526 anns, 73 cats\n"]}]},{"cell_type":"code","source":["# torchvision Detectionìš© Dataset (ìˆ˜ì •íŒ: 0-based ë¼ë²¨ ë§¤í•‘)\n","class CocoLikeDetection(torch.utils.data.Dataset):\n","    def __init__(self, img_dir, coco_json, transforms=None):\n","        with open(coco_json, \"r\") as f:\n","            coco = json.load(f)\n","        self.img_dir = img_dir\n","        self.transforms = transforms\n","\n","        # images / img_ids\n","        self.images  = {im[\"id\"]: im for im in coco[\"images\"]}\n","        self.img_ids = list(self.images.keys())\n","\n","        # image_id -> annotations\n","        self.anns_by_img = {im_id: [] for im_id in self.img_ids}\n","        for a in coco[\"annotations\"]:\n","            self.anns_by_img[a[\"image_id\"]].append(a)\n","\n","        # ì¹´í…Œê³ ë¦¬ ì§‘í•© ë° 0-based ë§¤í•‘\n","        self.cat_ids = sorted({c[\"id\"] for c in coco[\"categories\"]})\n","        self.cat_id_to_idx = {cid: i for i, cid in enumerate(self.cat_ids)}   # âœ… 0..num_classes-1\n","        self.idx_to_catid  = {i: cid for cid, i in self.cat_id_to_idx.items()} # ì—­ë§¤í•‘(ì¶”ë¡ /CSVìš©)\n","\n","    def __len__(self):\n","        return len(self.img_ids)\n","\n","    def __getitem__(self, idx):\n","        img_id  = self.img_ids[idx]\n","        im_meta = self.images[img_id]\n","        img_path = os.path.join(self.img_dir, im_meta[\"file_name\"])\n","        img = Image.open(img_path).convert(\"RGB\")\n","\n","        boxes, labels, areas, iscrowd = [], [], [], []\n","        for a in self.anns_by_img.get(img_id, []):\n","            bbox = a.get(\"bbox\")\n","            if not bbox or len(bbox) != 4:\n","                continue\n","            x, y, w, h = bbox\n","            boxes.append([x, y, x + w, y + h])\n","\n","            # âœ… ë°˜ë“œì‹œ 0-basedë¡œ ë³€í™˜\n","            cid = a[\"category_id\"]\n","            labels.append(self.cat_id_to_idx.get(cid, 0))\n","\n","            areas.append(a.get(\"area\", w * h))\n","            iscrowd.append(a.get(\"iscrowd\", 0))\n","\n","        target = {\n","            \"boxes\":   torch.as_tensor(boxes, dtype=torch.float32)   if boxes else torch.zeros((0,4), dtype=torch.float32),\n","            \"labels\":  torch.as_tensor(labels, dtype=torch.int64)    if labels else torch.zeros((0,),  dtype=torch.int64),\n","            \"image_id\": torch.tensor([img_id]),\n","            \"area\":    torch.as_tensor(areas, dtype=torch.float32)   if areas else torch.zeros((0,),   dtype=torch.float32),\n","            \"iscrowd\": torch.as_tensor(iscrowd, dtype=torch.int64)   if iscrowd else torch.zeros((0,), dtype=torch.int64),\n","        }\n","\n","        if self.transforms:\n","            img = self.transforms(img)\n","        return img, target"],"metadata":{"id":"Dj0kQny1NcrQ","executionInfo":{"status":"ok","timestamp":1761031479515,"user_tz":-540,"elapsed":46,"user":{"displayName":"Star Sin","userId":"12579642930462495568"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["import os, json, random, torch\n","import torchvision.transforms as T\n","from PIL import Image\n","\n","# ë³‘í•©í•œ COCO ì–´ë…¸í…Œì´ì…˜ ê²½ë¡œ (ì•ì—ì„œ mergeí•œ json)\n","train_json = \"./merged_coco/train_all.json\"\n","\n","# ===============================\n","# 2ï¸âƒ£ Transform ì •ì˜\n","# ===============================\n","def get_transform():\n","    \"\"\"\n","    ì´ë¯¸ì§€ë¥¼ Tensorë¡œ ë³€í™˜í•˜ëŠ” ê¸°ë³¸ transform\n","    (í•„ìš”ì‹œ RandomHorizontalFlip ë“± augmentation ì¶”ê°€ ê°€ëŠ¥)\n","    \"\"\"\n","    return T.Compose([T.ToTensor()])\n","\n","# ===============================\n","# 3ï¸âƒ£ Collate í•¨ìˆ˜ (dataloaderìš©)\n","# ===============================\n","def collate_fn(batch):\n","    \"\"\"\n","    detection ëª¨ë¸ìš© collate í•¨ìˆ˜\n","    \"\"\"\n","    return tuple(zip(*batch))"],"metadata":{"id":"gtJTp8fU-Vn8","executionInfo":{"status":"ok","timestamp":1761031485171,"user_tz":-540,"elapsed":5597,"user":{"displayName":"Star Sin","userId":"12579642930462495568"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# 2ï¸âƒ£ train/val split\n","full_ds = CocoLikeDetection(train_img_dir, train_json, transforms=get_transform())\n","indices = list(range(len(full_ds)))\n","random.Random(0).shuffle(indices)\n","split = int(0.9*len(indices))\n","train_idx, val_idx = indices[:split], indices[split:]\n","\n","train_ds = torch.utils.data.Subset(full_ds, train_idx)\n","val_ds   = torch.utils.data.Subset(full_ds, val_idx)\n","\n","train_loader = torch.utils.data.DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=2, collate_fn=collate_fn)\n","val_loader   = torch.utils.data.DataLoader(val_ds, batch_size=4, shuffle=False, num_workers=2, collate_fn=collate_fn)\n","\n","num_classes = len(full_ds.cat_ids)   # ì‹¤ì œ ê°ì²´ í´ë˜ìŠ¤ ìˆ˜\n","print(\"âœ… train/val:\", len(train_ds), len(val_ds), \"classes:\", num_classes)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AMDTHO3nNq17","executionInfo":{"status":"ok","timestamp":1761031516107,"user_tz":-540,"elapsed":35,"user":{"displayName":"Star Sin","userId":"12579642930462495568"}},"outputId":"e07586ed-7dd4-4699-bc00-a4c737385ca5"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… train/val: 1340 149 classes: 73\n"]}]},{"cell_type":"code","source":["# 3ï¸âƒ£ RetinaNet (one-stage detector)\n","import torchvision\n","import torch.nn as nn\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# torchvisionì˜ RetinaNetì€ num_classes=ì¹´í…Œê³ ë¦¬ ê°œìˆ˜(ë°°ê²½ ì œì™¸)ë¡œ ì§€ì •\n","model = torchvision.models.detection.retinanet_resnet50_fpn_v2(weights=None, num_classes=num_classes)\n","model = model.to(device)\n","\n","params = [p for p in model.parameters() if p.requires_grad]\n","optimizer = torch.optim.AdamW(params, lr=2.5e-4, weight_decay=1e-4)\n","lr_sched  = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=12)"],"metadata":{"id":"MIIvLbsvN8Yy","executionInfo":{"status":"ok","timestamp":1761031519394,"user_tz":-540,"elapsed":761,"user":{"displayName":"Star Sin","userId":"12579642930462495568"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["class EarlyStopping:\n","    def __init__(self, patience=3, delta=0.0):\n","        \"\"\"\n","        patience: ê°œì„  ì—†ëŠ” epoch í—ˆìš© íšŸìˆ˜\n","        delta: ìµœì†Œ ê°œì„  í­ (ì˜ˆ: 0.001ë³´ë‹¤ ì‘ìœ¼ë©´ ê°œì„  ì•„ë‹˜)\n","        \"\"\"\n","        self.patience = patience\n","        self.delta = delta\n","        self.counter = 0\n","        self.best_loss = None\n","        self.early_stop = False\n","\n","    def __call__(self, val_loss):\n","        if self.best_loss is None:\n","            self.best_loss = val_loss\n","        elif val_loss > self.best_loss - self.delta:\n","            self.counter += 1\n","            print(f\"âš ï¸ EarlyStopping ì¹´ìš´í„° {self.counter}/{self.patience}\")\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_loss = val_loss\n","            self.counter = 0"],"metadata":{"id":"k05hiGDeX6EZ","executionInfo":{"status":"ok","timestamp":1761031520247,"user_tz":-540,"elapsed":3,"user":{"displayName":"Star Sin","userId":"12579642930462495568"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["# early stopper ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n","early_stopper = EarlyStopping(patience=3, delta=0.005)\n","\n","# 4ï¸âƒ£ Train loop (ìˆ˜ì • ì•ˆì •íŒ)\n","EPOCHS = 20\n","\n","for epoch in range(EPOCHS):\n","    model.train()\n","    total_loss = 0.0\n","\n","    for imgs, targets in train_loader:\n","        imgs = [im.to(device) for im in imgs]\n","        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n","\n","        # --- ë°©ì–´ ì½”ë“œ: ë¼ë²¨ ë²”ìœ„ ì²´í¬ (RetinaNetì€ 0-based í•„ìš”) ---\n","        for t in targets:\n","            if t[\"labels\"].numel() > 0:\n","                assert int(t[\"labels\"].min()) >= 0, f\"âŒ ì˜ëª»ëœ ë¼ë²¨(min={int(t['labels'].min())})\"\n","                assert int(t[\"labels\"].max()) < num_classes, \\\n","                    f\"âŒ ì˜ëª»ëœ ë¼ë²¨(max={int(t['labels'].max())}) >= num_classes({num_classes})\"\n","\n","        # --- ì†ì‹¤ ê³„ì‚° ---\n","        loss_dict = model(imgs, targets)\n","        loss = sum(loss_dict.values())\n","\n","        optimizer.zero_grad(set_to_none=True)\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","    lr_sched.step()\n","\n","    # =======================\n","    # Validation (ê°„ë‹¨ ë°•ìŠ¤ ìˆ˜ ì²´í¬)\n","    # =======================\n","    model.eval()\n","    val_loss = 0.0\n","    total_boxes = 0\n","    avg_score = 0\n","\n","    with torch.no_grad():\n","        for imgs, targets in val_loader:\n","            imgs = [im.to(device) for im in imgs]\n","            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n","            model.train()   # âœ… ì¶”ê°€ (loss ê³„ì‚°ìš©)\n","            # ğŸ”¹ validation ì†ì‹¤ ê³„ì‚°\n","            loss_dict = model(imgs, targets)\n","            loss = sum(loss_dict.values())\n","            model.eval()    # âœ… ì¶”ê°€ (ë‹¤ì‹œ eval ë³µê·€)\n","            val_loss += loss.item()\n","\n","            # ğŸ”¹ inference ê²°ê³¼ í™•ì¸ (optional)\n","            outs = model(imgs)\n","            total_boxes += sum(o[\"boxes\"].shape[0] for o in outs)\n","            avg_score += np.mean([\n","                float(o[\"scores\"].mean()) if len(o[\"scores\"]) > 0 else 0 for o in outs\n","            ])\n","\n","    val_loss /= len(val_loader)\n","    avg_score /= len(val_loader)\n","\n","\n","    print(f\"[{epoch+1}/{EPOCHS}] \"\n","      f\"train_loss={total_loss/len(train_loader):.4f} | \"\n","      f\"val_loss={val_loss:.4f} | \"\n","      f\"val_boxes={total_boxes} | avg_score={avg_score:.3f}\")\n","\n","        # âœ… EarlyStopping ì²´í¬\n","    early_stopper(val_loss)\n","    if early_stopper.early_stop:\n","        print(f\"â¹ Early stopping triggered at epoch {epoch+1}\")\n","        break\n","# =======================\n","# ëª¨ë¸ ì €ì¥\n","# =======================\n","save_path = \"./data/retinanet_pills.pth\"\n","torch.save(model.state_dict(), save_path)\n","print(f\"ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {save_path}\")"],"metadata":{"id":"TvgQhA0uN8zK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761040106223,"user_tz":-540,"elapsed":8584259,"user":{"displayName":"Star Sin","userId":"12579642930462495568"}},"outputId":"e510afe1-f204-4c88-9764-1dc76c3c66a2"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["[1/20] train_loss=0.8836 | val_loss=0.6300 | val_boxes=21641 | avg_score=0.134\n","[2/20] train_loss=0.4930 | val_loss=0.4223 | val_boxes=17832 | avg_score=0.164\n","[3/20] train_loss=0.3721 | val_loss=0.3858 | val_boxes=14361 | avg_score=0.144\n","[4/20] train_loss=0.3139 | val_loss=0.3205 | val_boxes=12157 | avg_score=0.140\n","[5/20] train_loss=0.2779 | val_loss=0.2950 | val_boxes=11708 | avg_score=0.134\n","[6/20] train_loss=0.2474 | val_loss=0.2820 | val_boxes=10723 | avg_score=0.140\n","[7/20] train_loss=0.2214 | val_loss=0.2555 | val_boxes=11529 | avg_score=0.144\n","[8/20] train_loss=0.1987 | val_loss=0.2395 | val_boxes=9534 | avg_score=0.142\n","[9/20] train_loss=0.1817 | val_loss=0.2243 | val_boxes=8610 | avg_score=0.138\n","[10/20] train_loss=0.1648 | val_loss=0.2202 | val_boxes=7338 | avg_score=0.138\n","âš ï¸ EarlyStopping ì¹´ìš´í„° 1/3\n","[11/20] train_loss=0.1534 | val_loss=0.2115 | val_boxes=7229 | avg_score=0.143\n","[12/20] train_loss=0.1451 | val_loss=0.2075 | val_boxes=6961 | avg_score=0.143\n","âš ï¸ EarlyStopping ì¹´ìš´í„° 1/3\n","[13/20] train_loss=0.1429 | val_loss=0.2075 | val_boxes=6991 | avg_score=0.142\n","âš ï¸ EarlyStopping ì¹´ìš´í„° 2/3\n","[14/20] train_loss=0.1437 | val_loss=0.2059 | val_boxes=6944 | avg_score=0.144\n","[15/20] train_loss=0.1489 | val_loss=0.2102 | val_boxes=6986 | avg_score=0.143\n","âš ï¸ EarlyStopping ì¹´ìš´í„° 1/3\n","[16/20] train_loss=0.1604 | val_loss=0.2217 | val_boxes=6949 | avg_score=0.145\n","âš ï¸ EarlyStopping ì¹´ìš´í„° 2/3\n","[17/20] train_loss=0.1764 | val_loss=0.2276 | val_boxes=7610 | avg_score=0.150\n","âš ï¸ EarlyStopping ì¹´ìš´í„° 3/3\n","â¹ Early stopping triggered at epoch 17\n","ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: ./data/retinanet_pills.pth\n"]}]},{"cell_type":"code","source":["# 5ï¸âƒ£ test_imagesì—ì„œ ì¶”ë¡  í›„ CSVë¡œ ì €ì¥ (ìµœì¢… ì•ˆì •íŒ)\n","import pandas as pd\n","from pathlib import Path\n","\n","test_dir = os.path.join(base_path, \"test_images\")\n","score_thr = 0.25\n","csv_out  = \"./stage1_retinanet_predictions.csv\"\n","\n","rows = []\n","annotation_id = 1\n","model.eval()\n","\n","# label ì¸ë±ìŠ¤ â†” ì‹¤ì œ ì¹´í…Œê³ ë¦¬ id ë§¤í•‘\n","idx_to_catid = {i+1: cid for i, cid in enumerate(full_ds.cat_ids)}\n","\n","file_list = [fn for fn in os.listdir(test_dir) if fn.lower().endswith((\".png\", \".jpg\", \".jpeg\"))]\n","file_list.sort()\n","\n","for fn in file_list:\n","    img_path = os.path.join(test_dir, fn)\n","    img_name = os.path.splitext(fn)[0]  # âœ… í™•ì¥ì ì œê±° (ì˜ˆ: \"1.png\" â†’ \"1\")\n","    img = Image.open(img_path).convert(\"RGB\")\n","    x = T.ToTensor()(img).to(device)\n","\n","    with torch.no_grad():\n","        out = model([x])[0]\n","\n","    boxes  = out[\"boxes\"].detach().cpu().numpy()\n","    labels = out[\"labels\"].detach().cpu().numpy()\n","    scores = out[\"scores\"].detach().cpu().numpy()\n","\n","    for (x1, y1, x2, y2), lab, sc in zip(boxes, labels, scores):\n","        if sc < score_thr:\n","            continue\n","        if lab == 0:  # âœ… category_id 0(ë°°ê²½)ì€ ì œì™¸\n","            continue\n","\n","        rows.append({\n","            \"annotation_id\": annotation_id,\n","            \"image_id\": img_name,  # âœ… í™•ì¥ì ì œê±°ëœ ì´ë¦„ ì‚¬ìš©\n","            \"category_id\": int(idx_to_catid.get(int(lab), int(lab))),\n","            \"bbox_x\": round(float(x1), 2),\n","            \"bbox_y\": round(float(y1), 2),\n","            \"bbox_w\": round(float(x2 - x1), 2),\n","            \"bbox_h\": round(float(y2 - y1), 2),\n","            \"score\": round(float(sc), 3)\n","        })\n","        annotation_id += 1\n","\n","# âœ… file_name ì œê±°, image_idì— í™•ì¥ì ì—†ëŠ” ì´ë¦„ë§Œ í¬í•¨\n","df = pd.DataFrame(rows, columns=[\n","    \"annotation_id\", \"image_id\", \"category_id\", \"bbox_x\", \"bbox_y\", \"bbox_w\", \"bbox_h\", \"score\"\n","])\n","df.to_csv(csv_out, index=False, encoding=\"utf-8-sig\")\n","print(f\"âœ… CSV ì €ì¥ ì™„ë£Œ: {csv_out} (rows={len(df)})\")"],"metadata":{"id":"AtMdiywNN-ha","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761028944627,"user_tz":-540,"elapsed":122056,"user":{"displayName":"Star Sin","userId":"12579642930462495568"}},"outputId":"04a867f7-7075-4455-94d9-ca0e4f27bb46"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… CSV ì €ì¥: ./stage1_retinanet_predictions.csv  (rows=4687)\n"]}]},{"cell_type":"code","source":["# ë²¨ë¦¬ë°ì´ì…˜ setì„ ë”°ë¡œ ë§Œë“¤ê³ , í•™ìŠµì„ ë³„ë„ë¡œ í•˜ê²Œëœë‹¤."],"metadata":{"id":"6IPzB-i_f1UO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torchvision.ops as ops\n","\n","def nms_per_class_keep_top1(\n","    boxes, labels, scores,\n","    score_thr=0.25,\n","    iou_thr=0.5,\n","    keep_by=\"area\",   # \"area\" ë˜ëŠ” \"score\"\n","    verbose=False\n","):\n","    \"\"\"\n","    ì…ë ¥:\n","      boxes [N,4] (xyxy), labels [N], scores [N]  â€” CPU float32 ê¶Œì¥\n","    ë™ì‘:\n","      1) score_thr ì´í•˜, label==0(ë°°ê²½) ì œê±°\n","      2) í´ë˜ìŠ¤ë³„ NMS (IoU)\n","      3) ë‚¨ì€ ë°•ìŠ¤ ì¤‘ 'í´ë˜ìŠ¤ë‹¹ 1ê°œ'ë§Œ ìœ ì§€ (ë©´ì  or ì ìˆ˜ ê¸°ì¤€)\n","    ë°˜í™˜:\n","      boxes_kept, labels_kept, scores_kept (ëª¨ë‘ CPU float32 / long)\n","    \"\"\"\n","    # --- 0) ì•ˆì „ ìºìŠ¤íŒ… & ì •ë¦¬ ---\n","    if not isinstance(boxes, torch.Tensor):  boxes  = torch.as_tensor(boxes)\n","    if not isinstance(labels, torch.Tensor): labels = torch.as_tensor(labels)\n","    if not isinstance(scores, torch.Tensor): scores = torch.as_tensor(scores)\n","\n","    boxes  = boxes.detach().to(\"cpu\", dtype=torch.float32).contiguous()\n","    labels = labels.detach().to(\"cpu\", dtype=torch.int64).contiguous()\n","    scores = scores.detach().to(\"cpu\", dtype=torch.float32).contiguous()\n","\n","    # --- 1) ê¸°ë³¸ í•„í„° ---\n","    keep_mask = (scores >= float(score_thr)) & (labels != 0)\n","    boxes, labels, scores = boxes[keep_mask], labels[keep_mask], scores[keep_mask]\n","    if boxes.numel() == 0:\n","        if verbose: print(\"NMS: no boxes after score/bg filter\")\n","        return boxes, labels, scores\n","\n","    kept_b, kept_l, kept_s = [], [], []\n","\n","    # --- 2) í´ë˜ìŠ¤ë³„ NMS ---\n","    uniq = labels.unique().tolist()\n","    for lab in uniq:\n","        m = (labels == lab)\n","        b = boxes[m]\n","        s = scores[m]\n","        if b.numel() == 0:\n","            continue\n","\n","        # IoU ê¸°ë°˜ ì¤‘ë³µ ì œê±°: ì ìˆ˜ëŠ” s ì‚¬ìš©\n","        keep_idx = ops.nms(b, s, float(iou_thr))\n","        b2, s2 = b[keep_idx], s[keep_idx]\n","\n","        # --- 3) í´ë˜ìŠ¤ë‹¹ 1ê°œë§Œ ë‚¨ê¸°ê¸° (ë©´ì  or ì ìˆ˜ ê¸°ì¤€)\n","        if b2.shape[0] > 1:\n","            if keep_by == \"score\":\n","                chosen = torch.argmax(s2)\n","            else:  # keep_by == \"area\"\n","                areas = (b2[:, 2] - b2[:, 0]).clamp(min=0) * (b2[:, 3] - b2[:, 1]).clamp(min=0)\n","                chosen = torch.argmax(areas)\n","            b2 = b2[chosen:chosen+1]\n","            s2 = s2[chosen:chosen+1]\n","\n","        kept_b.append(b2)\n","        kept_l.append(torch.full((b2.shape[0],), lab, dtype=torch.int64))\n","        kept_s.append(s2)\n","\n","    if len(kept_b) == 0:\n","        if verbose: print(\"NMS: nothing kept per-class\")\n","        return boxes.new_zeros((0,4)), labels.new_zeros((0,), dtype=torch.int64), scores.new_zeros((0,))\n","\n","    boxes_kept  = torch.cat(kept_b, dim=0)\n","    labels_kept = torch.cat(kept_l, dim=0)\n","    scores_kept = torch.cat(kept_s, dim=0)\n","\n","    if verbose:\n","        print(f\"NMS kept: {boxes_kept.shape[0]} boxes (classes={len(uniq)})\")\n","\n","    return boxes_kept, labels_kept, scores_kept"],"metadata":{"id":"fFF42LKxPS5E","executionInfo":{"status":"ok","timestamp":1761041266032,"user_tz":-540,"elapsed":3,"user":{"displayName":"Star Sin","userId":"12579642930462495568"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["# ==== Per-Drug (category_id) NMS â†’ í´ë˜ìŠ¤ë³„ 'ê°€ì¥ í° ë°•ìŠ¤ 1ê°œ'ë§Œ ë‚¨ê¸°ê¸° ====\n","import os\n","import torch\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","import torchvision.transforms as T\n","import torchvision.ops as ops\n","from PIL import Image\n","\n","# --- ì„¤ì • ---\n","test_dir    = os.path.join(base_path, \"test_images\")\n","csv_out     = \"./stage1_retinanet_predictions_one_per_drug_nms.csv\"\n","score_thr   = 0.30    # ì ìˆ˜ í•„í„° (ê³¼ê²€ì¶œì´ë©´ â†‘, ëˆ„ë½ ë§ìœ¼ë©´ â†“)\n","iou_thr     = 0.50    # ê°™ì€ ì•½ì˜ ê²¹ì¹œ ì•µì»¤ë¥¼ í•˜ë‚˜ë¡œ ë¬¶ëŠ” IoU ê¸°ì¤€\n","visualize_n = 8       # ì• Nì¥ë§Œ ì‹œê°í™” (0ì´ë©´ ë¹„í™œì„±)\n","\n","model.eval()\n","\n","# label index(1..N) -> ì‹¤ì œ ì¹´í…Œê³ ë¦¬ id ë§¤í•‘ (Datasetì—ì„œ ë§Œë“  ë§µ ì‚¬ìš©)\n","idx_to_catid = getattr(full_ds, \"idx_to_catid\", None)\n","if idx_to_catid is None:\n","    idx_to_catid = {i+1: cid for i, cid in enumerate(full_ds.cat_ids)}\n","\n","rows = []\n","annotation_id = 1\n","shown = 0\n","\n","file_list = sorted([fn for fn in os.listdir(test_dir)\n","                    if fn.lower().endswith((\".png\", \".jpg\", \".jpeg\"))])\n","\n","for fn in file_list:\n","    img_path = os.path.join(test_dir, fn)\n","    image_id = os.path.splitext(fn)[0]\n","    img = Image.open(img_path).convert(\"RGB\")\n","    x = T.ToTensor()(img).to(device)\n","\n","    with torch.no_grad():\n","        out = model([x])[0]\n","\n","    # í…ì„œ ì •ë¦¬ (CPU/float32)\n","    boxes  = out[\"boxes\"].detach().to(\"cpu\", dtype=torch.float32)\n","    labels = out[\"labels\"].detach().to(\"cpu\", dtype=torch.int64)\n","    scores = out[\"scores\"].detach().to(\"cpu\", dtype=torch.float32)\n","\n","    # 1) score/bg í•„í„° (ë°°ê²½ label==0 ì œê±°)\n","    keep = (scores >= score_thr) & (labels != 0)\n","    boxes, labels, scores = boxes[keep], labels[keep], scores[keep]\n","\n","    print(boxes, labels, scores)\n","    if boxes.numel() == 0:\n","        continue\n","\n","    kept_b, kept_l, kept_s = [], [], []\n","\n","    # 2) ì•½(=category_id)ë³„ë¡œ NMS â†’ 3) ë‚¨ì€ ê²ƒ ì¤‘ 'ë©´ì  ìµœëŒ€' 1ê°œë§Œ ìœ ì§€\n","    for lab in labels.unique().tolist():\n","        m = (labels == lab)\n","        b = boxes[m]     # [M,4]\n","        s = scores[m]    # [M]\n","\n","        if b.numel() == 0:\n","            continue\n","\n","        cat_id = int(idx_to_catid.get(int(lab), int(lab)))\n","        print(f\"\\nğŸ”¹ Class {cat_id} â€” NMS ì „: {len(b)}ê°œ\")\n","        for i in range(len(b)):\n","            x1, y1, x2, y2 = b[i].tolist()\n","            area = (x2 - x1) * (y2 - y1)\n","            print(f\"  â”œâ”€ idx={cat_id} score={s[i]:.3f} area={area:.1f} box=({x1:.1f},{y1:.1f},{x2:.1f},{y2:.1f})\")\n","\n","        # NMSë¡œ ê²¹ì¹œ ì•µì»¤ ì •ë¦¬ (ë™ì¼ class ë‚´)\n","        keep_idx = ops.nms(b, s, iou_thr)\n","        b = b[keep_idx]\n","        s = s[keep_idx]\n","\n","        # ê°™ì€ ì•½(class)ì—ì„œë„ ì—¬ëŸ¬ ìœ„ì¹˜ê°€ ë‚¨ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ 'ë©´ì  ê°€ì¥ í°' 1ê°œë§Œ ì„ íƒ\n","        if b.shape[0] > 1:\n","            areas = (b[:,2]-b[:,0]).clamp(min=0) * (b[:,3]-b[:,1]).clamp(min=0)\n","            best = torch.argmax(areas)\n","            b = b[best:best+1]\n","            s = s[best:best+1]\n","\n","        kept_b.append(b)\n","        kept_l.append(torch.full((b.shape[0],), lab, dtype=torch.int64))\n","        kept_s.append(s)\n","\n","    if not kept_b:\n","        continue\n","\n","    boxes_kept  = torch.cat(kept_b, dim=0)\n","    labels_kept = torch.cat(kept_l, dim=0)\n","    scores_kept = torch.cat(kept_s, dim=0)\n","\n","    # 4) ì‹œê°í™”\n","    if shown < visualize_n:\n","        fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n","        ax.imshow(img); ax.axis(\"off\")\n","\n","    for (x1, y1, x2, y2), lab, sc in zip(boxes_kept.tolist(),\n","                                         labels_kept.tolist(),\n","                                         scores_kept.tolist()):\n","        cat_id = int(idx_to_catid.get(int(lab), int(lab)))\n","        rows.append({\n","            \"annotation_id\": annotation_id,\n","            \"image_id\": image_id,                       # í™•ì¥ì ì—†ëŠ” íŒŒì¼ëª…\n","            \"category_id\": cat_id,                      # ì‹¤ì œ ì¹´í…Œê³ ë¦¬ id\n","            \"bbox_x\": round(float(x1), 2),\n","            \"bbox_y\": round(float(y1), 2),\n","            \"bbox_w\": round(float(x2 - x1), 2),\n","            \"bbox_h\": round(float(y2 - y1), 2),\n","            \"score\":  round(float(sc), 3),\n","        })\n","        annotation_id += 1\n","\n","        if shown < visualize_n:\n","            rect = patches.Rectangle((x1, y1), x2-x1, y2-y1,\n","                                     linewidth=2, edgecolor='lime', facecolor='none')\n","            ax.add_patch(rect)\n","            ax.text(x1, max(0, y1-5), f\"{cat_id} ({sc:.2f})\",\n","                    fontsize=9, color=\"white\",\n","                    bbox=dict(facecolor=\"black\", alpha=0.6, pad=1))\n","\n","    if shown < visualize_n:\n","        shown += 1\n","        ax.set_title(f\"{fn} â€” per-drug NMS â†’ largest ONE per class (kept {boxes_kept.shape[0]})\", fontsize=12)\n","        plt.show()\n","\n","# 5) CSV ì €ì¥\n","df = pd.DataFrame(rows, columns=[\n","    \"annotation_id\",\"image_id\",\"category_id\",\"bbox_x\",\"bbox_y\",\"bbox_w\",\"bbox_h\",\"score\"\n","])\n","df.to_csv(csv_out, index=False, encoding=\"utf-8-sig\")\n","print(f\"âœ… CSV ì €ì¥ ì™„ë£Œ(ì•½ë³„ ê°€ì¥ í° 1ê°œë§Œ): {csv_out} (rows={len(df)})\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1pfJGV-3j_d82-p2b6_cWQ4G6n9Br6Jm2"},"id":"_ayQBfJsL_ug","executionInfo":{"status":"ok","timestamp":1761041886016,"user_tz":-540,"elapsed":129234,"user":{"displayName":"Star Sin","userId":"12579642930462495568"}},"outputId":"5dad120b-928b-4149-8702-3e4ceaa4343b"},"execution_count":43,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":[],"metadata":{"id":"2DCiVdwtLrAE"}}]}