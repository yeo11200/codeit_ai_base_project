{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyNpZOk35FfxKZI2ZX8nQa07"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QK5gvbaiUb4B","executionInfo":{"status":"ok","timestamp":1761117057961,"user_tz":-540,"elapsed":7260,"user":{"displayName":"Star Sin","userId":"12579642930462495568"}},"outputId":"4c342b21-85fb-4156-963e-256d2361251a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.2.0)\n","Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.10.5)\n","Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n","Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n","Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n","Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n","Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n","Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n"]}],"source":["!pip install kaggle"]},{"cell_type":"code","source":["!sudo apt-get install -y fonts-nanum\n","!sudo fc-cache -fv\n","!rm ~/.cache/matplotlib -rf\n","\n","!apt-get update -qq\n","!apt-get install fonts-nanum* -qq\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.font_manager as fm\n","import warnings\n","warnings.filterwarnings(action='ignore')\n","\n","path = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf' # ë‚˜ëˆ” ê³ ë”•\n","font_name = fm.FontProperties(fname=path, size=10).get_name() # ê¸°ë³¸ í°íŠ¸ ì‚¬ì´ì¦ˆ : 10\n","plt.rc('font', family=font_name)\n","\n","fm.fontManager.addfont(path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3UkuHJS7Uder","executionInfo":{"status":"ok","timestamp":1761117131447,"user_tz":-540,"elapsed":27607,"user":{"displayName":"Star Sin","userId":"12579642930462495568"}},"outputId":"ae427802-f2b1-49fc-82b7-063bd73797ad"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following NEW packages will be installed:\n","  fonts-nanum\n","0 upgraded, 1 newly installed, 0 to remove and 38 not upgraded.\n","Need to get 10.3 MB of archives.\n","After this operation, 34.1 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-nanum all 20200506-1 [10.3 MB]\n","Fetched 10.3 MB in 2s (4,577 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package fonts-nanum.\n","(Reading database ... 126675 files and directories currently installed.)\n","Preparing to unpack .../fonts-nanum_20200506-1_all.deb ...\n","Unpacking fonts-nanum (20200506-1) ...\n","Setting up fonts-nanum (20200506-1) ...\n","Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n","/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n","/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n","/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n","/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n","/usr/share/fonts/truetype/nanum: caching, new cache contents: 12 fonts, 0 dirs\n","/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n","/root/.local/share/fonts: skipping, no such directory\n","/root/.fonts: skipping, no such directory\n","/usr/share/fonts/truetype: skipping, looped directory detected\n","/usr/share/fonts/truetype/humor-sans: skipping, looped directory detected\n","/usr/share/fonts/truetype/liberation: skipping, looped directory detected\n","/usr/share/fonts/truetype/nanum: skipping, looped directory detected\n","/var/cache/fontconfig: cleaning cache directory\n","/root/.cache/fontconfig: not cleaning non-existent cache directory\n","/root/.fontconfig: not cleaning non-existent cache directory\n","fc-cache: succeeded\n","W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n","Selecting previously unselected package fonts-nanum-coding.\n","(Reading database ... 126698 files and directories currently installed.)\n","Preparing to unpack .../fonts-nanum-coding_2.5-3_all.deb ...\n","Unpacking fonts-nanum-coding (2.5-3) ...\n","Selecting previously unselected package fonts-nanum-eco.\n","Preparing to unpack .../fonts-nanum-eco_1.000-7_all.deb ...\n","Unpacking fonts-nanum-eco (1.000-7) ...\n","Selecting previously unselected package fonts-nanum-extra.\n","Preparing to unpack .../fonts-nanum-extra_20200506-1_all.deb ...\n","Unpacking fonts-nanum-extra (20200506-1) ...\n","Setting up fonts-nanum-extra (20200506-1) ...\n","Setting up fonts-nanum-coding (2.5-3) ...\n","Setting up fonts-nanum-eco (1.000-7) ...\n","Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n"]}]},{"cell_type":"code","source":["import os\n","from kaggle.api.kaggle_api_extended import KaggleApi\n","\n","os.environ['KAGGLE_USERNAME'] = 'starsin'\n","os.environ['KAGGLE_KEY'] = 'ff559a02afd29d67f19bc4001d5a69f7'\n","\n","api = KaggleApi()\n","api.authenticate()\n","\n","\n","# 2. ëŒ€íšŒ ë°ì´í„° ë‹¤ìš´ë¡œë“œ\n","competition_name = \"ai05-level1-project\"\n","api.competition_download_files(competition_name, path=\"./data\")"],"metadata":{"id":"SoX-Hw0rUfaV","executionInfo":{"status":"ok","timestamp":1761117338664,"user_tz":-540,"elapsed":203774,"user":{"displayName":"Star Sin","userId":"12579642930462495568"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import zipfile\n","\n","zip_path = \"./data/ai05-level1-project.zip\"\n","extract_dir = \"./data/ai05-level1-project\"\n","\n","os.makedirs(extract_dir, exist_ok=True)\n","\n","with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n","    zip_ref.extractall(extract_dir)"],"metadata":{"id":"bps-7ZwuUjm9","executionInfo":{"status":"ok","timestamp":1761117359632,"user_tz":-540,"elapsed":12302,"user":{"displayName":"Star Sin","userId":"12579642930462495568"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# === 0) ê³µí†µ ì„í¬íŠ¸ & ê²½ë¡œ ===\n","import os, json, random, time\n","import numpy as np\n","import pandas as pd\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","\n","import torch\n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as T\n","import torchvision.ops as ops\n","\n","# ê²½ë¡œ\n","base_path = \"./data/ai05-level1-project\"\n","img_dir   = os.path.join(base_path, \"train_images\")\n","test_dir  = os.path.join(base_path, \"test_images\")\n","train_json = \"./merged_coco/train_all.json\"   # COCO í•©ë³¸(ì—†ìœ¼ë©´ ë§¨ ì•„ë˜ ì˜µì…˜ ì…€ ì°¸ê³ )\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"device:\", device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5G2_3ut8U3UE","executionInfo":{"status":"ok","timestamp":1761119404409,"user_tz":-540,"elapsed":3262,"user":{"displayName":"Star Sin","userId":"12579642930462495568"}},"outputId":"0f1e1100-35f7-4e90-b2bf-f0bf0db49e65"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["device: cuda\n"]}]},{"cell_type":"code","source":["# === ì˜µì…˜) train_annotations ì „ì²´ë¥¼ í•˜ë‚˜ì˜ COCOë¡œ ë³‘í•© ===\n","train_ann_dir = os.path.join(base_path, \"train_annotations\")\n","merged = {\"images\": [], \"annotations\": [], \"categories\": []}\n","cat_map = {}\n","imgid_remap = {}   # (file_name, orig_image_id) -> new_image_id\n","ann_id = 1\n","new_img_id = 1\n","\n","for folder in os.listdir(train_ann_dir):\n","    if not folder.endswith(\"_json\"):\n","        continue\n","    ann_dir = os.path.join(train_ann_dir, folder)\n","    for dp, _, files in os.walk(ann_dir):\n","        for f in files:\n","            if not f.endswith(\".json\"):\n","                continue\n","            with open(os.path.join(dp, f), \"r\") as fh:\n","                j = json.load(fh)\n","            images = j.get(\"images\", [])\n","            anns   = j.get(\"annotations\", [])\n","            cats   = j.get(\"categories\", [])\n","            for c in cats:\n","                if c[\"id\"] not in cat_map:\n","                    cat_map[c[\"id\"]] = c\n","            for im in images:\n","                file_name = os.path.basename(im.get(\"file_name\") or im.get(\"imgfile\"))\n","                key = (file_name, im[\"id\"])\n","                if key not in imgid_remap:\n","                    imgid_remap[key] = new_img_id\n","                    merged[\"images\"].append({\n","                        \"id\": new_img_id,\n","                        \"file_name\": file_name,\n","                        \"width\": im.get(\"width\", 1024),\n","                        \"height\": im.get(\"height\", 1024)\n","                    })\n","                    new_img_id += 1\n","            for a in anns:\n","                for im in images:\n","                    if im[\"id\"] == a[\"image_id\"]:\n","                        file_name = os.path.basename(im.get(\"file_name\") or im.get(\"imgfile\"))\n","                        mapped = imgid_remap[(file_name, im[\"id\"])]\n","                        new_a = dict(a)\n","                        new_a[\"id\"] = ann_id; ann_id += 1\n","                        new_a[\"image_id\"] = mapped\n","                        merged[\"annotations\"].append(new_a)\n","                        break\n","\n","merged[\"categories\"] = list(cat_map.values())\n","os.makedirs(\"./merged_coco\", exist_ok=True)\n","with open(\"./merged_coco/train_all.json\", \"w\") as f:\n","    json.dump(merged, f, indent=2)\n","print(\"âœ… COCO ë³‘í•© ì™„ë£Œ:\", len(merged[\"images\"]), \"images,\", len(merged[\"annotations\"]), \"anns,\", len(merged[\"categories\"]), \"cats\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IHrooXtUU0ck","executionInfo":{"status":"ok","timestamp":1761119419588,"user_tz":-540,"elapsed":441,"user":{"displayName":"Star Sin","userId":"12579642930462495568"}},"outputId":"90e90eb0-02d1-47ba-ae12-9c7b691078ad"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… COCO ë³‘í•© ì™„ë£Œ: 1489 images, 4526 anns, 73 cats\n"]}]},{"cell_type":"code","source":["# === 1) Dataset / Loader (bbox -> mask ìë™ ìƒì„±) ===\n","def get_transform(train=True):\n","    # ë°•ìŠ¤ë¥¼ ê±´ë“œë¦¬ì§€ ì•ŠëŠ” photometric ì¦ê°•ë§Œ ì‚¬ìš© (ì•ˆì „)\n","    aug = [T.ToTensor()]\n","    if train:\n","        aug += [\n","            T.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.15, hue=0.03),\n","            T.RandomAdjustSharpness(sharpness_factor=1.5, p=0.30),\n","            T.GaussianBlur(kernel_size=3, sigma=(0.1, 1.5)),\n","            T.RandomAutocontrast(p=0.25),\n","        ]\n","    return T.Compose(aug)\n","\n","def boxes_to_rect_masks(size_hw, boxes_xyxy):\n","    \"\"\"\n","    size_hw: (H, W)\n","    boxes_xyxy: float/np.array [N,4] (x1,y1,x2,y2)\n","    return: uint8 mask [N, H, W] (0/1)\n","    \"\"\"\n","    H, W = size_hw\n","    masks = []\n","    for (x1, y1, x2, y2) in boxes_xyxy:\n","        x1, y1, x2, y2 = map(float, (x1, y1, x2, y2))\n","        x1 = max(0, min(W-1, x1)); x2 = max(0, min(W-1, x2))\n","        y1 = max(0, min(H-1, y1)); y2 = max(0, min(H-1, y2))\n","        if x2 <= x1 or y2 <= y1:\n","            masks.append(np.zeros((H, W), dtype=np.uint8))\n","            continue\n","        m = np.zeros((H, W), dtype=np.uint8)\n","        m[int(y1):int(y2), int(x1):int(x2)] = 1\n","        masks.append(m)\n","    if len(masks)==0:\n","        return np.zeros((0, H, W), dtype=np.uint8)\n","    return np.stack(masks, axis=0)\n","\n","class CocoLikeMaskDataset(torch.utils.data.Dataset):\n","    \"\"\"\n","    Mask R-CNNìš© Dataset.\n","    - COCO 'categories'ì˜ idë¥¼ 0-based indexë¡œ ë§¤í•‘í•˜ì—¬ labels ìƒì„±\n","    - segmentationì´ ì—†ì–´ë„ bboxë¥¼ ì‚¬ê°í˜• ë§ˆìŠ¤í¬ë¡œ rasterize\n","    \"\"\"\n","    def __init__(self, img_dir, coco_json, transforms=None, train=True):\n","        with open(coco_json, \"r\") as f:\n","            coco = json.load(f)\n","\n","        self.img_dir = img_dir\n","        self.transforms = transforms\n","        self.train = train\n","\n","        self.images  = {im[\"id\"]: im for im in coco[\"images\"]}\n","        self.img_ids = list(self.images.keys())\n","\n","        self.anns_by_img = {im_id: [] for im_id in self.img_ids}\n","        for a in coco[\"annotations\"]:\n","            self.anns_by_img[a[\"image_id\"]].append(a)\n","\n","        self.cat_ids = sorted({c[\"id\"] for c in coco[\"categories\"]})\n","        self.cat_id_to_idx = {cid: i for i, cid in enumerate(self.cat_ids)}   # 0..K-1\n","        self.idx_to_catid  = {i: cid for cid, i in self.cat_id_to_idx.items()}\n","\n","    def __len__(self):\n","        return len(self.img_ids)\n","\n","    def __getitem__(self, idx):\n","        img_id  = self.img_ids[idx]\n","        im_meta = self.images[img_id]\n","        file_name = im_meta[\"file_name\"]\n","        W = im_meta.get(\"width\", 1024)\n","        H = im_meta.get(\"height\", 1024)\n","\n","        img_path = os.path.join(self.img_dir, file_name)\n","        img = Image.open(img_path).convert(\"RGB\")\n","\n","        boxes, labels, areas, iscrowd = [], [], [], []\n","        for a in self.anns_by_img.get(img_id, []):\n","            if \"bbox\" not in a or not a[\"bbox\"]:\n","                continue\n","            x, y, w, h = a[\"bbox\"]\n","            boxes.append([x, y, x+w, y+h])\n","            labels.append(self.cat_id_to_idx.get(a[\"category_id\"], 0))\n","            areas.append(a.get(\"area\", w*h))\n","            iscrowd.append(a.get(\"iscrowd\", 0))\n","\n","        boxes_np = np.array(boxes, dtype=np.float32) if boxes else np.zeros((0,4), np.float32)\n","        masks_np = boxes_to_rect_masks((H, W), boxes_np)  # âœ… bboxâ†’mask\n","\n","        target = {\n","            \"boxes\":    torch.as_tensor(boxes_np, dtype=torch.float32),\n","            \"labels\":   torch.as_tensor(labels, dtype=torch.int64) if labels else torch.zeros((0,), dtype=torch.int64),\n","            \"masks\":    torch.as_tensor(masks_np, dtype=torch.uint8),    # [N,H,W], 0/1\n","            \"image_id\": torch.tensor([img_id]),\n","            \"area\":     torch.as_tensor(areas, dtype=torch.float32) if areas else torch.zeros((0,), dtype=torch.float32),\n","            \"iscrowd\":  torch.as_tensor(iscrowd, dtype=torch.int64) if iscrowd else torch.zeros((0,), dtype=torch.int64),\n","        }\n","\n","        if self.transforms:\n","            img = self.transforms(img)  # photometric only\n","        else:\n","            img = T.ToTensor()(img)\n","\n","        return img, target\n","\n","def collate_fn(batch):\n","    return tuple(zip(*batch))\n","\n","# ë¡œë”\n","full_ds = CocoLikeMaskDataset(img_dir, train_json, transforms=get_transform(train=True), train=True)\n","indices = list(range(len(full_ds)))\n","random.Random(0).shuffle(indices)\n","split = int(0.9*len(indices))\n","train_idx, val_idx = indices[:split], indices[split:]\n","\n","train_ds = torch.utils.data.Subset(full_ds, train_idx)\n","val_ds   = torch.utils.data.Subset(CocoLikeMaskDataset(img_dir, train_json, transforms=get_transform(train=False), train=False),\n","                                   val_idx)\n","\n","train_loader = torch.utils.data.DataLoader(train_ds, batch_size=8, shuffle=True,  num_workers=2, collate_fn=collate_fn)\n","val_loader   = torch.utils.data.DataLoader(val_ds,   batch_size=8, shuffle=False, num_workers=2, collate_fn=collate_fn)\n","\n","num_classes = len(full_ds.cat_ids)  # âœ… full_dsëŠ” Dataset ê°ì²´\n","print(\"âœ… train:\", len(train_ds), \"val:\", len(val_ds), \"classes:\", num_classes)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rB1rd0kqU4au","executionInfo":{"status":"ok","timestamp":1761119422113,"user_tz":-540,"elapsed":46,"user":{"displayName":"Star Sin","userId":"12579642930462495568"}},"outputId":"7e5ba312-e780-4c34-9968-dc98f5613219"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… train: 1340 val: 149 classes: 73\n"]}]},{"cell_type":"code","source":["# === 2) Mask R-CNN ì´ˆê¸°í™” ===\n","model = torchvision.models.detection.maskrcnn_resnet50_fpn_v2(\n","    weights=None,                # í•„ìš”í•˜ë©´ weights=\"DEFAULT\"\n","    num_classes=num_classes      # torchvision: ë°°ê²½ì€ ë‚´ë¶€ ì²˜ë¦¬\n",").to(device)\n","\n","params = [p for p in model.parameters() if p.requires_grad]\n","optimizer = torch.optim.AdamW(params, lr=2.5e-4, weight_decay=1e-4)\n","lr_sched  = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=16)\n","\n","print(\"Model ready.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7xERBaORU5vu","executionInfo":{"status":"ok","timestamp":1761119424908,"user_tz":-540,"elapsed":741,"user":{"displayName":"Star Sin","userId":"12579642930462495568"}},"outputId":"020c2b48-e1fa-4fdb-9ecc-e2548bb89fa9"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Model ready.\n"]}]},{"cell_type":"code","source":["# === 3) EarlyStopping & Train Loop ===\n","class EarlyStopping:\n","    def __init__(self, patience=3, delta=0.0):\n","        self.patience = patience\n","        self.delta = delta\n","        self.counter = 0\n","        self.best = None\n","        self.early_stop = False\n","\n","    def __call__(self, val_loss):\n","        if (self.best is None) or ((self.best - val_loss) > self.delta):\n","            self.best = val_loss\n","            self.counter = 0\n","        else:\n","            self.counter += 1\n","            print(f\"âš ï¸ EarlyStopping {self.counter}/{self.patience}\")\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","\n","early_stopper = EarlyStopping(patience=3, delta=1e-4)\n","\n","EPOCHS = 20\n","for epoch in range(1, EPOCHS+1):\n","    # ---- train ----\n","    model.train()\n","    total_loss = 0.0\n","    for imgs, targets in train_loader:\n","        imgs = [im.to(device) for im in imgs]\n","        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n","\n","        # label ë²”ìœ„ ë°©ì–´\n","        for t in targets:\n","            if t[\"labels\"].numel() > 0:\n","                assert int(t[\"labels\"].min()) >= 0\n","                assert int(t[\"labels\"].max()) < num_classes\n","\n","        loss_dict = model(imgs, targets)   # dict: classification, box_reg, mask, ...\n","        loss = sum(loss_dict.values())\n","\n","        optimizer.zero_grad(set_to_none=True)\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += float(loss.item())\n","\n","    lr_sched.step()\n","    train_loss = total_loss / max(1, len(train_loader))\n","\n","    # ---- validation loss (ì†ì‹¤ ê³„ì‚° ìœ„í•´ train ìœ ì§€ + no_grad) ----\n","    model.train()\n","    val_loss = 0.0\n","    with torch.no_grad():\n","        for imgs, targets in val_loader:\n","            imgs = [im.to(device) for im in imgs]\n","            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n","            loss_dict = model(imgs, targets)\n","            loss = sum(loss_dict.values())\n","            val_loss += float(loss.item())\n","    val_loss /= max(1, len(val_loader))\n","\n","    print(f\"[{epoch}/{EPOCHS}] train_loss={train_loss:.4f} | val_loss={val_loss:.4f}\")\n","\n","    early_stopper(val_loss)\n","    if early_stopper.early_stop:\n","        print(f\"â¹ Early stopping at epoch {epoch}\")\n","        break\n","\n","# ì €ì¥\n","os.makedirs(\"./checkpoints\", exist_ok=True)\n","ckpt_path = \"./checkpoints/maskrcnn_pills.pth\"\n","torch.save(model.state_dict(), ckpt_path)\n","print(\"ğŸ’¾ saved:\", ckpt_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AjWODrbHU6uZ","executionInfo":{"status":"ok","timestamp":1761126303286,"user_tz":-540,"elapsed":6876078,"user":{"displayName":"Star Sin","userId":"12579642930462495568"}},"outputId":"f7eafa43-3d7c-4796-d6b6-48026af746a2"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["[1/20] train_loss=1.3235 | val_loss=0.6550\n","[2/20] train_loss=0.6427 | val_loss=0.3274\n","[3/20] train_loss=0.4603 | val_loss=0.2811\n","[4/20] train_loss=0.3776 | val_loss=0.2613\n","[5/20] train_loss=0.3550 | val_loss=0.2005\n","[6/20] train_loss=0.3313 | val_loss=0.1826\n","[7/20] train_loss=0.3183 | val_loss=0.1548\n","[8/20] train_loss=0.2980 | val_loss=0.1607\n","âš ï¸ EarlyStopping 1/3\n","[9/20] train_loss=0.2813 | val_loss=0.1358\n","[10/20] train_loss=0.2704 | val_loss=0.1166\n","[11/20] train_loss=0.2535 | val_loss=0.1166\n","âš ï¸ EarlyStopping 1/3\n","[12/20] train_loss=0.2386 | val_loss=0.1048\n","[13/20] train_loss=0.2309 | val_loss=0.1110\n","âš ï¸ EarlyStopping 1/3\n","[14/20] train_loss=0.2307 | val_loss=0.1038\n","[15/20] train_loss=0.2304 | val_loss=0.0998\n","[16/20] train_loss=0.2320 | val_loss=0.1002\n","âš ï¸ EarlyStopping 1/3\n","[17/20] train_loss=0.2273 | val_loss=0.0999\n","âš ï¸ EarlyStopping 2/3\n","[18/20] train_loss=0.2235 | val_loss=0.0995\n","[19/20] train_loss=0.2263 | val_loss=0.1009\n","âš ï¸ EarlyStopping 1/3\n","[20/20] train_loss=0.2304 | val_loss=0.1041\n","âš ï¸ EarlyStopping 2/3\n","ğŸ’¾ saved: ./checkpoints/maskrcnn_pills.pth\n"]}]},{"cell_type":"code","source":["# === 4) ì¶”ë¡  ìœ í‹¸ (ì•½ë‹¹ 1ê°œë§Œ ë‚¨ê¸°ê¸°) ===\n","\n","# 0-based idx â†” category_id ë§¤í•‘\n","idx_to_catid = getattr(full_ds, \"idx_to_catid\", None)\n","if idx_to_catid is None:\n","    with open(train_json, \"r\") as f:\n","        coco_tmp = json.load(f)\n","    cat_ids_list = sorted({c[\"id\"] for c in coco_tmp[\"categories\"]})\n","    idx_to_catid = {i: cid for i, cid in enumerate(cat_ids_list)}\n","\n","def keep_one_per_category(B, L_cat, S, how=\"area\"):\n","    if len(B)==0:\n","        return B, L_cat, S\n","    B = np.asarray(B, np.float32)\n","    L_cat = np.asarray(L_cat, np.int64)\n","    S = np.asarray(S, np.float32)\n","    kept_b, kept_l, kept_s = [], [], []\n","    for cat in np.unique(L_cat):\n","        m = (L_cat == cat)\n","        bb = B[m]; ss = S[m]\n","        if bb.shape[0]==1:\n","            idx = 0\n","        else:\n","            areas = (bb[:,2]-bb[:,0]) * (bb[:,3]-bb[:,1])\n","            if how == \"score\":\n","                idx = int(np.argmax(ss))\n","            elif how == \"area_score\":\n","                score = (areas**0.7) * (np.clip(ss,1e-6,None)**0.3)\n","                idx = int(np.argmax(score))\n","            else:\n","                idx = int(np.argmax(areas))\n","        kept_b.append(bb[idx]); kept_l.append(cat); kept_s.append(ss[idx])\n","    return (np.vstack(kept_b).astype(np.float32),\n","            np.array(kept_l, np.int64),\n","            np.array(kept_s, np.float32))\n","\n","@torch.no_grad()\n","def infer_maskrcnn_one(model, pil_img, score_thr=0.30):\n","    x = T.ToTensor()(pil_img).to(device)\n","    model.eval()\n","    out = model([x])[0]\n","    b  = out[\"boxes\"].detach().cpu().numpy()\n","    l  = out[\"labels\"].detach().cpu().numpy()  # 0-based idx\n","    s  = out[\"scores\"].detach().cpu().numpy()\n","    m  = out.get(\"masks\", None)\n","    if m is not None:\n","        m = m.detach().cpu().numpy()  # [N,1,H,W] (sigmoid)\n","    # í•„í„°\n","    keep = (s >= score_thr) & (l != 0)  # 0==ë°°ê²½ ë°©ì§€ìš©\n","    return b[keep], l[keep], s[keep], (m[keep] if m is not None else None)"],"metadata":{"id":"fWL4zyQFU8_J","executionInfo":{"status":"ok","timestamp":1761126398953,"user_tz":-540,"elapsed":8,"user":{"displayName":"Star Sin","userId":"12579642930462495568"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# === 5) Test ì¶”ë¡  & CSV (ì•½ë‹¹ 1ê°œë§Œ, ì‹œê°í™”) ===\n","score_thr = 0.30\n","csv_out = \"./stage2_maskrcnn_predictions.csv\"\n","\n","rows = []\n","annotation_id = 1\n","\n","file_list = sorted([fn for fn in os.listdir(test_dir)\n","                    if fn.lower().endswith((\".png\",\".jpg\",\".jpeg\"))])\n","\n","VIS_N, shown = 8, 0\n","\n","for fn in file_list:\n","    img_path = os.path.join(test_dir, fn)\n","    image_id = os.path.splitext(fn)[0]\n","    img = Image.open(img_path).convert(\"RGB\")\n","\n","    B, L_idx, S, _ = infer_maskrcnn_one(model, img, score_thr=score_thr)\n","    if len(B)==0:\n","        continue\n","\n","    # ëª¨ë¸ ë¼ë²¨(0-based idx) -> ì‹¤ì œ ì¹´í…Œê³ ë¦¬ id\n","    L_cat = np.array([idx_to_catid[int(li)] for li in L_idx], dtype=np.int64)\n","\n","    # ë™ì¼ ì•½(category_id)ë‹¹ 1ê°œë§Œ ë‚¨ê¸°ê¸° (ë©´ì  ê¸°ì¤€)\n","    B, L_cat, S = keep_one_per_category(B, L_cat, S, how=\"area\")\n","\n","    # CSV ì ì¬\n","    for (x1,y1,x2,y2), lab, sc in zip(B, L_cat, S):\n","        rows.append({\n","            \"annotation_id\": annotation_id,\n","            \"image_id\": image_id,           # í™•ì¥ì ì œê±°\n","            \"category_id\": int(lab),\n","            \"bbox_x\": round(float(x1), 2),\n","            \"bbox_y\": round(float(y1), 2),\n","            \"bbox_w\": round(float(x2-x1), 2),\n","            \"bbox_h\": round(float(y2-y1), 2),\n","            \"score\":  round(float(sc), 3)\n","        })\n","        annotation_id += 1\n","\n","    # ì‹œê°í™”\n","    if shown < VIS_N:\n","        fig, ax = plt.subplots(1,1, figsize=(7,7))\n","        ax.imshow(img); ax.axis(\"off\")\n","        for (x1,y1,x2,y2), lab, sc in zip(B, L_cat, S):\n","            rect = patches.Rectangle((x1,y1), x2-x1, y2-y1, linewidth=2, edgecolor='lime', facecolor='none')\n","            ax.add_patch(rect)\n","            ax.text(x1, max(0,y1-5), f\"{int(lab)} ({sc:.2f})\",\n","                    fontsize=9, color=\"white\",\n","                    bbox=dict(facecolor=\"black\", alpha=0.6, pad=1))\n","        ax.set_title(f\"{fn} â€” Mask R-CNN per-drug ONE\", fontsize=11)\n","        plt.show()\n","        shown += 1\n","\n","df = pd.DataFrame(rows, columns=[\n","    \"annotation_id\",\"image_id\",\"category_id\",\"bbox_x\",\"bbox_y\",\"bbox_w\",\"bbox_h\",\"score\"\n","])\n","df.to_csv(csv_out, index=False, encoding=\"utf-8-sig\")\n","print(f\"âœ… CSV ì €ì¥: {csv_out} (rows={len(df)})\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1q4RU-sfx9rx4IiUI6mwU-qAg4e67GPkZ"},"id":"Wz_SwQrRU_Ts","executionInfo":{"status":"ok","timestamp":1761126507736,"user_tz":-540,"elapsed":0,"user":{"displayName":"Star Sin","userId":"12579642930462495568"}},"outputId":"a6415965-2383-4795-fb10-78d22d800b97"},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"kZatnUxLbnr6"},"execution_count":null,"outputs":[]}]}