{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","machine_shape":"hm","authorship_tag":"ABX9TyN5V0GmstQDsxVqGfOiDw2F"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"PX2AC-RdcwQQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761207772345,"user_tz":-540,"elapsed":6576,"user":{"displayName":"Star Sin","userId":"12579642930462495568"}},"outputId":"11708faa-0449-4755-f21b-ba3f3bb806cb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.2.0)\n","Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.10.5)\n","Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n","Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n","Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n","Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n","Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n","Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n"]}],"source":["!pip install kaggle"]},{"cell_type":"code","source":["!sudo apt-get install -y fonts-nanum\n","!sudo fc-cache -fv\n","!rm ~/.cache/matplotlib -rf\n","\n","!apt-get update -qq\n","!apt-get install fonts-nanum* -qq\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.font_manager as fm\n","import warnings\n","warnings.filterwarnings(action='ignore')\n","\n","path = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf' # ë‚˜ëˆ” ê³ ë”•\n","font_name = fm.FontProperties(fname=path, size=10).get_name() # ê¸°ë³¸ í°íŠ¸ ì‚¬ì´ì¦ˆ : 10\n","plt.rc('font', family=font_name)\n","\n","fm.fontManager.addfont(path)"],"metadata":{"id":"WXDuqTxMcztI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761207799872,"user_tz":-540,"elapsed":27294,"user":{"displayName":"Star Sin","userId":"12579642930462495568"}},"outputId":"627efcdf-a4b3-4591-f840-8697df6cf817"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following NEW packages will be installed:\n","  fonts-nanum\n","0 upgraded, 1 newly installed, 0 to remove and 38 not upgraded.\n","Need to get 10.3 MB of archives.\n","After this operation, 34.1 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-nanum all 20200506-1 [10.3 MB]\n","Fetched 10.3 MB in 2s (4,508 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package fonts-nanum.\n","(Reading database ... 126675 files and directories currently installed.)\n","Preparing to unpack .../fonts-nanum_20200506-1_all.deb ...\n","Unpacking fonts-nanum (20200506-1) ...\n","Setting up fonts-nanum (20200506-1) ...\n","Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n","/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n","/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n","/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n","/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n","/usr/share/fonts/truetype/nanum: caching, new cache contents: 12 fonts, 0 dirs\n","/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n","/root/.local/share/fonts: skipping, no such directory\n","/root/.fonts: skipping, no such directory\n","/usr/share/fonts/truetype: skipping, looped directory detected\n","/usr/share/fonts/truetype/humor-sans: skipping, looped directory detected\n","/usr/share/fonts/truetype/liberation: skipping, looped directory detected\n","/usr/share/fonts/truetype/nanum: skipping, looped directory detected\n","/var/cache/fontconfig: cleaning cache directory\n","/root/.cache/fontconfig: not cleaning non-existent cache directory\n","/root/.fontconfig: not cleaning non-existent cache directory\n","fc-cache: succeeded\n","W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n","Selecting previously unselected package fonts-nanum-coding.\n","(Reading database ... 126698 files and directories currently installed.)\n","Preparing to unpack .../fonts-nanum-coding_2.5-3_all.deb ...\n","Unpacking fonts-nanum-coding (2.5-3) ...\n","Selecting previously unselected package fonts-nanum-eco.\n","Preparing to unpack .../fonts-nanum-eco_1.000-7_all.deb ...\n","Unpacking fonts-nanum-eco (1.000-7) ...\n","Selecting previously unselected package fonts-nanum-extra.\n","Preparing to unpack .../fonts-nanum-extra_20200506-1_all.deb ...\n","Unpacking fonts-nanum-extra (20200506-1) ...\n","Setting up fonts-nanum-extra (20200506-1) ...\n","Setting up fonts-nanum-coding (2.5-3) ...\n","Setting up fonts-nanum-eco (1.000-7) ...\n","Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n"]}]},{"cell_type":"code","source":["import os\n","from kaggle.api.kaggle_api_extended import KaggleApi\n","\n","os.environ['KAGGLE_USERNAME'] = 'starsin'\n","os.environ['KAGGLE_KEY'] = 'ff559a02afd29d67f19bc4001d5a69f7'\n","\n","api = KaggleApi()\n","api.authenticate()\n","\n","\n","# 2. ëŒ€íšŒ ë°ì´í„° ë‹¤ìš´ë¡œë“œ\n","competition_name = \"ai05-level1-project\"\n","api.competition_download_files(competition_name, path=\"./data\")"],"metadata":{"id":"sqi2r8Qqc12P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import zipfile\n","\n","zip_path = \"./data/ai05-level1-project.zip\"\n","extract_dir = \"./data/ai05-level1-project\"\n","\n","os.makedirs(extract_dir, exist_ok=True)\n","\n","with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n","    zip_ref.extractall(extract_dir)"],"metadata":{"id":"dC2v_Ybic4dr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# === 0) ê¸°ë³¸ ì„¤ì • ===\n","import os, json, random, numpy as np\n","import torch, torchvision\n","import torchvision.transforms as T\n","from torch.utils.data import DataLoader, Subset\n","from PIL import Image\n","\n","# ê²½ë¡œ\n","base_path     = \"./data/ai05-level1-project\"\n","img_dir       = os.path.join(base_path, \"train_images\")\n","clean_json    = \"./merged_coco/train_all_robust.json\"  # ë³‘í•©/í´ë¦°ëœ COCO json\n","work_dir      = \"./checkpoints\"; os.makedirs(work_dir, exist_ok=True)\n","\n","# ë””ë°”ì´ìŠ¤\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"device:\", device)"],"metadata":{"id":"3W-zzvfac_NA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761208152446,"user_tz":-540,"elapsed":8984,"user":{"displayName":"Star Sin","userId":"12579642930462495568"}},"outputId":"bb7a9ee5-d728-4d42-c4b5-351984f24346"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["device: cuda\n"]}]},{"cell_type":"code","source":["import os, json, math, hashlib\n","from collections import defaultdict, Counter\n","from PIL import Image\n","\n","base_path = \"./data/ai05-level1-project\"\n","train_img_dir = os.path.join(base_path, \"train_images\")\n","train_ann_dir = os.path.join(base_path, \"train_annotations\")\n","out_dir = \"./merged_coco\"\n","os.makedirs(out_dir, exist_ok=True)\n","\n","def norm_name(p: str) -> str:\n","    return os.path.basename(p).strip()\n","\n","def file_exists_in_train_images(fname: str) -> bool:\n","    return os.path.isfile(os.path.join(train_img_dir, fname))\n","\n","def get_img_size_from_disk(fname: str):\n","    path = os.path.join(train_img_dir, fname)\n","    with Image.open(path) as im:\n","        w, h = im.size\n","    return w, h\n","\n","def bbox_valid_clip(x, y, w, h, W, H):\n","    # ìŒìˆ˜/0 í­/ë†’ì´ ì œê±° + ê²½ê³„ í´ë¦¬í•‘\n","    x = max(0.0, float(x)); y = max(0.0, float(y))\n","    w = float(w); h = float(h)\n","    if w < 2 or h < 2:\n","        return None\n","    x2 = min(W - 1.0, x + w)\n","    y2 = min(H - 1.0, y + h)\n","    if x2 <= x or y2 <= y:\n","        return None\n","    w2 = x2 - x\n","    h2 = y2 - y\n","    return [float(x), float(y), float(w2), float(h2)]\n","\n","def dedup_key(image_id, category_id, bbox):\n","    # ì¤‘ë³µ ann ì œê±°ë¥¼ ìœ„í•œ key (ì¢Œí‘œëŠ” ì†Œìˆ˜ì  1ìë¦¬ê¹Œì§€ ë¼ìš´ë”©)\n","    x,y,w,h = [round(float(v), 1) for v in bbox]\n","    return (int(image_id), int(category_id), x,y,w,h)\n","\n","def hash_cat(c):\n","    # ê°™ì€ idì¸ë° nameì´ ë‹¤ë¥¸ ê²½ìš°ë¥¼ ì¡ê¸° ìœ„í•œ í•´ì‹œ(ë¦¬í¬íŒ…ìš©)\n","    return hashlib.md5(json.dumps({\"id\": c[\"id\"], \"name\": c.get(\"name\",\"\"), \"super\": c.get(\"supercategory\",\"\")}, sort_keys=True).encode()).hexdigest()"],"metadata":{"id":"s5EZmnh0iIYt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["merged = {\"images\": [], \"annotations\": [], \"categories\": []}\n","\n","# 1) ì¹´í…Œê³ ë¦¬ ìˆ˜ì§‘ + ë™ëª…ì´ì¸(ê°™ì€ id ë‹¤ë¥¸ name) íƒì§€\n","cat_by_id = {}\n","cat_hash_by_id = {}\n","cat_conflict = []\n","\n","# 2) ì´ë¯¸ì§€ ë§¤í•‘: file_name ê¸°ì¤€ìœ¼ë¡œ ìƒˆ id ë¶€ì—¬(ì¤‘ë³µ file_nameì€ í•œ ì¥ìœ¼ë¡œ í†µí•©)\n","file_to_new_img_id = {}\n","new_img_id = 1\n","\n","# 3) ì´ë¯¸ì§€ ë©”íƒ€(í­/ë†’ì´) ì‹¤ì œ ë””ìŠ¤í¬ì—ì„œ ê°€ì ¸ì˜¤ê¸° (annotationsì˜ width/height ë¬´ì‹œ)\n","image_meta = {}   # new_img_id -> {\"file_name\":..., \"width\":..., \"height\":...}\n","\n","# 4) ì–´ë…¸í…Œì´ì…˜ ìˆ˜ì§‘\n","ann_id = 1\n","seen_ann_keys = set()\n","\n","# ë¦¬í¬íŠ¸ìš© ì¹´ìš´íŠ¸\n","cnt = {\n","    \"folders_scanned\": 0,\n","    \"json_scanned\": 0,\n","    \"images_declared\": 0,\n","    \"images_kept\": 0,\n","    \"images_missing_file\": 0,\n","    \"anns_declared\": 0,\n","    \"anns_kept\": 0,\n","    \"anns_bad_bbox\": 0,\n","    \"anns_orphan_image\": 0,\n","    \"anns_dup_removed\": 0,\n","}\n","\n","for folder in sorted(os.listdir(train_ann_dir)):\n","    if not folder.endswith(\"_json\"):\n","        continue\n","    cnt[\"folders_scanned\"] += 1\n","    ann_dir = os.path.join(train_ann_dir, folder)\n","\n","    for dp, _, files in os.walk(ann_dir):\n","        for f in files:\n","            if not f.lower().endswith(\".json\"):\n","                continue\n","            cnt[\"json_scanned\"] += 1\n","            jp = os.path.join(dp, f)\n","            try:\n","                with open(jp, \"r\") as fh:\n","                    j = json.load(fh)\n","            except Exception as e:\n","                print(f\"âš ï¸ JSON ë¡œë“œ ì‹¤íŒ¨: {jp} ({e})\")\n","                continue\n","\n","            images = j.get(\"images\", [])\n","            anns   = j.get(\"annotations\", [])\n","            cats   = j.get(\"categories\", [])\n","\n","            # ---- categories ìˆ˜ì§‘ & ì¶©ëŒ ë¦¬í¬íŠ¸ ----\n","            for c in cats:\n","                cid = int(c[\"id\"])\n","                h = hash_cat(c)\n","                if cid not in cat_by_id:\n","                    cat_by_id[cid] = {\"id\": cid, \"name\": c.get(\"name\",\"\"), \"supercategory\": c.get(\"supercategory\",\"pill\")}\n","                    cat_hash_by_id[cid] = h\n","                else:\n","                    if cat_hash_by_id[cid] != h:\n","                        cat_conflict.append((cid, cat_by_id[cid], {\"id\": cid, \"name\": c.get(\"name\",\"\"), \"supercategory\": c.get(\"supercategory\",\"pill\")}))\n","            # ---- images ì²˜ë¦¬ ----\n","            for im in images:\n","                cnt[\"images_declared\"] += 1\n","                file_name = norm_name(im.get(\"file_name\") or im.get(\"imgfile\") or \"\")\n","                if not file_name:\n","                    continue\n","                # ì‹¤ì œ íŒŒì¼ ì¡´ì¬ ê²€ì‚¬\n","                if not file_exists_in_train_images(file_name):\n","                    cnt[\"images_missing_file\"] += 1\n","                    continue\n","                # ìƒˆë¡œìš´ id ë¶€ì—¬(ì´ë¯¸ ìˆìœ¼ë©´ ì¬ì‚¬ìš©)\n","                if file_name not in file_to_new_img_id:\n","                    # í­/ë†’ì´ ì‹¤ì œ ë””ìŠ¤í¬ì—ì„œ\n","                    W,H = get_img_size_from_disk(file_name)\n","                    file_to_new_img_id[file_name] = new_img_id\n","                    image_meta[new_img_id] = {\"id\": new_img_id, \"file_name\": file_name, \"width\": W, \"height\": H}\n","                    new_img_id += 1\n","                    cnt[\"images_kept\"] += 1\n","\n","            # ---- annotations ì²˜ë¦¬ ----\n","            for a in anns:\n","                cnt[\"anns_declared\"] += 1\n","                # ì›ë³¸ image_id -> file_name ì°¾ê¸°\n","                src_im = None\n","                for im in images:\n","                    if im[\"id\"] == a.get(\"image_id\"):\n","                        src_im = im\n","                        break\n","                if src_im is None:\n","                    cnt[\"anns_orphan_image\"] += 1\n","                    continue\n","\n","                file_name = norm_name(src_im.get(\"file_name\") or src_im.get(\"imgfile\") or \"\")\n","                if not file_name or file_name not in file_to_new_img_id:\n","                    # ì´ë¯¸ì§€ê°€ íŒŒì¼ ë¯¸ì¡´ì¬ë¡œ ë“œëëœ ì¼€ì´ìŠ¤\n","                    cnt[\"anns_orphan_image\"] += 1\n","                    continue\n","                new_id = file_to_new_img_id[file_name]\n","                W = image_meta[new_id][\"width\"]\n","                H = image_meta[new_id][\"height\"]\n","\n","                # bbox ì •í•©ì„±/í´ë¦½\n","                bbox = a.get(\"bbox\")\n","                if not bbox or len(bbox) != 4:\n","                    cnt[\"anns_bad_bbox\"] += 1\n","                    continue\n","                fixed = bbox_valid_clip(bbox[0], bbox[1], bbox[2], bbox[3], W, H)\n","                if fixed is None:\n","                    cnt[\"anns_bad_bbox\"] += 1\n","                    continue\n","\n","                cat_id = int(a[\"category_id\"])\n","                if cat_id not in cat_by_id:\n","                    # ë¯¸ë“±ë¡ ì¹´í…Œê³ ë¦¬ë©´ ìŠ¤í‚µ\n","                    continue\n","\n","                # ì¤‘ë³µ ann ì œê±°\n","                k = dedup_key(new_id, cat_id, fixed)\n","                if k in seen_ann_keys:\n","                    cnt[\"anns_dup_removed\"] += 1\n","                    continue\n","                seen_ann_keys.add(k)\n","\n","                merged_ann = {\n","                    \"id\": ann_id,\n","                    \"image_id\": new_id,\n","                    \"category_id\": cat_id,\n","                    \"bbox\": fixed,\n","                    \"area\": float(fixed[2]*fixed[3]),\n","                    \"iscrowd\": int(a.get(\"iscrowd\", 0)),\n","                    \"segmentation\": a.get(\"segmentation\", []),  # ë¹„ì–´ ìˆì–´ë„ OK (Mask R-CNNì€ ìš°ë¦¬ê°€ ë‚˜ì¤‘ì— ì‚¬ê°ë§ˆìŠ¤í¬ ìƒì„±)\n","                }\n","                merged[\"annotations\"].append(merged_ann)\n","                ann_id += 1\n","\n","# ìµœì¢… ì´ë¯¸ì§€/ì¹´í…Œê³ ë¦¬ ê¸°ë¡\n","merged[\"images\"] = [image_meta[i] for i in sorted(image_meta)]\n","merged[\"categories\"] = [cat_by_id[cid] for cid in sorted(cat_by_id)]\n","\n","# ì €ì¥\n","out_json = os.path.join(out_dir, \"train_all_robust.json\")\n","with open(out_json, \"w\") as f:\n","    json.dump(merged, f, indent=2, ensure_ascii=False)\n","\n","print(\"âœ… COCO ë³‘í•© ì™„ë£Œ\")\n","print(\"   images:\", len(merged[\"images\"]),\n","      \"| anns:\", len(merged[\"annotations\"]),\n","      \"| cats:\", len(merged[\"categories\"]))\n","print(\"ğŸ“Š ë¦¬í¬íŠ¸:\", cnt)\n","\n","if cat_conflict:\n","    print(\"âš ï¸ ì¹´í…Œê³ ë¦¬ ì¶©ëŒ ê°ì§€(ê°™ì€ id, ë‹¤ë¥¸ name). ìƒ˜í”Œ 5ê°œë§Œ í‘œì‹œ:\")\n","    for row in cat_conflict[:5]:\n","        cid, oldc, newc = row\n","        print(f\"  id={cid} old={oldc} new={newc}\")"],"metadata":{"id":"b87zyef6dEnP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761208163042,"user_tz":-540,"elapsed":860,"user":{"displayName":"Star Sin","userId":"12579642930462495568"}},"outputId":"f0cd626f-8972-49fc-f54e-f55bee412926"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… COCO ë³‘í•© ì™„ë£Œ\n","   images: 1489 | anns: 4524 | cats: 73\n","ğŸ“Š ë¦¬í¬íŠ¸: {'folders_scanned': 498, 'json_scanned': 4526, 'images_declared': 4526, 'images_kept': 1489, 'images_missing_file': 0, 'anns_declared': 4526, 'anns_kept': 0, 'anns_bad_bbox': 2, 'anns_orphan_image': 0, 'anns_dup_removed': 0}\n"]}]},{"cell_type":"code","source":["from collections import Counter\n","import matplotlib.pyplot as plt\n","\n","with open(clean_json, \"r\") as f:\n","    coco = json.load(f)\n","\n","cat_counter = Counter([a[\"category_id\"] for a in coco[\"annotations\"]])\n","plt.figure(figsize=(12,4))\n","plt.bar(range(len(cat_counter)), cat_counter.values())\n","plt.title(\"Class Distribution (before balancing)\")\n","plt.show()\n","\n","print(\"ì´ í´ë˜ìŠ¤ :\", len(cat_counter))\n","print(\"ìƒ˜í”Œ 10ê°œ ë¯¸ë§Œ í´ë˜ìŠ¤:\", sum(v < 10 for v in cat_counter.values()))"],"metadata":{"id":"jqxD8Ty_dBdL","colab":{"base_uri":"https://localhost:8080/","height":290},"executionInfo":{"status":"ok","timestamp":1761208164344,"user_tz":-540,"elapsed":386,"user":{"displayName":"Star Sin","userId":"12579642930462495568"}},"outputId":"1fa824b3-19c8-4fb3-cf1a-1b0b37e912f3"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1200x400 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["ì´ í´ë˜ìŠ¤ : 73\n","ìƒ˜í”Œ 10ê°œ ë¯¸ë§Œ í´ë˜ìŠ¤: 3\n"]}]},{"cell_type":"code","source":["# === 1) Dataset / Loader (bboxâ†’rect mask) ===\n","\n","def get_transform(train=True):\n","    # ë°•ìŠ¤ë¥¼ ë¹„í‹€ì§€ ì•ŠëŠ” photometric ê³„ì—´ ìœ„ì£¼\n","    aug = [T.ToTensor()]\n","    if train:\n","        aug += [\n","            T.ColorJitter(0.15, 0.15, 0.15, 0.03),\n","            T.RandomAdjustSharpness(1.3, p=0.25),\n","            T.RandomAutocontrast(p=0.2),\n","        ]\n","    return T.Compose(aug)\n","\n","def boxes_to_rect_masks(size_hw, boxes_xyxy):\n","    H, W = size_hw\n","    if len(boxes_xyxy) == 0:\n","        return np.zeros((0, H, W), dtype=np.uint8)\n","    masks = []\n","    for (x1,y1,x2,y2) in boxes_xyxy:\n","        x1, y1, x2, y2 = map(float, (x1,y1,x2,y2))\n","        x1 = max(0, min(W-1, x1)); x2 = max(0, min(W-1, x2))\n","        y1 = max(0, min(H-1, y1)); y2 = max(0, min(H-1, y2))\n","        m = np.zeros((H,W), dtype=np.uint8)\n","        if x2 > x1 and y2 > y1:\n","            m[int(y1):int(y2), int(x1):int(x2)] = 1\n","        masks.append(m)\n","    return np.stack(masks, axis=0)\n","\n","class CocoLikeMaskDataset(torch.utils.data.Dataset):\n","    \"\"\"\n","    - COCO categoriesì˜ idë¥¼ 0-based indexë¡œ ë§¤í•‘í•˜ì—¬ labels ìƒì„±\n","    - segmentationì´ ì—†ì–´ë„ bboxë¥¼ ì‚¬ê° ë§ˆìŠ¤í¬ë¡œ rasterize\n","    \"\"\"\n","    def __init__(self, img_dir, coco_json, transforms=None, train=True):\n","        with open(coco_json, \"r\") as f:\n","            coco = json.load(f)\n","        self.img_dir = img_dir\n","        self.transforms = transforms\n","        self.train = train\n","\n","        self.images  = {im[\"id\"]: im for im in coco[\"images\"]}\n","        self.img_ids = list(self.images.keys())\n","\n","        self.anns_by_img = {im_id: [] for im_id in self.img_ids}\n","        for a in coco[\"annotations\"]:\n","            self.anns_by_img[a[\"image_id\"]].append(a)\n","\n","        self.cat_ids = sorted({c[\"id\"] for c in coco[\"categories\"]})\n","        # 0..K-1 â†” real cat_id\n","        self.cat_id_to_idx = {cid:i for i,cid in enumerate(self.cat_ids)}\n","        self.idx_to_catid  = {i:cid for cid,i in self.cat_id_to_idx.items()}\n","\n","    def __len__(self):\n","        return len(self.img_ids)\n","\n","    def __getitem__(self, idx):\n","        img_id = self.img_ids[idx]\n","        im_meta = self.images[img_id]\n","        img_path = os.path.join(self.img_dir, im_meta[\"file_name\"])\n","        img = Image.open(img_path).convert(\"RGB\")\n","        W, H = img.size\n","\n","        boxes, labels, areas, iscrowd = [], [], [], []\n","        for a in self.anns_by_img.get(img_id, []):\n","            if \"bbox\" not in a or not a[\"bbox\"]:\n","                continue\n","            x, y, w, h = a[\"bbox\"]\n","            boxes.append([x, y, x+w, y+h])\n","            labels.append(self.cat_id_to_idx[a[\"category_id\"]])\n","            areas.append(w*h); iscrowd.append(a.get(\"iscrowd\", 0))\n","\n","        boxes_t = torch.as_tensor(boxes, dtype=torch.float32) if boxes else torch.zeros((0,4), dtype=torch.float32)\n","        labels_t= torch.as_tensor(labels, dtype=torch.int64)   if labels else torch.zeros((0,), dtype=torch.int64)\n","        masks_np= boxes_to_rect_masks((H,W), boxes_t.numpy())   # [N,H,W]\n","        masks_t = torch.as_tensor(masks_np, dtype=torch.uint8)\n","\n","        target = {\n","            \"boxes\": boxes_t,\n","            \"labels\": labels_t,\n","            \"masks\":  masks_t,\n","            \"image_id\": torch.tensor([img_id]),\n","            \"area\":   torch.as_tensor(areas, dtype=torch.float32) if areas else torch.zeros((0,), dtype=torch.float32),\n","            \"iscrowd\":torch.as_tensor(iscrowd, dtype=torch.int64) if iscrowd else torch.zeros((0,), dtype=torch.int64),\n","        }\n","\n","        img = self.transforms(img) if self.transforms else T.ToTensor()(img)\n","        return img, target\n","\n","def collate_fn(batch):\n","    return tuple(zip(*batch))"],"metadata":{"id":"xTZ8H0K4dFkr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# === 2) split & loader ===\n","full_ds = CocoLikeMaskDataset(img_dir, clean_json, transforms=get_transform(train=True), train=True)\n","indices = list(range(len(full_ds)))\n","random.Random(0).shuffle(indices)\n","split = int(0.9 * len(indices))\n","train_idx, val_idx = indices[:split], indices[split:]\n","\n","train_ds = Subset(full_ds, train_idx)\n","# valì€ augmentation off\n","val_ds   = Subset(CocoLikeMaskDataset(img_dir, clean_json, transforms=get_transform(train=False), train=False),\n","                  val_idx)\n","\n","train_loader = DataLoader(train_ds, batch_size=8, shuffle=True,  num_workers=2, collate_fn=collate_fn)\n","val_loader   = DataLoader(val_ds,   batch_size=8, shuffle=False, num_workers=2, collate_fn=collate_fn)\n","\n","if isinstance(full_ds, torch.utils.data.Subset):\n","    num_classes = len(full_ds.dataset.cat_ids)\n","else:\n","    num_classes = len(full_ds.cat_ids)\n","\n","\n","print(\"âœ… train:\", len(train_ds), \"val:\", len(val_ds), \"classes:\", num_classes)"],"metadata":{"id":"DTTOS7JddLFI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761208166393,"user_tz":-540,"elapsed":39,"user":{"displayName":"Star Sin","userId":"12579642930462495568"}},"outputId":"5c07dc93-a9b1-4496-edfe-8776c89c7ffd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… train: 1340 val: 149 classes: 73\n"]}]},{"cell_type":"code","source":["from torchvision.models.detection import maskrcnn_resnet50_fpn_v2, MaskRCNN_ResNet50_FPN_V2_Weights\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n","import torch\n","from torch.optim import AdamW\n","\n","# =============================\n","# 1ï¸âƒ£ ëª¨ë¸ ë¡œë“œ (COCO í”„ë¦¬íŠ¸ë ˆì¸)\n","# =============================\n","weights = MaskRCNN_ResNet50_FPN_V2_Weights.COCO_V1\n","model = maskrcnn_resnet50_fpn_v2(weights=weights)\n","\n","# í•´ìƒë„ ì¡°ì • (IoU@0.9 ëŒ€ì‘)\n","model.transform.min_size = (1024,)\n","model.transform.max_size = 1536\n","\n","# =============================\n","# 2ï¸âƒ£ ì»¤ìŠ¤í…€ í—¤ë“œ êµì²´\n","# =============================\n","in_features = model.roi_heads.box_predictor.cls_score.in_features\n","model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n","\n","in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n","model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, 256, num_classes)\n","\n","# =============================\n","# 3ï¸âƒ£ GPUë¡œ ì´ë™\n","# =============================\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)  # ğŸ’¥ ë°˜ë“œì‹œ ì´ íƒ€ì´ë°ì— GPUë¡œ ì˜¬ë ¤ì•¼ í•¨\n","\n","# =============================\n","# 4ï¸âƒ£ Optimizer & Scheduler\n","# =============================\n","optimizer = AdamW(\n","    [p for p in model.parameters() if p.requires_grad],\n","    lr=1e-4,\n","    weight_decay=1e-4\n",")\n","lr_sched = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=15)"],"metadata":{"id":"AKmd3fVSdNAX","executionInfo":{"status":"ok","timestamp":1761208169210,"user_tz":-540,"elapsed":1786,"user":{"displayName":"Star Sin","userId":"12579642930462495568"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"784eee34-6835-4f22-ff3c-56c12972911b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading: \"https://download.pytorch.org/models/maskrcnn_resnet50_fpn_v2_coco-73cbd019.pth\" to /root/.cache/torch/hub/checkpoints/maskrcnn_resnet50_fpn_v2_coco-73cbd019.pth\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 177M/177M [00:00<00:00, 246MB/s]\n"]}]},{"cell_type":"code","source":["# === 4) COCO eval utils ===\n","from pycocotools.coco import COCO\n","from pycocotools.cocoeval import COCOeval\n","\n","def _get_base_ds(ds_or_subset):\n","    return getattr(ds_or_subset, \"dataset\", ds_or_subset)\n","\n","def set_inference_params(model, score_thr=0.0001, nms_thr=0.5, detections_per_img=1000):\n","    model.roi_heads.score_thresh = score_thr\n","    model.roi_heads.nms_thresh = nms_thr\n","    model.roi_heads.detections_per_img = detections_per_img\n","    return model\n","\n","def _xyxy_to_xywh(boxes):\n","    boxes = np.asarray(boxes, dtype=np.float32)\n","    out = boxes.copy()\n","    out[:,2] = out[:,2]-out[:,0]; out[:,3] = out[:,3]-out[:,1]\n","    return out\n","\n","@torch.no_grad()\n","def run_coco_eval_bbox(model, val_loader, val_json_path, idx_to_catid, device=\"cuda\",\n","                       iou_lo=0.75, iou_hi=0.95, verbose=True):\n","    model.eval()\n","    set_inference_params(model, 0.0001, 0.5, 1000)  # í‰ê°€ìš© ì™„í™”\n","    cocoGt = COCO(val_json_path)\n","\n","    dets = []\n","    for imgs, tgts in val_loader:\n","        imgs = [im.to(device) for im in imgs]\n","        outs = model(imgs)\n","        for out, tgt in zip(outs, tgts):\n","            img_id = int(tgt[\"image_id\"].item())\n","            boxes  = out[\"boxes\"].cpu().numpy()\n","            scores = out[\"scores\"].cpu().numpy()\n","            labels = out[\"labels\"].cpu().numpy()  # 0-based(idx)\n","\n","            cat_ids = np.array([int(idx_to_catid[int(l)]) for l in labels], dtype=np.int64)\n","            xywh = _xyxy_to_xywh(boxes)\n","            for b, s, c in zip(xywh, scores, cat_ids):\n","                dets.append({\n","                    \"image_id\": img_id,\n","                    \"category_id\": int(c),\n","                    \"bbox\": [float(b[0]), float(b[1]), float(b[2]), float(b[3])],\n","                    \"score\": float(s)\n","                })\n","\n","    cocoDt = cocoGt.loadRes(dets) if len(dets)>0 else COCO()\n","    cocoEval = COCOeval(cocoGt, cocoDt, iouType='bbox')\n","    cocoEval.params.useCats = 1\n","    cocoEval.evaluate(); cocoEval.accumulate()\n","    if verbose: cocoEval.summarize()\n","\n","    precisions = cocoEval.eval['precision']  # [T,R,K,A,M]\n","    iou_thrs  = cocoEval.params.iouThrs      # [T]\n","    A_idx = 0; M_idx = -1\n","    mask = (iou_thrs >= iou_lo-1e-9) & (iou_thrs <= iou_hi+1e-9)\n","    pr = precisions[mask, :, :, A_idx, M_idx]\n","    pr = pr[pr > -1]\n","    ap = float(np.mean(pr)) if pr.size else 0.0\n","    if verbose:\n","        print(f\"mAP@[{iou_lo:.2f}:{iou_hi:.2f}] = {ap:.4f}\")\n","    return ap\n","\n","def export_val_coco_json(base_ds, subset_idx, src_json_path, out_json_path):\n","    with open(src_json_path, \"r\") as f:\n","        coco = json.load(f)\n","    val_img_ids = set(int(base_ds.img_ids[i]) for i in subset_idx)\n","    images = [im for im in coco[\"images\"] if int(im[\"id\"]) in val_img_ids]\n","    keep_ids = set(int(im[\"id\"]) for im in images)\n","    anns   = [a for a in coco[\"annotations\"] if int(a[\"image_id\"]) in keep_ids]\n","    out = {\"images\": images, \"annotations\": anns, \"categories\": coco[\"categories\"]}\n","    os.makedirs(os.path.dirname(out_json_path), exist_ok=True)\n","    with open(out_json_path, \"w\") as f:\n","        json.dump(out, f, indent=2, ensure_ascii=False)\n","    return out_json_path\n","\n","# val GT JSON ìƒì„±\n","val_json_path = \"./merged_coco/val_gt.json\"\n","_ = export_val_coco_json(_get_base_ds(full_ds), val_idx, clean_json, val_json_path)\n","\n","# ë¼ë²¨ ë§¤í•‘\n","base_ds = _get_base_ds(full_ds)\n","idx_to_catid = base_ds.idx_to_catid"],"metadata":{"id":"RDKDRY_idOw9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# === Cell 1: ê¸°ë³¸ ì„¤ì • & ìœ í‹¸ ===\n","import os, json, torch, numpy as np\n","from torch.utils.data import DataLoader, Subset\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","def get_base_dataset(ds):\n","    \"\"\"Subset/ì›ë³¸ êµ¬ë¶„ ì—†ì´ ë² ì´ìŠ¤ Dataset ê°ì²´ë¥¼ ëŒë ¤ì¤Œ.\"\"\"\n","    return ds.dataset if isinstance(ds, Subset) else ds\n","\n","def _xyxy_to_xywh(boxes):\n","    boxes = np.asarray(boxes, dtype=np.float32)\n","    out = boxes.copy()\n","    out[:, 2] = out[:, 2] - out[:, 0]\n","    out[:, 3] = out[:, 3] - out[:, 1]\n","    return out"],"metadata":{"id":"rw2tsjQ1ODgl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# === Cell 2: COCO val_gt.json ìƒì„± (info/licenses ë³´ì¡´) ===\n","def export_val_coco_json(base_ds, subset_idx, src_json_path, out_json_path):\n","    \"\"\"\n","    base_ds: (ë² ì´ìŠ¤) í•™ìŠµì— ì“´ COCO Dataset (ì˜ˆ: CocoLikeMaskDataset)\n","    subset_idx: val Subsetì˜ ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸\n","    src_json_path: ë³‘í•©ëœ ì „ì²´ train_all.json ê°™ì€ ì›ë³¸ COCO\n","    out_json_path: ì €ì¥í•  val_gt.json ê²½ë¡œ\n","    \"\"\"\n","    with open(src_json_path, \"r\") as f:\n","        coco = json.load(f)\n","\n","    # val ì´ë¯¸ì§€ id ëª¨ìœ¼ê¸°\n","    val_img_ids = set(int(base_ds.img_ids[i]) for i in subset_idx)\n","\n","    # ì´ë¯¸ì§€/ì–´ë…¸í…Œì´ì…˜ í•„í„°ë§\n","    images = [im for im in coco[\"images\"] if int(im[\"id\"]) in val_img_ids]\n","    keep_ids = set(int(im[\"id\"]) for im in images)\n","    anns   = [a for a in coco[\"annotations\"] if int(a[\"image_id\"]) in keep_ids]\n","\n","    # info/licenses ë³´ì¡´(ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì£¼ì…)\n","    info = coco.get(\"info\", {\"description\": \"auto-generated val split\"})\n","    licenses = coco.get(\"licenses\", [])\n","\n","    out = {\n","        \"info\": info,\n","        \"licenses\": licenses,\n","        \"images\": images,\n","        \"annotations\": anns,\n","        \"categories\": coco[\"categories\"],\n","    }\n","    os.makedirs(os.path.dirname(out_json_path), exist_ok=True)\n","    with open(out_json_path, \"w\") as f:\n","        json.dump(out, f, indent=2, ensure_ascii=False)\n","    return out_json_path"],"metadata":{"id":"DRxPIjtyOFDS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# === Cell 3: COCO mAP@[0.75:0.95] í‰ê°€ í•¨ìˆ˜ ===\n","from pycocotools.coco import COCO\n","from pycocotools.cocoeval import COCOeval\n","\n","@torch.no_grad()\n","def run_coco_eval_bbox(model, val_loader, val_json_path, idx_to_catid, device=\"cuda\",\n","                       iou_lo=0.75, iou_hi=0.95, verbose=True):\n","    \"\"\"\n","    model: Mask R-CNN ë“± torchvision detection ëª¨ë¸\n","    val_loader: (images, targets) ë°°ì¹˜ ì œê³µí•˜ëŠ” DataLoader (targetsëŠ” ìµœì†Œ image_id í¬í•¨)\n","    val_json_path: COCO GT json (ìœ„ Cell 2ë¡œ ë§Œë“  val_gt.json ì¶”ì²œ)\n","    idx_to_catid: ëª¨ë¸ ë¼ë²¨ ì¸ë±ìŠ¤(0..K-1) -> ì‹¤ì œ category_id ë§¤í•‘ dict\n","    \"\"\"\n","    model.eval()\n","\n","    # í‰ê°€ ì‹œ í›„ë³´ë¥¼ ë§ì´ ë‚¨ê¸°ê¸° (PRì»¤ë¸Œìš©; mAP ê³„ì‚°ì— ìœ ë¦¬)\n","    if hasattr(model, \"roi_heads\"):\n","        model.roi_heads.score_thresh = 0.0001\n","        model.roi_heads.nms_thresh = 0.50\n","        model.roi_heads.detections_per_img = 1000\n","\n","    cocoGt = COCO(val_json_path)\n","\n","    # âœ… ë°©ì–´: info/licenses ì—†ìœ¼ë©´ ì£¼ì…\n","    if 'info' not in cocoGt.dataset:\n","        cocoGt.dataset['info'] = {\"description\": \"auto-generated val split\"}\n","    if 'licenses' not in cocoGt.dataset:\n","        cocoGt.dataset['licenses'] = []\n","\n","    dets = []\n","    for imgs, tgts in val_loader:\n","        imgs = [im.to(device) for im in imgs]\n","        outs = model(imgs)\n","        for out, tgt in zip(outs, tgts):\n","            # targetsëŠ” GPUì— ì˜¬ë¦´ í•„ìš” ì—†ìŒ (image_idë§Œ ì“°ë‹ˆê¹Œ)\n","            img_id = int(tgt[\"image_id\"].item())\n","            boxes  = out[\"boxes\"].detach().cpu().numpy()\n","            scores = out[\"scores\"].detach().cpu().numpy()\n","            labels = out[\"labels\"].detach().cpu().numpy()  # 0-based idx\n","\n","            # idx -> real category_id\n","            cat_ids = np.array([int(idx_to_catid[int(l)]) for l in labels], dtype=np.int64)\n","            xywh = _xyxy_to_xywh(boxes)\n","\n","            for b, s, c in zip(xywh, scores, cat_ids):\n","                dets.append({\n","                    \"image_id\": img_id,\n","                    \"category_id\": int(c),\n","                    \"bbox\": [float(b[0]), float(b[1]), float(b[2]), float(b[3])],\n","                    \"score\": float(s)\n","                })\n","\n","    # âœ… ë¹ˆ ê²°ê³¼ë„ ì•ˆì „í•˜ê²Œ\n","    cocoDt = cocoGt.loadRes(dets if len(dets) > 0 else [])\n","\n","    cocoEval = COCOeval(cocoGt, cocoDt, iouType='bbox')\n","    cocoEval.params.useCats = 1\n","    cocoEval.evaluate(); cocoEval.accumulate()\n","    if verbose:\n","        cocoEval.summarize()\n","\n","    precisions = cocoEval.eval['precision']  # [T,R,K,A,M]\n","    iou_thrs  = cocoEval.params.iouThrs\n","    A_idx = 0; M_idx = -1\n","    mask = (iou_thrs >= iou_lo-1e-9) & (iou_thrs <= iou_hi+1e-9)\n","    pr = precisions[mask, :, :, A_idx, M_idx]\n","    pr = pr[pr > -1]\n","    ap = float(np.mean(pr)) if pr.size else 0.0\n","    if verbose:\n","        print(f\"mAP@[{iou_lo:.2f}:{iou_hi:.2f}] = {ap:.4f}\")\n","    return ap"],"metadata":{"id":"hZSfv2TW78V1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# === Cell 4: ì‚¬ìš© ì˜ˆì‹œ ===\n","# ê°€ì •:\n","# - train_ds, val_ds, train_loader, val_loader ì´ë¯¸ êµ¬ì„±ë¨\n","# - full_ds(=train+val ì›ë³¸ Dataset) ì¡´ì¬\n","# - train_all.json ê°™ì€ ë³‘í•© COCO ê²½ë¡œê°€ ìˆìŒ â†’ ì—¬ê¸°ì„œ val_gt ìƒì„±\n","# - model/optimizer/lr_sched í•™ìŠµ ëë‚œ ìƒíƒœ\n","\n","# 1) base dataset & idx_to_catid\n","base_ds = get_base_dataset(full_ds)   # CocoLikeMaskDataset ê°™ì€ ì›ë³¸ Dataset\n","idx_to_catid = base_ds.idx_to_catid   # {0: <cat_id_0>, 1: <cat_id_1>, ...}\n","\n","# 2) val ì¸ë±ìŠ¤ ìˆ˜ì§‘\n","if isinstance(val_ds, Subset):\n","    val_indices = val_ds.indices\n","else:\n","    # val_dsê°€ Subsetì´ ì•„ë‹ˆë¼ë©´, ì „ë¶€ í‰ê°€í•˜ê³  ì‹¶ë‹¤ë©´ ì´ë ‡ê²Œ:\n","    val_indices = list(range(len(base_ds)))\n","\n","# 3) val_gt.json ìƒì„±\n","src_json_path = \"./merged_coco/train_all_robust.json\"   # ë„¤ê°€ ë³‘í•©í•´ë‘” COCO json ê²½ë¡œ\n","val_json_path = \"./merged_coco/val_gt.json\"\n","export_val_coco_json(base_ds, val_indices, src_json_path, val_json_path)\n","\n","# 4) í‰ê°€ ì‹¤í–‰\n","ap_strict = run_coco_eval_bbox(\n","    model, val_loader, val_json_path, idx_to_catid, device=device,\n","    iou_lo=0.75, iou_hi=0.95, verbose=True\n",")\n","print(f\"âœ… strict mAP result: {ap_strict:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JXHYMWbJOJMO","executionInfo":{"status":"ok","timestamp":1761208797636,"user_tz":-540,"elapsed":48249,"user":{"displayName":"Star Sin","userId":"12579642930462495568"}},"outputId":"164dc28e-602d-44d3-b829-9071577d8499"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["loading annotations into memory...\n","Done (t=0.00s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=0.29s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=2.52s).\n","Accumulating evaluation results...\n","DONE (t=1.03s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.584\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.786\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.746\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.584\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.720\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.736\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.736\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.736\n","mAP@[0.75:0.95] = 0.3847\n","âœ… strict mAP result: 0.3847\n"]}]},{"cell_type":"code","source":["# === 6) Test ì¶”ë¡  â†’ CSV (í›„ì²˜ë¦¬ ì—†ì´ ì›ì‹œ ì¶œë ¥) ===\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","\n","test_dir = os.path.join(base_path, \"test_images\")\n","score_thr = 0.001  # ì›ì‹œ ì¶œë ¥ ìµœëŒ€í•œ ë³´ì¡´ (í‰ê°€ ì„œë²„ê°€ PRì»¤ë¸Œ í†µí•© ì‹œ ìœ ë¦¬)\n","\n","rows = []\n","annotation_id = 1\n","\n","file_list = sorted([fn for fn in os.listdir(test_dir) if fn.lower().endswith((\".png\",\".jpg\",\".jpeg\"))])\n","\n","model.eval()\n","set_inference_params(model, score_thr=0.0001, nms_thr=0.5, detections_per_img=1000)\n","\n","for fn in file_list:\n","    img_path = os.path.join(test_dir, fn)\n","    img_name = os.path.splitext(fn)[0]\n","    img = Image.open(img_path).convert(\"RGB\")\n","    x = T.ToTensor()(img).to(device)\n","    with torch.no_grad():\n","        out = model([x])[0]\n","\n","    boxes  = out[\"boxes\"].detach().cpu().numpy()\n","    labels = out[\"labels\"].detach().cpu().numpy()   # 0-based idx\n","    scores = out[\"scores\"].detach().cpu().numpy()\n","\n","    # idx -> real cat_id\n","    L_cat = np.array([int(idx_to_catid[int(l)]) for l in labels], dtype=np.int64)\n","\n","    for (x1,y1,x2,y2), lab, sc in zip(boxes, L_cat, scores):\n","        if sc < score_thr:\n","            continue\n","        rows.append({\n","            \"annotation_id\": annotation_id,\n","            \"image_id\": img_name,\n","            \"category_id\": int(lab),\n","            \"bbox_x\": round(float(x1), 2),\n","            \"bbox_y\": round(float(y1), 2),\n","            \"bbox_w\": round(float(x2 - x1), 2),\n","            \"bbox_h\": round(float(y2 - y1), 2),\n","            \"score\": round(float(sc), 4),\n","        })\n","        annotation_id += 1\n","\n","csv_out = \"./maskrcnn_predictions_raw.csv\"\n","df = pd.DataFrame(rows, columns=[\"annotation_id\",\"image_id\",\"category_id\",\"bbox_x\",\"bbox_y\",\"bbox_w\",\"bbox_h\",\"score\"])\n","df.to_csv(csv_out, index=False, encoding=\"utf-8-sig\")\n","print(f\"âœ… CSV ì €ì¥: {csv_out}  (rows={len(df)})\")"],"metadata":{"id":"_MbYkcAED8qk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# === 7) ë¹ ë¥¸ ì‹œê°í™” ===\n","VIS_N = 6; shown=0\n","for fn in file_list:\n","    if shown >= VIS_N: break\n","    p = os.path.join(test_dir, fn)\n","    img = Image.open(p).convert(\"RGB\")\n","    x = T.ToTensor()(img).to(device)\n","    with torch.no_grad():\n","        out = model([x])[0]\n","    boxes = out[\"boxes\"].cpu().numpy()\n","    labels= out[\"labels\"].cpu().numpy()\n","    scores= out[\"scores\"].cpu().numpy()\n","    L_cat = np.array([int(idx_to_catid[int(l)]) for l in labels], dtype=np.int64)\n","\n","    import matplotlib.pyplot as plt, matplotlib.patches as patches\n","    fig, ax = plt.subplots(1,1, figsize=(7,7))\n","    ax.imshow(img); ax.axis(\"off\")\n","    for (x1,y1,x2,y2), lab, sc in zip(boxes, L_cat, scores):\n","        rect = patches.Rectangle((x1,y1), x2-x1, y2-y1, fill=False, linewidth=2)\n","        ax.add_patch(rect)\n","        ax.text(x1, max(0,y1-5), f\"{lab} {sc:.2f}\", fontsize=9,\n","                bbox=dict(facecolor=\"black\", alpha=0.6, pad=1), color=\"white\")\n","    ax.set_title(fn)\n","    plt.show()\n","    shown += 1"],"metadata":{"id":"GpTTFMjmD-M8"},"execution_count":null,"outputs":[]}]}