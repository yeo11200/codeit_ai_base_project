import os
import json
import shutil
import cv2
import random
import math
import pandas as pd
import numpy as np
from tqdm import tqdm
from PIL import Image

# merge_coco_annotations
def merge_coco_annotations(root_folder, output_file):
    """
    ì§€ì •ëœ í´ë”ì™€ ê·¸ í•˜ìœ„ í´ë”ì˜ ëª¨ë“  COCO JSON íŒŒì¼ì„ ë³‘í•©í•©ë‹ˆë‹¤.

    Args:
        root_folder (str): ê²€ìƒ‰ì„ ì‹œì‘í•  ìµœìƒìœ„ í´ë” ê²½ë¡œ
        output_file (str): ë³‘í•©ëœ ê²°ê³¼ë¥¼ ì €ì¥í•  íŒŒì¼ ì´ë¦„
    """
    merged_data = {
        "images": [],
        "annotations": [],
        "categories": []
    }

    category_ids = set()
    image_ids = set()
    annotation_id_counter = 1

    # ì§€ì •ëœ í´ë” ë° í•˜ìœ„ í´ë” íƒìƒ‰
    for dirpath, _, filenames in os.walk(root_folder):
        for filename in filenames:
            if filename.endswith('.json'):
                json_path = os.path.join(dirpath, filename)
                print(f"ì²˜ë¦¬ ì¤‘: {json_path}")

                try:
                    with open(json_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)

                    # ì¹´í…Œê³ ë¦¬ ë³‘í•© (ì¤‘ë³µ ë°©ì§€)
                    if 'categories' in data:
                        for category in data['categories']:
                            if category['id'] not in category_ids:
                                merged_data['categories'].append(category)
                                category_ids.add(category['id'])

                    # ì´ë¯¸ì§€ ì •ë³´ ë³‘í•© (ì¤‘ë³µ ë°©ì§€)
                    if 'images' in data:
                        for image in data['images']:
                            if image['id'] not in image_ids:
                                merged_data['images'].append(image)
                                image_ids.add(image['id'])

                    # ì–´ë…¸í…Œì´ì…˜ ë³‘í•© (ID ì¬ì„¤ì •)
                    if 'annotations' in data:
                        for ann in data['annotations']:
                            ann['id'] = annotation_id_counter
                            merged_data['annotations'].append(ann)
                            annotation_id_counter += 1

                except Exception as e:
                    print(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ '{json_path}': {e}")

    # ì¹´í…Œê³ ë¦¬ ì´ë¦„ìˆœìœ¼ë¡œ ì •ë ¬ (ì„ íƒ ì‚¬í•­)
    merged_data['categories'] = sorted(merged_data['categories'], key=lambda x: x['name'])

    # ë³‘í•©ëœ íŒŒì¼ ì €ì¥
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(merged_data, f, ensure_ascii=False, indent=4)

    print("-" * 30)
    print(f"ë³‘í•© ì™„ë£Œ! ì´ {len(merged_data['images'])}ê°œì˜ ì´ë¯¸ì§€, {len(merged_data['annotations'])}ê°œì˜ ì–´ë…¸í…Œì´ì…˜ì„")
    print(f"'{output_file}' íŒŒì¼ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
    print(f"ì´ í´ë˜ìŠ¤ ìˆ˜: {len(merged_data['categories'])}")
    
# "ê¹¨ë—í•œ ì–´ë…¸í…Œì´ì…˜ ìƒì„±" í•¨ìˆ˜
def create_clean_annotations(original_merged_json, clean_json_output):
    """
    ì›ë³¸ ì–´ë…¸í…Œì´ì…˜ì—ì„œ íŒŒì¼ëª… ê·œì¹™ê³¼ bbox ê°œìˆ˜ê°€ ì¼ì¹˜í•˜ëŠ” 'ê¹¨ë—í•œ' ë°ì´í„°ë§Œ ì„ ë³„í•˜ì—¬
    ìƒˆë¡œìš´ ì–´ë…¸í…Œì´ì…˜ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    print("\n-> ì˜¬ë°”ë¥¸ ë¡œì§ìœ¼ë¡œ ê¹¨ë—í•œ ì›ë³¸ ë°ì´í„°ë¥¼ ì„ ë³„í•©ë‹ˆë‹¤...")
    with open(original_merged_json, 'r', encoding='utf-8') as f:
        merged_data = json.load(f)

    images_df = pd.DataFrame(merged_data['images'])
    annotations_df = pd.DataFrame(merged_data['annotations'])
    
    actual_counts = annotations_df['image_id'].value_counts().reset_index()
    actual_counts.columns = ['id', 'actual_count']
    analysis_df = pd.merge(images_df, actual_counts, on='id', how='left')
    analysis_df['actual_count'] = analysis_df['actual_count'].fillna(0).astype(int)
    analysis_df['expected_count'] = analysis_df['file_name'].apply(
        lambda f: len(f.split('_')[0].split('-')) - 1
    )
    
    mismatched_df = analysis_df[analysis_df['actual_count'] != analysis_df['expected_count']]
    
    # ì´ë¯¸ì§€ì˜ 'id' ì»¬ëŸ¼ì„ ê¸°ì¤€ìœ¼ë¡œ ì˜¬ë°”ë¥¸ ID ì§‘í•©ì„ ë§Œë“­ë‹ˆë‹¤.
    correct_image_ids = set(analysis_df['id']) - set(mismatched_df['id'])
    
    clean_data = {
        "images": [img for img in merged_data['images'] if img['id'] in correct_image_ids],
        "annotations": [ann for ann in merged_data['annotations'] if ann['image_id'] in correct_image_ids],
        "categories": merged_data['categories']
    }
    
    with open(clean_json_output, 'w', encoding='utf-8') as f:
        json.dump(clean_data, f, ensure_ascii=False, indent=4)

    print(f"-> {len(clean_data['images'])}ê°œì˜ ê¹¨ë—í•œ ì›ë³¸ì„ ì„ ë³„í•˜ì—¬ '{clean_json_output}'ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
    return clean_data # í›„ì† ì‘ì—…ì„ ìœ„í•´ ë°ì´í„° ë°˜í™˜

# build_pill_library
def build_pill_library(json_path, image_folder_path, output_base_folder):
    """
    ì–´ë…¸í…Œì´ì…˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì›ë³¸ ì´ë¯¸ì§€ì—ì„œ ê°œë³„ ì•Œì•½ ì´ë¯¸ì§€ë¥¼ ì˜ë¼ë‚´ì–´
    í´ë˜ìŠ¤ë³„ë¡œ ì •ë¦¬ëœ 'ì•Œì•½ ë¼ì´ë¸ŒëŸ¬ë¦¬'ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤.
    """
    if not os.path.exists(json_path):
        print(f"ì˜¤ë¥˜: '{json_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    if not os.path.exists(image_folder_path):
        print(f"ì˜¤ë¥˜: ì´ë¯¸ì§€ í´ë” '{image_folder_path}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    # ë¹ ë¥¸ ì¡°íšŒë¥¼ ìœ„í•´ ì´ë¯¸ì§€ IDì™€ íŒŒì¼ëª…ì„ ë§¤í•‘í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ ìƒì„±
    image_id_to_filename = {img['id']: img['file_name'] for img in data['images']}
    # ì¹´í…Œê³ ë¦¬ IDì™€ í´ë˜ìŠ¤ëª…ì„ ë§¤í•‘í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ ìƒì„±
    category_id_to_name = {cat['id']: cat['name'] for cat in data['categories']}

    # ê¸°ë³¸ ì¶œë ¥ í´ë” ìƒì„±
    os.makedirs(output_base_folder, exist_ok=True)
    print(f"'{output_base_folder}' í´ë”ì— ì•Œì•½ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")

    # ê° ì¹´í…Œê³ ë¦¬(í´ë˜ìŠ¤)ë³„ë¡œ í•˜ìœ„ í´ë” ìƒì„±
    for cat_name in category_id_to_name.values():
        os.makedirs(os.path.join(output_base_folder, cat_name), exist_ok=True)

    # ëª¨ë“  ì–´ë…¸í…Œì´ì…˜ì„ ìˆœíšŒí•˜ë©° ì´ë¯¸ì§€ ìë¥´ê¸°
    for ann in tqdm(data['annotations'], desc="ì•Œì•½ ì´ë¯¸ì§€ ì¶”ì¶œ ì¤‘"):
        image_id = ann['image_id']
        category_id = ann['category_id']
        bbox = ann['bbox'] # [x, y, width, height]

        # ì´ë¯¸ì§€ íŒŒì¼ëª…ê³¼ í´ë˜ìŠ¤ëª… ì¡°íšŒ
        filename = image_id_to_filename.get(image_id)
        cat_name = category_id_to_name.get(category_id)

        if not filename or not cat_name:
            continue

        try:
            # ì›ë³¸ ì´ë¯¸ì§€ ì—´ê¸°
            img_path = os.path.join(image_folder_path, filename)
            with Image.open(img_path) as img:
                # BBox ì¢Œí‘œë¥¼ PILì˜ crop í˜•ì‹ (left, upper, right, lower)ìœ¼ë¡œ ë³€í™˜
                x, y, w, h = bbox
                cropped_img = img.crop((x, y, x + w, y + h))

                # ì˜ë¼ë‚¸ ì´ë¯¸ì§€ ì €ì¥ (íŒŒì¼ ì´ë¦„ì€ ì–´ë…¸í…Œì´ì…˜ IDë¡œ í•˜ì—¬ ì¤‘ë³µ ë°©ì§€)
                output_filename = f"pill_{ann['id']}.png"
                output_path = os.path.join(output_base_folder, cat_name, output_filename)
                cropped_img.save(output_path)
                
        except FileNotFoundError:
            # print(f"ê²½ê³ : ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ - {img_path}")
            pass
        except Exception as e:
            print(f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ '{filename}': {e}")
            
    print("\n--- âœ… Phase 1 ì™„ë£Œ ---")
    print("ëª¨ë“  ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ê°œë³„ ì´ë¯¸ì§€ë¡œ ì¶”ì¶œí•˜ì—¬ 'ë””ì§€í„¸ ì•Œì•½ ë¼ì´ë¸ŒëŸ¬ë¦¬'ë¥¼ ì„±ê³µì ìœ¼ë¡œ êµ¬ì¶•í–ˆìŠµë‹ˆë‹¤.")

# clean_annotations_from_library
def clean_annotations_from_library(library_base_folder, original_json_path, cleaned_json_path):
    """
    ì‹¤ì œ íŒŒì¼ ì‹œìŠ¤í…œì— ì¡´ì¬í•˜ëŠ” í¬ë¡­ëœ ì•Œì•½ ì´ë¯¸ì§€ë“¤ì„ ê¸°ì¤€ìœ¼ë¡œ
    ì›ë³¸ ì–´ë…¸í…Œì´ì…˜ íŒŒì¼ì„ ì •ë¦¬í•©ë‹ˆë‹¤.
    """
    print("--- Phase 1: ì–´ë…¸í…Œì´ì…˜ íŒŒì¼ ì •ë¦¬ ì‹œì‘ ---")
    
    # 1. ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì•Œì•½ íŒŒì¼ë¡œë¶€í„° ìœ íš¨í•œ ì–´ë…¸í…Œì´ì…˜ ID ëª©ë¡ ìƒì„±
    valid_annotation_ids = set()
    for dirpath, _, filenames in os.walk(library_base_folder):
        for filename in filenames:
            if filename.startswith('pill_') and filename.endswith('.png'):
                try:
                    # 'pill_{ann_id}.png' í˜•ì‹ì—ì„œ ann_id ì¶”ì¶œ
                    ann_id = int(filename.split('_')[1].split('.')[0])
                    valid_annotation_ids.add(ann_id)
                except (ValueError, IndexError):
                    continue
    
    print(f"'{library_base_folder}' í´ë”ì—ì„œ ìœ íš¨í•œ ì•Œì•½ ì´ë¯¸ì§€ {len(valid_annotation_ids)}ê°œë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤.")

    # 2. ì›ë³¸ ì–´ë…¸í…Œì´ì…˜ íŒŒì¼ ë¡œë“œ
    with open(original_json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
        
    # 3. ìœ íš¨í•œ IDë¥¼ ê°€ì§„ ì–´ë…¸í…Œì´ì…˜ë§Œ í•„í„°ë§
    cleaned_annotations = [
        ann for ann in tqdm(data['annotations'], desc="ì–´ë…¸í…Œì´ì…˜ í•„í„°ë§ ì¤‘") 
        if ann['id'] in valid_annotation_ids
    ]
    
    # 4. ì •ë¦¬ëœ ì–´ë…¸í…Œì´ì…˜ì— ì‚¬ìš©ëœ ì´ë¯¸ì§€ IDë“¤ë§Œ ì¶”ë¦¼
    valid_image_ids = {ann['image_id'] for ann in cleaned_annotations}
    
    # 5. ìœ íš¨í•œ ì´ë¯¸ì§€ IDë¥¼ ê°€ì§„ ì´ë¯¸ì§€ ì •ë³´ë§Œ í•„í„°ë§
    cleaned_images = [img for img in data['images'] if img['id'] in valid_image_ids]
    
    # 6. ìµœì¢… ë°ì´í„° êµ¬ì„±
    cleaned_data = {
        "images": cleaned_images,
        "annotations": cleaned_annotations,
        "categories": data['categories']
    }
    
    with open(cleaned_json_path, 'w', encoding='utf-8') as f:
        json.dump(cleaned_data, f, ensure_ascii=False, indent=4)
        
    print(f"\nâœ… ì–´ë…¸í…Œì´ì…˜ ì •ë¦¬ ì™„ë£Œ! '{cleaned_json_path}' íŒŒì¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
    print(f"ìµœì¢… ìœ íš¨ ì–´ë…¸í…Œì´ì…˜ ìˆ˜: {len(cleaned_annotations)}")
    print("-" * 40)

# ì´ë¯¸ì§€ ìƒì„± ì•Œê³ ë¦¬ì¦˜(ë¹ˆ ë°°ê²½ ì´ë¯¸ì§€ë¥¼ ì‚¬ë“±ë¶„í•˜ê³ , ê° êµ¬ì—­ì—ì„œ ëœë¤ìœ¼ë¡œ ë°°ì¹˜)
def synthesize_images(cleaned_json_path, library_json_path, library_folder, backgrounds_folder, output_folder, target_count=200):
    """
    ì¤€ë¹„ëœ ë°°ê²½ ì´ë¯¸ì§€ ìœ„ì—, ê° í´ë˜ìŠ¤ë³„ ëª©í‘œì¹˜ì— ë„ë‹¬í•˜ë„ë¡ 4ê°œì˜ ê·€í‰ì´ ì‚¬ë¶„ë©´ ë‚´ì—ì„œ 
    ëœë¤í•˜ê²Œ ì•Œì•½ì„ ë°°ì¹˜í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ í•©ì„±í•©ë‹ˆë‹¤. (ê²½ê³„ì„  ì˜¤ë¥˜ í•´ê²°)
    """
    print("--- ğŸ¯ ëª©í‘œ ì§€í–¥ì  ì´ë¯¸ì§€ í•©ì„± ì‹œì‘ (v3.2: ê²½ê³„ì„  ì˜¤ë¥˜ í•´ê²°) ---")
    pills_per_image = 4

    # --- 1. í´ë˜ìŠ¤ ë¶„í¬ ë¶„ì„ ë° í•„ìš” ê°œìˆ˜ ê³„ì‚° ---
    with open(cleaned_json_path, 'r', encoding='utf-8') as f:
        cleaned_data = json.load(f)
        
    annotations_df = pd.DataFrame(cleaned_data['annotations'])
    current_counts = annotations_df['category_id'].value_counts()
    cat_id_to_name = {cat['id']: cat['name'] for cat in cleaned_data['categories']}
    
    needed_counts = {}
    print("\n[Step 1] í´ë˜ìŠ¤ë³„ í•„ìš” ê°œìˆ˜ ê³„ì‚°:")
    for cat_id, cat_name in cat_id_to_name.items():
        needed = max(0, target_count - current_counts.get(cat_id, 0))
        if needed > 0:
            print(f"- {cat_name}: {current_counts.get(cat_id, 0)}ê°œ -> {needed}ê°œ ì¶”ê°€ í•„ìš”")
            needed_counts[cat_id] = needed
            
    if not needed_counts:
        print("\nëª¨ë“  í´ë˜ìŠ¤ê°€ ì´ë¯¸ ëª©í‘œ ê°œìˆ˜ë¥¼ ì¶©ì¡±í•©ë‹ˆë‹¤. í•©ì„±ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    class_pool, class_weights = list(needed_counts.keys()), list(needed_counts.values())
    num_images_to_create = math.ceil(sum(class_weights) / pills_per_image)
    print(f"\nì´ {sum(class_weights)}ê°œì˜ ì•Œì•½ ì¶”ê°€ë¥¼ ìœ„í•´ ì•½ {num_images_to_create}ê°œì˜ ì´ë¯¸ì§€ ìƒì„±ì´ í•„ìš”í•©ë‹ˆë‹¤.")

    # --- 2. ì•Œì•½ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ---
    with open(library_json_path, 'r', encoding='utf-8') as f:
        library_data = json.load(f)
        
    pills_by_category = {}
    for ann in library_data['annotations']:
        cat_id = ann['category_id']
        pill_filename = f"pill_{ann['id']}.png"
        pill_path = os.path.join(library_folder, cat_id_to_name[cat_id], pill_filename)
        if os.path.exists(pill_path):
            pills_by_category.setdefault(cat_id, []).append(pill_path)

    # --- 3. ì´ë¯¸ì§€ í•©ì„± ì¤€ë¹„ ---
    os.makedirs(os.path.join(output_folder, 'images'), exist_ok=True)
    background_files = [os.path.join(backgrounds_folder, f) for f in os.listdir(backgrounds_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
    
    if not background_files:
        print(f"\nì˜¤ë¥˜: '{backgrounds_folder}' í´ë”ì—ì„œ ë°°ê²½ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    synthetic_coco = {"images": [], "annotations": [], "categories": library_data['categories']}
    annotation_id_counter = 1
    
    # --- 4. ì´ë¯¸ì§€ í•©ì„± ë£¨í”„ ---
    print("\n[Step 2] ì´ë¯¸ì§€ í•©ì„± ì‹œì‘...")
    
    for image_id in tqdm(range(num_images_to_create), desc="ì´ë¯¸ì§€ í•©ì„± ì¤‘"):
        bg_path = random.choice(background_files)
        # í•œê¸€ ê²½ë¡œ ì²˜ë¦¬ ë° ë°°ê²½ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ë°©ì–´ ì½”ë“œ
        try:
            stream = open(bg_path, "rb")
            bytes_data = bytearray(stream.read())
            numpyarray = np.asarray(bytes_data, dtype=np.uint8)
            background = cv2.imdecode(numpyarray, cv2.IMREAD_COLOR)
            stream.close()
            if background is None:
                print(f"\n[ê²½ê³ ] ë°°ê²½ íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤: {bg_path}")
                continue
        except Exception as e:
            print(f"\n[ê²½ê³ ] ë°°ê²½ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ. ê±´ë„ˆëœë‹ˆë‹¤: {bg_path}, ì˜¤ë¥˜: {e}")
            continue

        bg_h, bg_w, _ = background.shape
        
        selected_category_ids = random.choices(class_pool, weights=class_weights, k=pills_per_image)
        while len(set(selected_category_ids)) < pills_per_image:
             selected_category_ids = random.choices(class_pool, weights=class_weights, k=pills_per_image)

        quadrants = [
            (0, 0, bg_w//2, bg_h//2), (bg_w//2, 0, bg_w, bg_h//2),
            (0, bg_h//2, bg_w//2, bg_h), (bg_w//2, bg_h//2, bg_w, bg_h)
        ]
        
        for i, category_id in enumerate(selected_category_ids):
            q_x1, q_y1, q_x2, q_y2 = quadrants[i]
            
            pill_path = random.choice(pills_by_category[category_id])
            
            try:
                stream = open(pill_path, "rb")
                bytes_data = bytearray(stream.read())
                numpyarray = np.asarray(bytes_data, dtype=np.uint8)
                pill = cv2.imdecode(numpyarray, cv2.IMREAD_UNCHANGED)
                stream.close()
                if pill is None:
                    print(f"\n[ê²½ê³ ] ì•Œì•½ íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤: {pill_path}")
                    continue
            except Exception as e:
                print(f"\n[ê²½ê³ ] ì•Œì•½ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ. ê±´ë„ˆëœë‹ˆë‹¤: {pill_path}, ì˜¤ë¥˜: {e}")
                continue

            mask = pill[:,:,3] if pill.shape[2] == 4 else cv2.threshold(cv2.cvtColor(pill, cv2.COLOR_BGR2GRAY), 240, 255, cv2.THRESH_BINARY_INV)[1]
            pill, (ph, pw) = pill[:,:,:3], pill.shape[:2]

            # âœ… [ìˆ˜ì •ëœ ë¶€ë¶„] ì•ˆì „í•œ ìœ„ì¹˜ ê³„ì‚° ë¡œì§
            margin = 10
            
            # ì•Œì•½ ì¤‘ì‹¬ì˜ ìœ íš¨í•œ X, Y ì¢Œí‘œ ë²”ìœ„ ê³„ì‚°
            min_cx = q_x1 + pw//2 + margin
            max_cx = q_x2 - pw//2 - margin
            min_cy = q_y1 + ph//2 + margin
            max_cy = q_y2 - ph//2 - margin
            
            # ìœ íš¨í•œ ë²”ìœ„ê°€ ì—†ì„ ê²½ìš° (ì•Œì•½ì´ ì‚¬ë¶„ë©´ë³´ë‹¤ í´ ë•Œ)
            if min_cx >= max_cx or min_cy >= max_cy:
                # ì‚¬ë¶„ë©´ì˜ ì¤‘ì•™ì„ ê¸°ì¤€ìœ¼ë¡œ í•˜ë˜, ë°°ê²½ ì´ë¯¸ì§€ ì „ì²´ ê²½ê³„ë¥¼ ë²—ì–´ë‚˜ì§€ ì•Šë„ë¡ ê°•ì œ ì¡°ì •
                center_x = max(pw//2, min((q_x1 + q_x2)//2, bg_w - pw//2))
                center_y = max(ph//2, min((q_y1 + q_y2)//2, bg_h - ph//2))
            else:
                center_x = random.randint(min_cx, max_cx)
                center_y = random.randint(min_cy, max_cy)

            background = cv2.seamlessClone(pill, background, mask, (center_x, center_y), cv2.NORMAL_CLONE)
            new_bbox = [center_x - pw//2, center_y - ph//2, pw, ph]
            
            synthetic_coco['annotations'].append({
                "id": annotation_id_counter, "image_id": image_id, "category_id": category_id,
                "bbox": new_bbox, "area": pw * ph, "iscrowd": 0
            })
            annotation_id_counter += 1

        output_filename = f"synthetic_final_{image_id:06d}.png"
        output_filepath = os.path.join(output_folder, 'images', output_filename)
        
        extension = os.path.splitext(output_filepath)[1]
        result, encoded_img = cv2.imencode(extension, background)
        if result:
            with open(output_filepath, mode='w+b') as f:
                encoded_img.tofile(f)
                
        synthetic_coco['images'].append({"id": image_id, "width": bg_w, "height": bg_h, "file_name": output_filename})

    # --- 5. ìµœì¢… ê²°ê³¼ ì €ì¥ ---
    output_json_path = os.path.join(output_folder, 'synthetic_annotations_final.json')
    with open(output_json_path, 'w', encoding='utf-8') as f:
        json.dump(synthetic_coco, f, ensure_ascii=False, indent=4)
        
    print(f"\nâœ… ì´ë¯¸ì§€ í•©ì„± ì™„ë£Œ! '{output_folder}' í´ë”ì— {len(synthetic_coco['images'])}ê°œì˜ ì´ë¯¸ì§€ì™€ ì–´ë…¸í…Œì´ì…˜ íŒŒì¼ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")

# ìµœì¢… íŒ¨í‚¤ì§• í•¨ìˆ˜
def package_final_dataset(clean_data, synthetic_json_path, source_original_images_folder, source_synthetic_images_folder, output_folder):
    """
    ê¹¨ë—í•œ ì›ë³¸ ë°ì´í„°ì™€ í•©ì„± ë°ì´í„°ë¥¼ ìµœì¢…ì ìœ¼ë¡œ í†µí•©í•˜ì—¬ íŒ¨í‚¤ì§•í•©ë‹ˆë‹¤.
    """
    final_images_dir = os.path.join(output_folder, 'images')
    if os.path.exists(output_folder):
        shutil.rmtree(output_folder)
    os.makedirs(final_images_dir)
    
    # 1. ì´ë¯¸ì§€ íŒŒì¼ ë³µì‚¬
    clean_filenames = [img['file_name'] for img in clean_data['images']]
    for filename in tqdm(clean_filenames, desc="ì›ë³¸ ì´ë¯¸ì§€ ë³µì‚¬"):
        shutil.copy(os.path.join(source_original_images_folder, filename), final_images_dir)
    
    synth_filenames = os.listdir(source_synthetic_images_folder)
    for filename in tqdm(synth_filenames, desc="í•©ì„± ì´ë¯¸ì§€ ë³µì‚¬"):
        shutil.copy(os.path.join(source_synthetic_images_folder, filename), final_images_dir)

    # 2. ì–´ë…¸í…Œì´ì…˜ ë³‘í•©
    with open(synthetic_json_path, 'r', encoding='utf-8') as f:
        synth_data = json.load(f)

    final_coco = {"images": [], "annotations": [], "categories": clean_data['categories']}
    final_coco['images'].extend(clean_data['images'])
    final_coco['annotations'].extend(clean_data['annotations'])
    
    # ID ì¬ì„¤ì •
    image_id_offset = max(img['id'] for img in clean_data['images']) + 1 if clean_data['images'] else 0
    ann_id_offset = max(ann['id'] for ann in clean_data['annotations']) + 1 if clean_data['annotations'] else 0
    
    synth_image_id_map = {img['id']: img['id'] + image_id_offset for img in synth_data['images']}
    
    for synth_img in synth_data['images']:
        synth_img['id'] = synth_image_id_map[synth_img['id']]
        final_coco['images'].append(synth_img)

    for synth_ann in synth_data['annotations']:
        synth_ann['id'] += ann_id_offset
        synth_ann['image_id'] = synth_image_id_map[synth_ann['image_id']]
        final_coco['annotations'].append(synth_ann)
    
    # ìµœì¢… íŒŒì¼ ì €ì¥
    output_json_path = os.path.join(output_folder, 'final_annotations.json')
    with open(output_json_path, 'w', encoding='utf-8') as f:
        json.dump(final_coco, f, ensure_ascii=False, indent=4)